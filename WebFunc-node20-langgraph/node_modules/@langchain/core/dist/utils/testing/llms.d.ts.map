{"version":3,"file":"llms.d.ts","names":["CallbackManagerForLLMRun","BaseLLMParams","LLM","GenerationChunk","FakeLLM","Promise","FakeStreamingLLM","AsyncGenerator"],"sources":["../../../src/utils/testing/llms.d.ts"],"sourcesContent":["import { CallbackManagerForLLMRun } from \"../../callbacks/manager.js\";\nimport { BaseLLMParams, LLM } from \"../../language_models/llms.js\";\nimport { GenerationChunk } from \"../../outputs.js\";\nexport declare class FakeLLM extends LLM {\n    response?: string;\n    thrownErrorString?: string;\n    constructor(fields: {\n        response?: string;\n        thrownErrorString?: string;\n    } & BaseLLMParams);\n    _llmType(): string;\n    _call(prompt: string, _options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<string>;\n}\nexport declare class FakeStreamingLLM extends LLM {\n    sleep?: number;\n    responses?: string[];\n    thrownErrorString?: string;\n    constructor(fields: {\n        sleep?: number;\n        responses?: string[];\n        thrownErrorString?: string;\n    } & BaseLLMParams);\n    _llmType(): string;\n    _call(prompt: string): Promise<string>;\n    _streamResponseChunks(input: string, _options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk, void, unknown>;\n}\n//# sourceMappingURL=llms.d.ts.map"],"mappings":";;;;;cAGqBI,OAAAA,SAAgBF,GAAAA;;EAAhBE,iBAAO,CAAA,EAAA,MAAA;EAMpBH,WAAAA,CAAAA,MAAAA,EAAAA;IAEoED,QAAAA,CAAAA,EAAAA,MAAAA;IAA2BK,iBAAAA,CAAAA,EAAAA,MAAAA;EARlEH,CAAAA,GAM7BD,aAN6BC;EAAG,QAAA,CAAA,CAAA,EAAA,MAAA;EAUnBI,KAAAA,CAAAA,MAAAA,EAAAA,MAAgB,EAAA,QAAA,EAAA,IAAA,CAAA,mBAAA,CAAA,EAAA,UAAA,CAAA,EAFuCN,wBAEvC,CAAA,EAFkEK,OAElE,CAAA,MAAA,CAAA;;AAUVA,cAVNC,gBAAAA,SAAyBJ,GAAAA,CAUnBG;EACiEL,KAAAA,CAAAA,EAAAA,MAAAA;EAA0CG,SAAAA,CAAAA,EAAAA,MAAAA,EAAAA;EAAfI,iBAAAA,CAAAA,EAAAA,MAAAA;EAXzEL,WAAAA,CAAAA,MAAAA,EAAAA;IAAG,KAAA,CAAA,EAAA,MAAA;;;MAQzCD;;yBAEmBI;0FACiEL,2BAA2BO,eAAeJ"}