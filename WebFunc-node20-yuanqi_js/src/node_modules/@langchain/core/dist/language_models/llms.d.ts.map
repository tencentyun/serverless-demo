{"version":3,"file":"llms.d.ts","names":["BasePromptValueInterface","LLMResult","Generation","GenerationChunk","BaseCallbackConfig","CallbackManagerForLLMRun","Callbacks","BaseLanguageModel","BaseLanguageModelCallOptions","BaseLanguageModelInput","BaseLanguageModelParams","RunnableConfig","BaseCache","SerializedLLM","Record","BaseLLMParams","BaseLLMCallOptions","BaseLLM","CallOptions","Exclude","Omit","Partial","Promise","AsyncGenerator","prompts","cache","llmStringKey","parsedOptions","handledOptions","runId","LLM"],"sources":["../../src/language_models/llms.d.ts"],"sourcesContent":["import type { BasePromptValueInterface } from \"../prompt_values.js\";\nimport { type LLMResult, type Generation, GenerationChunk } from \"../outputs.js\";\nimport { type BaseCallbackConfig, type CallbackManagerForLLMRun, type Callbacks } from \"../callbacks/manager.js\";\nimport { BaseLanguageModel, type BaseLanguageModelCallOptions, type BaseLanguageModelInput, type BaseLanguageModelParams } from \"./base.js\";\nimport type { RunnableConfig } from \"../runnables/config.js\";\nimport type { BaseCache } from \"../caches/index.js\";\nexport type SerializedLLM = {\n    _model: string;\n    _type: string;\n} & Record<string, any>;\nexport interface BaseLLMParams extends BaseLanguageModelParams {\n}\nexport interface BaseLLMCallOptions extends BaseLanguageModelCallOptions {\n}\n/**\n * LLM Wrapper. Takes in a prompt (or prompts) and returns a string.\n */\nexport declare abstract class BaseLLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLanguageModel<string, CallOptions> {\n    ParsedCallOptions: Omit<CallOptions, Exclude<keyof RunnableConfig, \"signal\" | \"timeout\" | \"maxConcurrency\">>;\n    lc_namespace: string[];\n    /**\n     * This method takes an input and options, and returns a string. It\n     * converts the input to a prompt value and generates a result based on\n     * the prompt.\n     * @param input Input for the LLM.\n     * @param options Options for the LLM call.\n     * @returns A string result based on the prompt.\n     */\n    invoke(input: BaseLanguageModelInput, options?: Partial<CallOptions>): Promise<string>;\n    _streamResponseChunks(_input: string, _options: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;\n    protected _separateRunnableConfigFromCallOptionsCompat(options?: Partial<CallOptions>): [RunnableConfig, this[\"ParsedCallOptions\"]];\n    _streamIterator(input: BaseLanguageModelInput, options?: Partial<CallOptions>): AsyncGenerator<string>;\n    /**\n     * This method takes prompt values, options, and callbacks, and generates\n     * a result based on the prompts.\n     * @param promptValues Prompt values for the LLM.\n     * @param options Options for the LLM call.\n     * @param callbacks Callbacks for the LLM call.\n     * @returns An LLMResult based on the prompts.\n     */\n    generatePrompt(promptValues: BasePromptValueInterface[], options?: string[] | Partial<CallOptions>, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Run the LLM on the given prompts and input.\n     */\n    abstract _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(_options?: this[\"ParsedCallOptions\"]): any;\n    _flattenLLMResult(llmResult: LLMResult): LLMResult[];\n    /** @ignore */\n    _generateUncached(prompts: string[], parsedOptions: this[\"ParsedCallOptions\"], handledOptions: BaseCallbackConfig, startedRunManagers?: CallbackManagerForLLMRun[]): Promise<LLMResult>;\n    _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }: {\n        prompts: string[];\n        cache: BaseCache<Generation[]>;\n        llmStringKey: string;\n        parsedOptions: any;\n        handledOptions: RunnableConfig;\n        runId?: string;\n    }): Promise<LLMResult & {\n        missingPromptIndices: number[];\n        startedRunManagers?: CallbackManagerForLLMRun[];\n    }>;\n    /**\n     * Run the LLM on the given prompts and input, handling caching.\n     */\n    generate(prompts: string[], options?: string[] | Partial<CallOptions>, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Get the identifying parameters of the LLM.\n     */\n    _identifyingParams(): Record<string, any>;\n    /**\n     * Return the string type key uniquely identifying this class of LLM.\n     */\n    abstract _llmType(): string;\n    _modelType(): string;\n}\n/**\n * LLM class that provides a simpler interface to subclass than {@link BaseLLM}.\n *\n * Requires only implementing a simpler {@link _call} method instead of {@link _generate}.\n *\n * @augments BaseLLM\n */\nexport declare abstract class LLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLLM<CallOptions> {\n    /**\n     * Run the LLM on the given prompt and input.\n     */\n    abstract _call(prompt: string, options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<string>;\n    _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n}\n//# sourceMappingURL=llms.d.ts.map"],"mappings":";;;;;;;;;KAMYa,aAAAA;;;AAAZ,CAAA,GAGIC,MAHQD,CAAAA,MAAAA,EAAAA,GAAa,CAAA;AAIRE,UAAAA,aAAAA,SAAsBL,uBAAuB,CAAA,CAE9D;AAK8BO,UALbD,kBAAAA,SAA2BR,4BAKP,CAAA;;;;AACkBG,uBADzBM,OACyBN,CAAAA,oBADGK,kBACHL,GADwBK,kBACxBL,CAAAA,SADoDJ,iBACpDI,CAAAA,MAAAA,EAD8EO,WAC9EP,CAAAA,CAAAA;EAAdQ,iBAAAA,EAAlBC,IAAkBD,CAAbD,WAAaC,EAAAA,OAAAA,CAAAA,MAAcR,cAAdQ,EAAAA,QAAAA,GAAAA,SAAAA,GAAAA,gBAAAA,CAAAA,CAAAA;EAAlBC,YAAAA,EAAAA,MAAAA,EAAAA;EAULX;;;;;;;;EAEmDY,MAAAA,CAAAA,KAAAA,EAFnDZ,sBAEmDY,EAAAA,OAAAA,CAAAA,EAFjBA,OAEiBA,CAFTH,WAESG,CAAAA,CAAAA,EAFMC,OAEND,CAAAA,MAAAA,CAAAA;EAAwBV,qBAAAA,CAAAA,MAAAA,EAAAA,MAAAA,EAAAA,QAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,WAAAA,CAAAA,EADAN,wBACAM,CAAAA,EAD2BY,cAC3BZ,CAD0CR,eAC1CQ,CAAAA;EAClEF,UAAAA,4CAAAA,CAAAA,OAAAA,CAAAA,EAD0CY,OAC1CZ,CADkDS,WAClDT,CAAAA,CAAAA,EAAAA,CADkEE,cAClEF,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA;EAA0CS,eAAAA,CAAAA,KAAAA,EAA1CT,sBAA0CS,EAAAA,OAAAA,CAAAA,EAARG,OAAQH,CAAAA,WAAAA,CAAAA,CAAAA,EAAeK,cAAfL,CAAAA,MAAAA,CAAAA;EAARG;;;;;;;;EAa8BhB,cAAAA,CAAAA,YAAAA,EAJ1DL,wBAI0DK,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAJTgB,OAIShB,CAJDa,WAICb,CAAAA,EAAAA,SAAAA,CAAAA,EAJyBC,SAIzBD,CAAAA,EAJqCiB,OAIrCjB,CAJ6CJ,SAI7CI,CAAAA;EAAmCJ;;;EAKjFA,SAAAA,SAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,UAAAA,CAAAA,EAL8CI,wBAK9CJ,CAAAA,EALyEqB,OAKzErB,CALiFA,SAKjFA,CAAAA;EAEsDG;;;EAAsEkB,gBAAAA,CAAAA,QAAAA,CAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA,EAAAA,GAAAA;EACnJE,iBAAAA,CAAAA,SAAAA,EAHWvB,SAGXuB,CAAAA,EAHuBvB,SAGvBuB,EAAAA;EAASC;EAAOC,iBAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,aAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,cAAAA,EAD6DtB,kBAC7DsB,EAAAA,kBAAAA,CAAAA,EADsGrB,wBACtGqB,EAAAA,CAAAA,EADmIJ,OACnII,CAD2IzB,SAC3IyB,CAAAA;EAAcC,eAAAA,CAAAA;IAAAA,OAAAA;IAAAA,KAAAA;IAAAA,YAAAA;IAAAA,aAAAA;IAAAA,cAAAA;IAAAA;EASvBtB,CATuBsB,EAAAA;IAAeC,OAAAA,EAAAA,MAAAA,EAAAA;IAAgBC,KAAAA,EAEpEjB,SAFoEiB,CAE1D3B,UAF0D2B,EAAAA,CAAAA;IAE1D3B,YAAAA,EAAAA,MAAAA;IAAVU,aAAAA,EAAAA,GAAAA;IAGSD,cAAAA,EAAAA,cAAAA;IAERV,KAAAA,CAAAA,EAAAA,MAAAA;EAEaI,CAAAA,CAAAA,EAFrBiB,OAEqBjB,CAFbJ,SAEaI,GAAAA;IAFrBiB,oBAAAA,EAAAA,MAAAA,EAAAA;IAOqDJ,kBAAAA,CAAAA,EALhCb,wBAKgCa,EAAAA;EAARG,CAAAA,CAAAA;EAAkCf;;;EAI7DQ,QAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAJ2BO,OAI3BP,CAJmCI,WAInCJ,CAAAA,EAAAA,SAAAA,CAAAA,EAJ6DR,SAI7DQ,CAAAA,EAJyEQ,OAIzER,CAJiFb,SAIjFa,CAAAA;EArDiFP;AAAiB;AAmE5H;EAAsDS,kBAAAA,CAAAA,CAAAA,EAd5BF,MAc4BE,CAAAA,MAAAA,EAAAA,GAAAA,CAAAA;EAAqBA;;;EAIoCM,SAAAA,QAAAA,CAAAA,CAAAA,EAAAA,MAAAA;EAC7BjB,UAAAA,CAAAA,CAAAA,EAAAA,MAAAA;;;;AAL4B;;;;;uBAAhFyB,wBAAwBd,qBAAqBA,4BAA4BC,QAAQC;;;;kFAI3Bb,2BAA2BiB;gFAC7BjB,2BAA2BiB,QAAQrB"}