{"version":3,"file":"contextEditing.d.ts","names":["__types_js10","BaseMessage","BaseLanguageModel","ContextSize","KeepSize","TokenCounter","ContextEdit","Promise","ClearToolUsesEditConfig","ClearToolUsesEdit","Set","ContextEditingMiddlewareConfig","contextEditingMiddleware","_langchain_core_tools5","ServerTool","ClientTool","AgentMiddleware"],"sources":["../../../src/agents/middleware/contextEditing.d.ts"],"sourcesContent":["/**\n * Context editing middleware.\n *\n * This middleware mirrors Anthropic's context editing capabilities by clearing\n * older tool results once the conversation grows beyond a configurable token\n * threshold. The implementation is intentionally model-agnostic so it can be used\n * with any LangChain chat model.\n */\nimport type { BaseMessage } from \"@langchain/core/messages\";\nimport type { BaseLanguageModel } from \"@langchain/core/language_models/base\";\nimport { type ContextSize, type KeepSize, type TokenCounter } from \"./summarization.js\";\n/**\n * Protocol describing a context editing strategy.\n *\n * Implement this interface to create custom strategies for managing\n * conversation context size. The `apply` method should modify the\n * messages array in-place and return the updated token count.\n *\n * @example\n * ```ts\n * import { HumanMessage, type ContextEdit, type BaseMessage  } from \"langchain\";\n *\n * class RemoveOldHumanMessages implements ContextEdit {\n *   constructor(private keepRecent: number = 10) {}\n *\n *   async apply({ messages, countTokens }) {\n *     // Check current token count\n *     const tokens = await countTokens(messages);\n *\n *     // Remove old human messages if over limit, keeping the most recent ones\n *     if (tokens > 50000) {\n *       const humanMessages: number[] = [];\n *\n *       // Find all human message indices\n *       for (let i = 0; i < messages.length; i++) {\n *         if (HumanMessage.isInstance(messages[i])) {\n *           humanMessages.push(i);\n *         }\n *       }\n *\n *       // Remove old human messages (keep only the most recent N)\n *       const toRemove = humanMessages.slice(0, -this.keepRecent);\n *       for (let i = toRemove.length - 1; i >= 0; i--) {\n *         messages.splice(toRemove[i]!, 1);\n *       }\n *     }\n *   }\n * }\n * ```\n */\nexport interface ContextEdit {\n    /**\n     * Apply an edit to the message list, returning the new token count.\n     *\n     * This method should:\n     * 1. Check if editing is needed based on `tokens` parameter\n     * 2. Modify the `messages` array in-place (if needed)\n     * 3. Return the new token count after modifications\n     *\n     * @param params - Parameters for the editing operation\n     * @returns The updated token count after applying edits\n     */\n    apply(params: {\n        /**\n         * Array of messages to potentially edit (modify in-place)\n         */\n        messages: BaseMessage[];\n        /**\n         * Function to count tokens in a message array\n         */\n        countTokens: TokenCounter;\n        /**\n         * Optional model instance for model profile information\n         */\n        model?: BaseLanguageModel;\n    }): void | Promise<void>;\n}\n/**\n * Configuration for clearing tool outputs when token limits are exceeded.\n */\nexport interface ClearToolUsesEditConfig {\n    /**\n     * Trigger conditions for context editing.\n     * Can be a single condition object (all properties must be met) or an array of conditions (any condition must be met).\n     *\n     * @example\n     * ```ts\n     * // Single condition: trigger if tokens >= 100000 AND messages >= 50\n     * trigger: { tokens: 100000, messages: 50 }\n     *\n     * // Multiple conditions: trigger if (tokens >= 100000 AND messages >= 50) OR (tokens >= 50000 AND messages >= 100)\n     * trigger: [\n     *   { tokens: 100000, messages: 50 },\n     *   { tokens: 50000, messages: 100 }\n     * ]\n     *\n     * // Fractional trigger: trigger at 80% of model's max input tokens\n     * trigger: { fraction: 0.8 }\n     * ```\n     */\n    trigger?: ContextSize | ContextSize[];\n    /**\n     * Context retention policy applied after editing.\n     * Specify how many tool results to preserve using messages, tokens, or fraction.\n     *\n     * @example\n     * ```ts\n     * // Keep 3 most recent tool results\n     * keep: { messages: 3 }\n     *\n     * // Keep tool results that fit within 1000 tokens\n     * keep: { tokens: 1000 }\n     *\n     * // Keep tool results that fit within 30% of model's max input tokens\n     * keep: { fraction: 0.3 }\n     * ```\n     */\n    keep?: KeepSize;\n    /**\n     * Whether to clear the originating tool call parameters on the AI message.\n     * @default false\n     */\n    clearToolInputs?: boolean;\n    /**\n     * List of tool names to exclude from clearing.\n     * @default []\n     */\n    excludeTools?: string[];\n    /**\n     * Placeholder text inserted for cleared tool outputs.\n     * @default \"[cleared]\"\n     */\n    placeholder?: string;\n    /**\n     * @deprecated Use `trigger: { tokens: value }` instead.\n     */\n    triggerTokens?: number;\n    /**\n     * @deprecated Use `keep: { messages: value }` instead.\n     */\n    keepMessages?: number;\n    /**\n     * @deprecated This property is deprecated and will be removed in a future version.\n     * Use `keep: { tokens: value }` or `keep: { messages: value }` instead to control retention.\n     */\n    clearAtLeast?: number;\n}\n/**\n * Strategy for clearing tool outputs when token limits are exceeded.\n *\n * This strategy mirrors Anthropic's `clear_tool_uses_20250919` behavior by\n * replacing older tool results with a placeholder text when the conversation\n * grows too large. It preserves the most recent tool results and can exclude\n * specific tools from being cleared.\n *\n * @example\n * ```ts\n * import { ClearToolUsesEdit } from \"langchain\";\n *\n * const edit = new ClearToolUsesEdit({\n *   trigger: { tokens: 100000 },  // Start clearing at 100K tokens\n *   keep: { messages: 3 },        // Keep 3 most recent tool results\n *   excludeTools: [\"important\"],   // Never clear \"important\" tool\n *   clearToolInputs: false,        // Keep tool call arguments\n *   placeholder: \"[cleared]\",      // Replacement text\n * });\n *\n * // Multiple trigger conditions\n * const edit2 = new ClearToolUsesEdit({\n *   trigger: [\n *     { tokens: 100000, messages: 50 },\n *     { tokens: 50000, messages: 100 }\n *   ],\n *   keep: { messages: 3 },\n * });\n *\n * // Fractional trigger with model profile\n * const edit3 = new ClearToolUsesEdit({\n *   trigger: { fraction: 0.8 },  // Trigger at 80% of model's max tokens\n *   keep: { fraction: 0.3 },     // Keep 30% of model's max tokens\n * });\n * ```\n */\nexport declare class ClearToolUsesEdit implements ContextEdit {\n    #private;\n    trigger: ContextSize | ContextSize[];\n    keep: KeepSize;\n    clearToolInputs: boolean;\n    excludeTools: Set<string>;\n    placeholder: string;\n    model: BaseLanguageModel;\n    clearAtLeast: number;\n    constructor(config?: ClearToolUsesEditConfig);\n    apply(params: {\n        messages: BaseMessage[];\n        model: BaseLanguageModel;\n        countTokens: TokenCounter;\n    }): Promise<void>;\n}\n/**\n * Configuration for the Context Editing Middleware.\n */\nexport interface ContextEditingMiddlewareConfig {\n    /**\n     * Sequence of edit strategies to apply. Defaults to a single\n     * ClearToolUsesEdit mirroring Anthropic defaults.\n     */\n    edits?: ContextEdit[];\n    /**\n     * Whether to use approximate token counting (faster, less accurate)\n     * or exact counting implemented by the chat model (potentially slower, more accurate).\n     * Currently only OpenAI models support exact counting.\n     * @default \"approx\"\n     */\n    tokenCountMethod?: \"approx\" | \"model\";\n}\n/**\n * Middleware that automatically prunes tool results to manage context size.\n *\n * This middleware applies a sequence of edits when the total input token count\n * exceeds configured thresholds. By default, it uses the `ClearToolUsesEdit` strategy\n * which mirrors Anthropic's `clear_tool_uses_20250919` behaviour by clearing older\n * tool results once the conversation exceeds 100,000 tokens.\n *\n * ## Basic Usage\n *\n * Use the middleware with default settings to automatically manage context:\n *\n * @example Basic usage with defaults\n * ```ts\n * import { contextEditingMiddleware } from \"langchain\";\n * import { createAgent } from \"langchain\";\n *\n * const agent = createAgent({\n *   model: \"anthropic:claude-sonnet-4-5\",\n *   tools: [searchTool, calculatorTool],\n *   middleware: [\n *     contextEditingMiddleware(),\n *   ],\n * });\n * ```\n *\n * The default configuration:\n * - Triggers when context exceeds **100,000 tokens**\n * - Keeps the **3 most recent** tool results\n * - Uses **approximate token counting** (fast)\n * - Does not clear tool call arguments\n *\n * ## Custom Configuration\n *\n * Customize the clearing behavior with `ClearToolUsesEdit`:\n *\n * @example Custom ClearToolUsesEdit configuration\n * ```ts\n * import { contextEditingMiddleware, ClearToolUsesEdit } from \"langchain\";\n *\n * // Single condition: trigger if tokens >= 50000 AND messages >= 20\n * const agent1 = createAgent({\n *   model: \"anthropic:claude-sonnet-4-5\",\n *   tools: [searchTool, calculatorTool],\n *   middleware: [\n *     contextEditingMiddleware({\n *       edits: [\n *         new ClearToolUsesEdit({\n *           trigger: { tokens: 50000, messages: 20 },\n *           keep: { messages: 5 },\n *           excludeTools: [\"search\"],\n *           clearToolInputs: true,\n *         }),\n *       ],\n *       tokenCountMethod: \"approx\",\n *     }),\n *   ],\n * });\n *\n * // Multiple conditions: trigger if (tokens >= 50000 AND messages >= 20) OR (tokens >= 30000 AND messages >= 50)\n * const agent2 = createAgent({\n *   model: \"anthropic:claude-sonnet-4-5\",\n *   tools: [searchTool, calculatorTool],\n *   middleware: [\n *     contextEditingMiddleware({\n *       edits: [\n *         new ClearToolUsesEdit({\n *           trigger: [\n *             { tokens: 50000, messages: 20 },\n *             { tokens: 30000, messages: 50 },\n *           ],\n *           keep: { messages: 5 },\n *         }),\n *       ],\n *     }),\n *   ],\n * });\n *\n * // Fractional trigger with model profile\n * const agent3 = createAgent({\n *   model: chatModel,\n *   tools: [searchTool, calculatorTool],\n *   middleware: [\n *     contextEditingMiddleware({\n *       edits: [\n *         new ClearToolUsesEdit({\n *           trigger: { fraction: 0.8 },  // Trigger at 80% of model's max tokens\n *           keep: { fraction: 0.3 },     // Keep 30% of model's max tokens\n *           model: chatModel,\n *         }),\n *       ],\n *     }),\n *   ],\n * });\n * ```\n *\n * ## Custom Editing Strategies\n *\n * Implement your own context editing strategy by creating a class that\n * implements the `ContextEdit` interface:\n *\n * @example Custom editing strategy\n * ```ts\n * import { contextEditingMiddleware, type ContextEdit, type TokenCounter } from \"langchain\";\n * import type { BaseMessage } from \"@langchain/core/messages\";\n *\n * class CustomEdit implements ContextEdit {\n *   async apply(params: {\n *     tokens: number;\n *     messages: BaseMessage[];\n *     countTokens: TokenCounter;\n *   }): Promise<number> {\n *     // Implement your custom editing logic here\n *     // and apply it to the messages array, then\n *     // return the new token count after edits\n *     return countTokens(messages);\n *   }\n * }\n * ```\n *\n * @param config - Configuration options for the middleware\n * @returns A middleware instance that can be used with `createAgent`\n */\nexport declare function contextEditingMiddleware(config?: ContextEditingMiddlewareConfig): import(\"./types.js\").AgentMiddleware<undefined, undefined, unknown, readonly (import(\"@langchain/core/tools\").ServerTool | import(\"@langchain/core/tools\").ClientTool)[]>;\n//# sourceMappingURL=contextEditing.d.ts.map"],"mappings":";;;;;;;;;AA2EsB;AAKtB;;;;AAqCmB;AAkEnB;;;;;;;;;;;;AAA6D;AAmB7D;AAyIA;;;;;AAA+H;;;;;;;;;;;;;UAjS9GM,WAAAA;;;;;;;;;;;;;;;;cAgBCL;;;;iBAIGI;;;;YAILH;aACDK;;;;;UAKEC,uBAAAA;;;;;;;;;;;;;;;;;;;;YAoBHL,cAAcA;;;;;;;;;;;;;;;;;SAiBjBC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cAkEUK,iBAAAA,YAA6BH;;WAErCH,cAAcA;QACjBC;;gBAEQM;;SAEPR;;uBAEcM;;cAEPP;WACHC;iBACMG;MACbE;;;;;UAKSI,8BAAAA;;;;;UAKLL;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iBAoIYM,wBAAAA,UAAkCD,0FAA8BE,sBAAAA,CAAiHC,UAAAA,GAAUD,sBAAAA,CAAmCE"}