{"version":3,"file":"promptCaching.d.ts","names":["______types_js0","z","InferInteropZodInput","contextSchema","ZodBoolean","ZodOptional","ZodEnum","ZodNumber","ZodTypeAny","ZodObject","PromptCachingMiddlewareConfig","Partial","anthropicPromptCachingMiddleware","_langchain_core_tools12","ServerTool","ClientTool","AgentMiddleware"],"sources":["../../../../../src/agents/middleware/provider/anthropic/promptCaching.d.ts"],"sourcesContent":["import { z } from \"zod/v3\";\nimport { InferInteropZodInput } from \"@langchain/core/utils/types\";\ndeclare const contextSchema: z.ZodObject<{\n    /**\n     * Whether to enable prompt caching.\n     * @default true\n     */\n    enableCaching: z.ZodOptional<z.ZodBoolean>;\n    /**\n     * The time-to-live for the cached prompt.\n     * @default \"5m\"\n     */\n    ttl: z.ZodOptional<z.ZodEnum<[\"5m\", \"1h\"]>>;\n    /**\n     * The minimum number of messages required before caching is applied.\n     * @default 3\n     */\n    minMessagesToCache: z.ZodOptional<z.ZodNumber>;\n    /**\n     * The behavior to take when an unsupported model is used.\n     * - \"ignore\" will ignore the unsupported model and continue without caching.\n     * - \"warn\" will warn the user and continue without caching.\n     * - \"raise\" will raise an error and stop the agent.\n     * @default \"warn\"\n     */\n    unsupportedModelBehavior: z.ZodOptional<z.ZodEnum<[\"ignore\", \"warn\", \"raise\"]>>;\n}, \"strip\", z.ZodTypeAny, {\n    enableCaching?: boolean | undefined;\n    ttl?: \"1h\" | \"5m\" | undefined;\n    minMessagesToCache?: number | undefined;\n    unsupportedModelBehavior?: \"ignore\" | \"raise\" | \"warn\" | undefined;\n}, {\n    enableCaching?: boolean | undefined;\n    ttl?: \"1h\" | \"5m\" | undefined;\n    minMessagesToCache?: number | undefined;\n    unsupportedModelBehavior?: \"ignore\" | \"raise\" | \"warn\" | undefined;\n}>;\nexport type PromptCachingMiddlewareConfig = Partial<InferInteropZodInput<typeof contextSchema>>;\n/**\n * Creates a prompt caching middleware for Anthropic models to optimize API usage.\n *\n * This middleware automatically adds cache control headers to the last messages when using Anthropic models,\n * enabling their prompt caching feature. This can significantly reduce costs for applications with repetitive\n * prompts, long system messages, or extensive conversation histories.\n *\n * ## How It Works\n *\n * The middleware intercepts model requests and adds cache control metadata that tells Anthropic's\n * API to cache processed prompt prefixes. On subsequent requests with matching prefixes, the\n * cached representations are reused, skipping redundant token processing.\n *\n * ## Benefits\n *\n * - **Cost Reduction**: Avoid reprocessing the same tokens repeatedly (up to 90% savings on cached portions)\n * - **Lower Latency**: Cached prompts are processed faster as embeddings are pre-computed\n * - **Better Scalability**: Reduced computational load enables handling more requests\n * - **Consistent Performance**: Stable response times for repetitive queries\n *\n * @param middlewareOptions - Configuration options for the caching behavior\n * @param middlewareOptions.enableCaching - Whether to enable prompt caching (default: `true`)\n * @param middlewareOptions.ttl - Cache time-to-live: `\"5m\"` for 5 minutes or `\"1h\"` for 1 hour (default: `\"5m\"`)\n * @param middlewareOptions.minMessagesToCache - Minimum number of messages required before caching is applied (default: `3`)\n * @param middlewareOptions.unsupportedModelBehavior - The behavior to take when an unsupported model is used (default: `\"warn\"`)\n *\n * @returns A middleware instance that can be passed to `createAgent`\n *\n * @throws {Error} If used with non-Anthropic models\n *\n * @example\n * Basic usage with default settings\n * ```typescript\n * import { createAgent } from \"langchain\";\n * import { anthropicPromptCachingMiddleware } from \"langchain\";\n *\n * const agent = createAgent({\n *   model: \"anthropic:claude-3-5-sonnet\",\n *   middleware: [\n *     anthropicPromptCachingMiddleware()\n *   ]\n * });\n * ```\n *\n * @example\n * Custom configuration for longer conversations\n * ```typescript\n * const cachingMiddleware = anthropicPromptCachingMiddleware({\n *   ttl: \"1h\",  // Cache for 1 hour instead of default 5 minutes\n *   minMessagesToCache: 5  // Only cache after 5 messages\n * });\n *\n * const agent = createAgent({\n *   model: \"anthropic:claude-3-5-sonnet\",\n *   systemPrompt: \"You are a helpful assistant with deep knowledge of...\", // Long system prompt\n *   middleware: [cachingMiddleware]\n * });\n * ```\n *\n * @example\n * Conditional caching based on runtime context\n * ```typescript\n * const agent = createAgent({\n *   model: \"anthropic:claude-3-5-sonnet\",\n *   middleware: [\n *     anthropicPromptCachingMiddleware({\n *       enableCaching: true,\n *       ttl: \"5m\"\n *     })\n *   ]\n * });\n *\n * // Disable caching for specific requests\n * await agent.invoke(\n *   { messages: [new HumanMessage(\"Process this without caching\")] },\n *   {\n *     configurable: {\n *       middleware_context: { enableCaching: false }\n *     }\n *   }\n * );\n * ```\n *\n * @example\n * Optimal setup for customer support chatbot\n * ```typescript\n * const supportAgent = createAgent({\n *   model: \"anthropic:claude-3-5-sonnet\",\n *   systemPrompt: `You are a customer support agent for ACME Corp.\n *\n *     Company policies:\n *     - Always be polite and professional\n *     - Refer to knowledge base for product information\n *     - Escalate billing issues to human agents\n *     ... (extensive policies and guidelines)\n *   `,\n *   tools: [searchKnowledgeBase, createTicket, checkOrderStatus],\n *   middleware: [\n *     anthropicPromptCachingMiddleware({\n *       ttl: \"1h\",  // Long TTL for stable system prompt\n *       minMessagesToCache: 1  // Cache immediately due to large system prompt\n *     })\n *   ]\n * });\n * ```\n *\n * @remarks\n * - **Anthropic Only**: This middleware only works with Anthropic models and will throw an error if used with other providers\n * - **Automatic Application**: Caching is applied automatically when message count exceeds `minMessagesToCache`\n * - **Cache Scope**: Caches are isolated per API key and cannot be shared across different keys\n * - **TTL Options**: Only supports \"5m\" (5 minutes) and \"1h\" (1 hour) as TTL values per Anthropic's API\n * - **Best Use Cases**: Long system prompts, multi-turn conversations, repetitive queries, RAG applications\n * - **Cost Impact**: Cached tokens are billed at 10% of the base input token price, cache writes are billed at 25% of the base\n *\n * @see {@link createAgent} for agent creation\n * @see {@link https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching} Anthropic's prompt caching documentation\n * @public\n */\nexport declare function anthropicPromptCachingMiddleware(middlewareOptions?: PromptCachingMiddlewareConfig): import(\"../../types.js\").AgentMiddleware<undefined, z.ZodObject<{\n    /**\n     * Whether to enable prompt caching.\n     * @default true\n     */\n    enableCaching: z.ZodOptional<z.ZodBoolean>;\n    /**\n     * The time-to-live for the cached prompt.\n     * @default \"5m\"\n     */\n    ttl: z.ZodOptional<z.ZodEnum<[\"5m\", \"1h\"]>>;\n    /**\n     * The minimum number of messages required before caching is applied.\n     * @default 3\n     */\n    minMessagesToCache: z.ZodOptional<z.ZodNumber>;\n    /**\n     * The behavior to take when an unsupported model is used.\n     * - \"ignore\" will ignore the unsupported model and continue without caching.\n     * - \"warn\" will warn the user and continue without caching.\n     * - \"raise\" will raise an error and stop the agent.\n     * @default \"warn\"\n     */\n    unsupportedModelBehavior: z.ZodOptional<z.ZodEnum<[\"ignore\", \"warn\", \"raise\"]>>;\n}, \"strip\", z.ZodTypeAny, {\n    enableCaching?: boolean | undefined;\n    ttl?: \"1h\" | \"5m\" | undefined;\n    minMessagesToCache?: number | undefined;\n    unsupportedModelBehavior?: \"ignore\" | \"raise\" | \"warn\" | undefined;\n}, {\n    enableCaching?: boolean | undefined;\n    ttl?: \"1h\" | \"5m\" | undefined;\n    minMessagesToCache?: number | undefined;\n    unsupportedModelBehavior?: \"ignore\" | \"raise\" | \"warn\" | undefined;\n}>, {\n    enableCaching?: boolean | undefined;\n    ttl?: \"1h\" | \"5m\" | undefined;\n    minMessagesToCache?: number | undefined;\n    unsupportedModelBehavior?: \"ignore\" | \"raise\" | \"warn\" | undefined;\n}, readonly (import(\"@langchain/core/tools\").ServerTool | import(\"@langchain/core/tools\").ClientTool)[]>;\nexport {};\n//# sourceMappingURL=promptCaching.d.ts.map"],"mappings":";;;;;;cAEcG,eAAeF,CAAAA,CAAEQ;;;;AADoC;EAMhCL,aAAAA,EAAhBH,CAAAA,CAAEI,WAAcD,CAAFH,CAAAA,CAAEG,UAAAA,CAAAA;EAAdC;;;;EAUKA,GAAAA,EALjBJ,CAAAA,CAAEI,WAKeA,CALHJ,CAAAA,CAAEK,OAKCD,CAAAA,CAAAA,IAAAA,EAAAA,IAAAA,CAAAA,CAAAA,CAAAA;EAQoBC;;;;EAvBN,kBAAA,EAehBL,CAAAA,CAAEI,WAfc,CAeFJ,CAAAA,CAAEM,SAfA,CAAA;EAmC5BG;;;;AAAuC;AAuHnD;;EAKmCN,wBAAAA,EAxILH,CAAAA,CAAEI,WAwIGD,CAxISH,CAAAA,CAAEK,OAwIXF,CAAAA,CAAAA,QAAAA,EAAAA,MAAAA,EAAAA,OAAAA,CAAAA,CAAAA,CAAAA;CAAhBH,EAAEI,OAAAA,EAvITJ,CAAAA,CAAEO,UAuIOH,EAAAA;EAKIC,aAAAA,CAAAA,EAAAA,OAAAA,GAAAA,SAAAA;EAAdD,GAAAA,CAAAA,EAAAA,IAAAA,GAAAA,IAAAA,GAAAA,SAAAA;EAK6BE,kBAAAA,CAAAA,EAAAA,MAAAA,GAAAA,SAAAA;EAAdF,wBAAAA,CAAAA,EAAAA,QAAAA,GAAAA,OAAAA,GAAAA,MAAAA,GAAAA,SAAAA;CAQkBJ,EAAEK;EAAdD,aAAAA,CAAAA,EAAAA,OAAAA,GAAAA,SAAAA;EAClBG,GAAAA,CAAAA,EAAAA,IAAAA,GAAAA,IAAAA,GAAAA,SAAAA;EAxBqJC,kBAAAA,CAAAA,EAAAA,MAAAA,GAAAA,SAAAA;EAASI,wBAuC/HC,CAAAA,EAAAA,QAAAA,GAAAA,OAAAA,GAAAA,MAAAA,GAAAA,SAAAA;CAAUD,CAAAA;KA9J3CH,6BAAAA,GAAgCC,QAAQT,4BAA4BC;AAuHqE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iBAA7HS,gCAAAA,qBAAqDF,2DAAoFT,CAAAA,CAAEQ;;;;;iBAKhJR,CAAAA,CAAEI,YAAYJ,CAAAA,CAAEG;;;;;OAK1BH,CAAAA,CAAEI,YAAYJ,CAAAA,CAAEK;;;;;sBAKDL,CAAAA,CAAEI,YAAYJ,CAAAA,CAAEM;;;;;;;;4BAQVN,CAAAA,CAAEI,YAAYJ,CAAAA,CAAEK;YAClCL,CAAAA,CAAEO;;;;;;;;;;;;;;;aAxB8JK,uBAAAA,CAuC/HC,UAAAA,GAAUD,uBAAAA,CAAmCE"}