{"version":3,"file":"llms.d.cts","names":["BasePromptValueInterface","LLMResult","Generation","GenerationChunk","BaseCallbackConfig","CallbackManagerForLLMRun","Callbacks","BaseLanguageModel","BaseLanguageModelCallOptions","BaseLanguageModelInput","BaseLanguageModelParams","RunnableConfig","BaseCache","SerializedLLM","Record","BaseLLMParams","BaseLLMCallOptions","BaseLLM","CallOptions","Exclude","Omit","Partial","Promise","AsyncGenerator","prompts","cache","llmStringKey","parsedOptions","handledOptions","runId","LLM"],"sources":["../../src/language_models/llms.d.ts"],"sourcesContent":["import type { BasePromptValueInterface } from \"../prompt_values.js\";\nimport { type LLMResult, type Generation, GenerationChunk } from \"../outputs.js\";\nimport { type BaseCallbackConfig, type CallbackManagerForLLMRun, type Callbacks } from \"../callbacks/manager.js\";\nimport { BaseLanguageModel, type BaseLanguageModelCallOptions, type BaseLanguageModelInput, type BaseLanguageModelParams } from \"./base.js\";\nimport type { RunnableConfig } from \"../runnables/config.js\";\nimport type { BaseCache } from \"../caches/index.js\";\nexport type SerializedLLM = {\n    _model: string;\n    _type: string;\n} & Record<string, any>;\nexport interface BaseLLMParams extends BaseLanguageModelParams {\n}\nexport interface BaseLLMCallOptions extends BaseLanguageModelCallOptions {\n}\n/**\n * LLM Wrapper. Takes in a prompt (or prompts) and returns a string.\n */\nexport declare abstract class BaseLLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLanguageModel<string, CallOptions> {\n    ParsedCallOptions: Omit<CallOptions, Exclude<keyof RunnableConfig, \"signal\" | \"timeout\" | \"maxConcurrency\">>;\n    lc_namespace: string[];\n    /**\n     * This method takes an input and options, and returns a string. It\n     * converts the input to a prompt value and generates a result based on\n     * the prompt.\n     * @param input Input for the LLM.\n     * @param options Options for the LLM call.\n     * @returns A string result based on the prompt.\n     */\n    invoke(input: BaseLanguageModelInput, options?: Partial<CallOptions>): Promise<string>;\n    _streamResponseChunks(_input: string, _options: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;\n    protected _separateRunnableConfigFromCallOptionsCompat(options?: Partial<CallOptions>): [RunnableConfig, this[\"ParsedCallOptions\"]];\n    _streamIterator(input: BaseLanguageModelInput, options?: Partial<CallOptions>): AsyncGenerator<string>;\n    /**\n     * This method takes prompt values, options, and callbacks, and generates\n     * a result based on the prompts.\n     * @param promptValues Prompt values for the LLM.\n     * @param options Options for the LLM call.\n     * @param callbacks Callbacks for the LLM call.\n     * @returns An LLMResult based on the prompts.\n     */\n    generatePrompt(promptValues: BasePromptValueInterface[], options?: string[] | Partial<CallOptions>, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Run the LLM on the given prompts and input.\n     */\n    abstract _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(_options?: this[\"ParsedCallOptions\"]): any;\n    _flattenLLMResult(llmResult: LLMResult): LLMResult[];\n    /** @ignore */\n    _generateUncached(prompts: string[], parsedOptions: this[\"ParsedCallOptions\"], handledOptions: BaseCallbackConfig, startedRunManagers?: CallbackManagerForLLMRun[]): Promise<LLMResult>;\n    _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }: {\n        prompts: string[];\n        cache: BaseCache<Generation[]>;\n        llmStringKey: string;\n        parsedOptions: any;\n        handledOptions: RunnableConfig;\n        runId?: string;\n    }): Promise<LLMResult & {\n        missingPromptIndices: number[];\n        startedRunManagers?: CallbackManagerForLLMRun[];\n    }>;\n    /**\n     * Run the LLM on the given prompts and input, handling caching.\n     */\n    generate(prompts: string[], options?: string[] | Partial<CallOptions>, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Get the identifying parameters of the LLM.\n     */\n    _identifyingParams(): Record<string, any>;\n    /**\n     * Return the string type key uniquely identifying this class of LLM.\n     */\n    abstract _llmType(): string;\n    _modelType(): string;\n}\n/**\n * LLM class that provides a simpler interface to subclass than {@link BaseLLM}.\n *\n * Requires only implementing a simpler {@link _call} method instead of {@link _generate}.\n *\n * @augments BaseLLM\n */\nexport declare abstract class LLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLLM<CallOptions> {\n    /**\n     * Run the LLM on the given prompt and input.\n     */\n    abstract _call(prompt: string, options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<string>;\n    _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n}\n//# sourceMappingURL=llms.d.ts.map"],"mappings":";;;;;;;;KAMYa,aAAAA;;EAAAA,KAAAA,EAAAA,MAAAA;AAIZ,CAAA,GADIC,MACaC,CAAAA,MAAAA,EAAAA,GAAa,CAAA;AAEbC,UAFAD,aAAAA,SAAsBL,uBAEKF,CAAAA,CAK5C;AAA0DQ,UALzCA,kBAAAA,SAA2BR,4BAKcQ,CAAAA;;;;AACjBG,uBADXF,OACWE,CAAAA,oBADiBH,kBACjBG,GADsCH,kBACtCG,CAAAA,SADkEZ,iBAClEY,CAAAA,MAAAA,EAD4FD,WAC5FC,CAAAA,CAAAA;EAAlBC,iBAAAA,EAAAA,IAAAA,CAAKF,WAALE,EAAkBD,OAAlBC,CAAAA,MAAgCT,cAAhCS,EAAAA,QAAAA,GAAAA,SAAAA,GAAAA,gBAAAA,CAAAA,CAAAA;EAULX,YAAAA,EAAAA,MAAAA,EAAAA;EAA0CS;;;;;;;;EAEiCP,MAAAA,CAAAA,KAAAA,EAF3EF,sBAE2EE,EAAAA,OAAAA,CAAAA,EAFzCU,OAEyCV,CAFjCO,WAEiCP,CAAAA,CAAAA,EAFlBW,OAEkBX,CAAAA,MAAAA,CAAAA;EAClEF,qBAAAA,CAAAA,MAAAA,EAAAA,MAAAA,EAAAA,QAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,WAAAA,CAAAA,EAFkEJ,wBAElEI,CAAAA,EAF6Fc,cAE7Fd,CAF4GN,eAE5GM,CAAAA;EAA0CS,UAAAA,4CAAAA,CAAAA,OAAAA,CAAAA,EADAG,OACAH,CADQA,WACRA,CAAAA,CAAAA,EAAAA,CADwBP,cACxBO,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA;EAARG,eAAAA,CAAAA,KAAAA,EAAlCZ,sBAAkCY,EAAAA,OAAAA,CAAAA,EAAAA,OAAAA,CAAQH,WAARG,CAAAA,CAAAA,EAAuBE,cAAvBF,CAAAA,MAAAA,CAAAA;EAAuBE;;;;;;;;EAa0CtB,cAAAA,CAAAA,YAAAA,EAJ7FD,wBAI6FC,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAJ5CoB,OAI4CpB,CAJpCiB,WAIoCjB,CAAAA,EAAAA,SAAAA,CAAAA,EAJVK,SAIUL,CAAAA,EAJEqB,OAIFrB,CAJUA,SAIVA,CAAAA;EAARqB;;;EAOnBlB,SAAAA,SAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,UAAAA,CAAAA,EAPRC,wBAOQD,CAAAA,EAPmBkB,OAOnBlB,CAP2BH,SAO3BG,CAAAA;EAAyCC;;;EACtHmB,gBAAAA,CAAAA,QAAAA,CAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA,EAAAA,GAAAA;EAASC,iBAAAA,CAAAA,SAAAA,EAHExB,SAGFwB,CAAAA,EAHcxB,SAGdwB,EAAAA;EAAOC;EAAcC,iBAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,aAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,cAAAA,EAD+CvB,kBAC/CuB,EAAAA,kBAAAA,CAAAA,EADwFtB,wBACxFsB,EAAAA,CAAAA,EADqHL,OACrHK,CAD6H1B,SAC7H0B,CAAAA;EAAeC,eAAAA,CAAAA;IAAAA,OAAAA;IAAAA,KAAAA;IAAAA,YAAAA;IAAAA,aAAAA;IAAAA,cAAAA;IAAAA;EAO3DN,CAP2DM,EAAAA;IAAgBC,OAAAA,EAAAA,MAAAA,EAAAA;IAE1D3B,KAAAA,EAAVU,SAAUV,CAAAA,UAAAA,EAAAA,CAAAA;IAAVU,YAAAA,EAAAA,MAAAA;IAGSD,aAAAA,EAAAA,GAAAA;IAERV,cAAAA,EAFQU,cAERV;IAEaI,KAAAA,CAAAA,EAAAA,MAAAA;EAFrBiB,CAAAA,CAAAA,EAAAA,OAAAA,CAAQrB,SAARqB,GAAAA;IAOqDJ,oBAAAA,EAAAA,MAAAA,EAAAA;IAARG,kBAAAA,CAAAA,EALxBhB,wBAKwBgB,EAAAA;EAAkCf,CAAAA,CAAAA;EAAoBL;;;EAjDAM,QAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAiDtDc,OAjDsDd,CAiD9CW,WAjD8CX,CAAAA,EAAAA,SAAAA,CAAAA,EAiDpBD,SAjDoBC,CAAAA,EAiDRe,OAjDQf,CAiDAN,SAjDAM,CAAAA;EAAiB;AAmE5H;;EAA2ES,kBAAAA,CAAAA,CAAAA,EAdjDF,MAciDE,CAAAA,MAAAA,EAAAA,GAAAA,CAAAA;EAAoCE;;;EAK7Bb,SAAAA,QAAAA,CAAAA,CAAAA,EAAAA,MAAAA;EAAmCJ,UAAAA,CAAAA,CAAAA,EAAAA,MAAAA;;;AALP;;;;;;uBAAhF6B,wBAAwBd,qBAAqBA,4BAA4BC,QAAQC;;;;kFAI3Bb,2BAA2BiB;gFAC7BjB,2BAA2BiB,QAAQrB"}