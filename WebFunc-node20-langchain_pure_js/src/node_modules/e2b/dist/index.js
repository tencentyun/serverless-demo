"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __knownSymbol = (name, symbol) => (symbol = Symbol[name]) ? symbol : Symbol.for("Symbol." + name);
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __objRest = (source, exclude) => {
  var target = {};
  for (var prop in source)
    if (__hasOwnProp.call(source, prop) && exclude.indexOf(prop) < 0)
      target[prop] = source[prop];
  if (source != null && __getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(source)) {
      if (exclude.indexOf(prop) < 0 && __propIsEnum.call(source, prop))
        target[prop] = source[prop];
    }
  return target;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __await = function(promise, isYieldStar) {
  this[0] = promise;
  this[1] = isYieldStar;
};
var __asyncGenerator = (__this, __arguments, generator) => {
  var resume = (k, v, yes, no) => {
    try {
      var x = generator[k](v), isAwait = (v = x.value) instanceof __await, done = x.done;
      Promise.resolve(isAwait ? v[0] : v).then((y) => isAwait ? resume(k === "return" ? k : "next", v[1] ? { done: y.done, value: y.value } : y, yes, no) : yes({ value: y, done })).catch((e) => resume("throw", e, yes, no));
    } catch (e) {
      no(e);
    }
  }, method = (k) => it[k] = (x) => new Promise((yes, no) => resume(k, x, yes, no)), it = {};
  return generator = generator.apply(__this, __arguments), it[__knownSymbol("asyncIterator")] = () => it, method("next"), method("throw"), method("return"), it;
};
var __forAwait = (obj, it, method) => (it = obj[__knownSymbol("asyncIterator")]) ? it.call(obj) : (obj = obj[__knownSymbol("iterator")](), it = {}, method = (key, fn) => (fn = obj[key]) && (it[key] = (arg) => new Promise((yes, no, done) => (arg = fn.call(obj, arg), done = arg.done, Promise.resolve(arg.value).then((value) => yes({ value, done }), no)))), method("next"), method("return"), it);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  ALL_TRAFFIC: () => ALL_TRAFFIC,
  ApiClient: () => ApiClient,
  AuthenticationError: () => AuthenticationError,
  BuildError: () => BuildError,
  CommandExitError: () => CommandExitError,
  ConnectionConfig: () => ConnectionConfig,
  FileType: () => FileType2,
  FileUploadError: () => FileUploadError,
  FilesystemEventType: () => FilesystemEventType,
  Git: () => Git,
  GitAuthError: () => GitAuthError,
  GitUpstreamError: () => GitUpstreamError,
  InvalidArgumentError: () => InvalidArgumentError,
  LogEntry: () => LogEntry,
  LogEntryEnd: () => LogEntryEnd,
  LogEntryStart: () => LogEntryStart,
  NotEnoughSpaceError: () => NotEnoughSpaceError,
  NotFoundError: () => NotFoundError,
  RateLimitError: () => RateLimitError,
  ReadyCmd: () => ReadyCmd,
  Sandbox: () => Sandbox,
  SandboxError: () => SandboxError,
  Template: () => Template,
  TemplateBase: () => TemplateBase,
  TemplateError: () => TemplateError,
  TimeoutError: () => TimeoutError,
  default: () => src_default,
  defaultBuildLogger: () => defaultBuildLogger,
  getSignature: () => getSignature,
  waitForFile: () => waitForFile,
  waitForPort: () => waitForPort,
  waitForProcess: () => waitForProcess,
  waitForTimeout: () => waitForTimeout,
  waitForURL: () => waitForURL
});
module.exports = __toCommonJS(src_exports);

// src/api/index.ts
var import_openapi_fetch = __toESM(require("openapi-fetch"));

// src/api/metadata.ts
var import_platform2 = __toESM(require("platform"));

// package.json
var version = "2.12.0";

// src/utils.ts
var import_platform = __toESM(require("platform"));
function getRuntime() {
  var _a3, _b, _c;
  if (globalThis.Bun) {
    return { runtime: "bun", version: globalThis.Bun.version };
  }
  if (globalThis.Deno) {
    return { runtime: "deno", version: globalThis.Deno.version.deno };
  }
  if (((_b = (_a3 = globalThis.process) == null ? void 0 : _a3.release) == null ? void 0 : _b.name) === "node") {
    return { runtime: "node", version: import_platform.default.version || "unknown" };
  }
  if (typeof EdgeRuntime === "string") {
    return { runtime: "vercel-edge", version: "unknown" };
  }
  if (((_c = globalThis.navigator) == null ? void 0 : _c.userAgent) === "Cloudflare-Workers") {
    return { runtime: "cloudflare-worker", version: "unknown" };
  }
  if (typeof window !== "undefined") {
    return { runtime: "browser", version: import_platform.default.version || "unknown" };
  }
  return { runtime: "unknown", version: "unknown" };
}
var { runtime, version: runtimeVersion } = getRuntime();
async function sha256(data) {
  if (typeof crypto !== "undefined") {
    const encoder = new TextEncoder();
    const dataBuffer = encoder.encode(data);
    const hashBuffer = await crypto.subtle.digest("SHA-256", dataBuffer);
    const hashArray = new Uint8Array(hashBuffer);
    return btoa(String.fromCharCode(...hashArray));
  }
  const { createHash } = require("crypto");
  const hash = createHash("sha256").update(data, "utf8").digest();
  return hash.toString("base64");
}
function timeoutToSeconds(timeout) {
  return Math.ceil(timeout / 1e3);
}
function dynamicRequire(module2) {
  if (runtime === "browser") {
    throw new Error("Browser runtime is not supported for require");
  }
  return require(module2);
}
async function dynamicImport(module2) {
  if (runtime === "browser") {
    throw new Error("Browser runtime is not supported for dynamic import");
  }
  return await import(module2);
}
function ansiRegex({ onlyFirst = false } = {}) {
  const ST = "(?:\\u0007|\\u001B\\u005C|\\u009C)";
  const osc = `(?:\\u001B\\][\\s\\S]*?${ST})`;
  const csi = "[\\u001B\\u009B][[\\]()#;?]*(?:\\d{1,4}(?:[;:]\\d{0,4})*)?[\\dA-PR-TZcf-nq-uy=><~]";
  const pattern = `${osc}|${csi}`;
  return new RegExp(pattern, onlyFirst ? void 0 : "g");
}
function stripAnsi(text) {
  return text.replace(ansiRegex(), "");
}
function toBlob(data) {
  if (data instanceof Blob) {
    return data;
  }
  if (typeof data === "string" || data instanceof ArrayBuffer) {
    return new Blob([data]);
  }
  return new Response(data).blob();
}

// src/api/metadata.ts
var _a;
var defaultHeaders = {
  browser: typeof window !== "undefined" && import_platform2.default.name || "unknown",
  lang: "js",
  lang_version: runtimeVersion,
  package_version: version,
  publisher: "e2b",
  sdk_runtime: runtime,
  system: ((_a = import_platform2.default.os) == null ? void 0 : _a.family) || "unknown"
};
function getEnvVar(name) {
  if (runtime === "deno") {
    return Deno.env.get(name);
  }
  if (typeof process === "undefined") {
    return "";
  }
  return process.env[name];
}

// src/errors.ts
function formatSandboxTimeoutError(message) {
  return new TimeoutError(
    `${message}: This error is likely due to sandbox timeout. You can modify the sandbox timeout by passing 'timeoutMs' when starting the sandbox or calling '.setTimeout' on the sandbox with the desired timeout.`
  );
}
var SandboxError = class extends Error {
  constructor(message, stackTrace) {
    super(message);
    this.name = "SandboxError";
    if (stackTrace) {
      this.stack = stackTrace;
    }
  }
};
var TimeoutError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "TimeoutError";
  }
};
var InvalidArgumentError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "InvalidArgumentError";
  }
};
var NotEnoughSpaceError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "NotEnoughSpaceError";
  }
};
var NotFoundError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "NotFoundError";
  }
};
var AuthenticationError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "AuthenticationError";
  }
};
var GitAuthError = class extends AuthenticationError {
  constructor(message) {
    super(message);
    this.name = "GitAuthError";
  }
};
var GitUpstreamError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "GitUpstreamError";
  }
};
var TemplateError = class extends SandboxError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "TemplateError";
  }
};
var RateLimitError = class extends SandboxError {
  constructor(message) {
    super(message);
    this.name = "RateLimitError";
  }
};
var BuildError = class extends Error {
  constructor(message, stackTrace) {
    super(message);
    this.name = "BuildError";
    if (stackTrace) {
      this.stack = stackTrace;
    }
  }
};
var FileUploadError = class extends BuildError {
  constructor(message, stackTrace) {
    super(message, stackTrace);
    this.name = "FileUploadError";
  }
};

// src/logs.ts
function formatLog(log) {
  return JSON.parse(JSON.stringify(log));
}
function createRpcLogger(logger) {
  function logEach(stream) {
    return __asyncGenerator(this, null, function* () {
      var _a3;
      try {
        for (var iter = __forAwait(stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const m = temp.value;
          (_a3 = logger.debug) == null ? void 0 : _a3.call(logger, "Response stream:", formatLog(m));
          yield m;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
    });
  }
  return (next) => async (req) => {
    var _a3, _b;
    (_a3 = logger.info) == null ? void 0 : _a3.call(logger, `Request: POST ${req.url}`);
    const res = await next(req);
    if (res.stream) {
      return __spreadProps(__spreadValues({}, res), {
        message: logEach(res.message)
      });
    } else {
      (_b = logger.info) == null ? void 0 : _b.call(logger, "Response:", formatLog(res.message));
    }
    return res;
  };
}
function createApiLogger(logger) {
  return {
    async onRequest({ request }) {
      var _a3;
      (_a3 = logger.info) == null ? void 0 : _a3.call(logger, `Request ${request.method} ${request.url}`);
      return request;
    },
    async onResponse({ response }) {
      var _a3, _b;
      if (response.status >= 400) {
        (_a3 = logger.error) == null ? void 0 : _a3.call(logger, "Response:", response.status, response.statusText);
      } else {
        (_b = logger.info) == null ? void 0 : _b.call(logger, "Response:", response.status, response.statusText);
      }
      return response;
    }
  };
}

// src/api/index.ts
function handleApiError(response, errorClass = SandboxError, stackTrace) {
  var _a3, _b, _c, _d, _e, _f;
  if (!response.error) {
    return;
  }
  if (response.response.status === 401) {
    const message2 = "Unauthorized, please check your credentials.";
    const content = (_b = (_a3 = response.error) == null ? void 0 : _a3.message) != null ? _b : response.error;
    if (content) {
      return new AuthenticationError(`${message2} - ${content}`);
    }
    return new AuthenticationError(message2);
  }
  if (response.response.status === 429) {
    const message2 = "Rate limit exceeded, please try again later";
    const content = (_d = (_c = response.error) == null ? void 0 : _c.message) != null ? _d : response.error;
    if (content) {
      return new RateLimitError(`${message2} - ${content}`);
    }
    return new RateLimitError(message2);
  }
  const message = (_f = (_e = response.error) == null ? void 0 : _e.message) != null ? _f : response.error;
  return new errorClass(`${response.response.status}: ${message}`, stackTrace);
}
var ApiClient = class {
  constructor(config, opts = { requireAccessToken: false, requireApiKey: false }) {
    if ((opts == null ? void 0 : opts.requireApiKey) && !config.apiKey) {
      throw new AuthenticationError(
        "API key is required, please visit the Team tab at https://e2b.dev/dashboard to get your API key. You can either set the environment variable `E2B_API_KEY` or you can pass it directly to the sandbox like Sandbox.create({ apiKey: 'e2b_...' })"
      );
    }
    if ((opts == null ? void 0 : opts.requireAccessToken) && !config.accessToken) {
      throw new AuthenticationError(
        "Access token is required, please visit the Personal tab at https://e2b.dev/dashboard to get your access token. You can set the environment variable `E2B_ACCESS_TOKEN` or pass the `accessToken` in options."
      );
    }
    this.api = (0, import_openapi_fetch.default)({
      baseUrl: config.apiUrl,
      // keepalive: true, // TODO: Return keepalive
      headers: __spreadValues(__spreadValues(__spreadValues(__spreadValues({}, defaultHeaders), config.apiKey && { "X-API-KEY": config.apiKey }), config.accessToken && {
        Authorization: `Bearer ${config.accessToken}`
      }), config.headers),
      querySerializer: {
        array: {
          style: "form",
          explode: false
        }
      }
    });
    if (config.logger) {
      this.api.use(createApiLogger(config.logger));
    }
  }
};

// src/connectionConfig.ts
var REQUEST_TIMEOUT_MS = 6e4;
var DEFAULT_SANDBOX_TIMEOUT_MS = 3e5;
var KEEPALIVE_PING_INTERVAL_SEC = 50;
var KEEPALIVE_PING_HEADER = "Keepalive-Ping-Interval";
var _ConnectionConfig = class _ConnectionConfig {
  constructor(opts) {
    var _a3;
    this.apiKey = (opts == null ? void 0 : opts.apiKey) || _ConnectionConfig.apiKey;
    this.debug = (opts == null ? void 0 : opts.debug) || _ConnectionConfig.debug;
    this.domain = (opts == null ? void 0 : opts.domain) || _ConnectionConfig.domain;
    this.accessToken = (opts == null ? void 0 : opts.accessToken) || _ConnectionConfig.accessToken;
    this.requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : REQUEST_TIMEOUT_MS;
    this.logger = opts == null ? void 0 : opts.logger;
    this.headers = (opts == null ? void 0 : opts.headers) || {};
    this.headers["User-Agent"] = `e2b-js-sdk/${version}`;
    this.apiUrl = (opts == null ? void 0 : opts.apiUrl) || _ConnectionConfig.apiUrl || (this.debug ? "http://localhost:3000" : `https://api.${this.domain}`);
    this.sandboxUrl = (opts == null ? void 0 : opts.sandboxUrl) || _ConnectionConfig.sandboxUrl;
  }
  static get domain() {
    return getEnvVar("E2B_DOMAIN") || "e2b.app";
  }
  static get apiUrl() {
    return getEnvVar("E2B_API_URL");
  }
  static get sandboxUrl() {
    return getEnvVar("E2B_SANDBOX_URL");
  }
  static get debug() {
    return (getEnvVar("E2B_DEBUG") || "false").toLowerCase() === "true";
  }
  static get apiKey() {
    return getEnvVar("E2B_API_KEY");
  }
  static get accessToken() {
    return getEnvVar("E2B_ACCESS_TOKEN");
  }
  getSignal(requestTimeoutMs) {
    const timeout = requestTimeoutMs != null ? requestTimeoutMs : this.requestTimeoutMs;
    return timeout ? AbortSignal.timeout(timeout) : void 0;
  }
  getSandboxUrl(sandboxId, opts) {
    if (this.sandboxUrl) {
      return this.sandboxUrl;
    }
    return `${this.debug ? "http" : "https"}://${this.getHost(sandboxId, opts.envdPort, opts.sandboxDomain)}`;
  }
  getHost(sandboxId, port, sandboxDomain) {
    if (this.debug) {
      return `localhost:${port}`;
    }
    return `${port}-${sandboxId}.${sandboxDomain != null ? sandboxDomain : this.domain}`;
  }
};
_ConnectionConfig.envdPort = 49983;
var ConnectionConfig = _ConnectionConfig;
var defaultUsername = "user";

// src/sandbox/signature.ts
async function getSignature({
  path: path2,
  operation,
  user,
  expirationInSeconds,
  envdAccessToken
}) {
  if (!envdAccessToken) {
    throw new Error(
      "Access token is not set and signature cannot be generated!"
    );
  }
  const signatureExpiration = expirationInSeconds ? Math.floor(Date.now() / 1e3) + expirationInSeconds : null;
  let signatureRaw;
  if (user == void 0) {
    user = "";
  }
  if (signatureExpiration === null) {
    signatureRaw = `${path2}:${operation}:${user}:${envdAccessToken}`;
  } else {
    signatureRaw = `${path2}:${operation}:${user}:${envdAccessToken}:${signatureExpiration.toString()}`;
  }
  const hashBase64 = await sha256(signatureRaw);
  const signature = "v1_" + hashBase64.replace(/=+$/, "");
  return {
    signature,
    expiration: signatureExpiration
  };
}

// src/sandbox/filesystem/index.ts
var import_connect3 = require("@connectrpc/connect");

// src/envd/api.ts
var import_openapi_fetch2 = __toESM(require("openapi-fetch"));
var import_connect = require("@connectrpc/connect");
async function handleEnvdApiError(res) {
  var _a3;
  if (!res.error) {
    return;
  }
  const message = typeof res.error == "string" ? res.error : ((_a3 = res.error) == null ? void 0 : _a3.message) || await res.response.text();
  switch (res.response.status) {
    case 400:
      return new InvalidArgumentError(message);
    case 401:
      return new AuthenticationError(message);
    case 404:
      return new NotFoundError(message);
    case 429:
      return new SandboxError(
        `${res.response.status}: ${message}: The requests are being rate limited.`
      );
    case 502:
      return formatSandboxTimeoutError(message);
    case 507:
      return new NotEnoughSpaceError(message);
    default:
      return new SandboxError(`${res.response.status}: ${message}`);
  }
}
async function handleProcessStartEvent(events) {
  var _a3;
  let startEvent;
  try {
    startEvent = (await events[Symbol.asyncIterator]().next()).value;
  } catch (err) {
    if (err instanceof import_connect.ConnectError) {
      if (err.code === import_connect.Code.Unavailable) {
        throw new NotFoundError("Sandbox is probably not running anymore");
      }
    }
    throw err;
  }
  if (((_a3 = startEvent.event) == null ? void 0 : _a3.event.case) !== "start") {
    throw new Error("Expected start event");
  }
  return startEvent.event.event.value.pid;
}
async function handleWatchDirStartEvent(events) {
  var _a3;
  let startEvent;
  try {
    startEvent = (await events[Symbol.asyncIterator]().next()).value;
  } catch (err) {
    if (err instanceof import_connect.ConnectError) {
      if (err.code === import_connect.Code.Unavailable) {
        throw new NotFoundError("Sandbox is probably not running anymore");
      }
    }
    throw err;
  }
  if (((_a3 = startEvent.event) == null ? void 0 : _a3.case) !== "start") {
    throw new Error("Expected start event");
  }
  return startEvent.event.value;
}
var EnvdApiClient = class {
  constructor(config, metadata) {
    this.api = (0, import_openapi_fetch2.default)({
      baseUrl: config.apiUrl,
      fetch: config == null ? void 0 : config.fetch,
      headers: config == null ? void 0 : config.headers
      // keepalive: true, // TODO: Return keepalive
    });
    this.version = metadata.version;
    if (config.logger) {
      this.api.use(createApiLogger(config.logger));
    }
  }
};

// src/envd/rpc.ts
var import_connect2 = require("@connectrpc/connect");
var import_compare_versions = require("compare-versions");

// src/envd/versions.ts
var ENVD_VERSION_RECURSIVE_WATCH = "0.1.4";
var ENVD_DEBUG_FALLBACK = "99.99.99";
var ENVD_COMMANDS_STDIN = "0.3.0";
var ENVD_DEFAULT_USER = "0.4.0";

// src/envd/rpc.ts
function handleRpcError(err) {
  if (err instanceof import_connect2.ConnectError) {
    switch (err.code) {
      case import_connect2.Code.InvalidArgument:
        return new InvalidArgumentError(err.message);
      case import_connect2.Code.Unauthenticated:
        return new AuthenticationError(err.message);
      case import_connect2.Code.NotFound:
        return new NotFoundError(err.message);
      case import_connect2.Code.Unavailable:
        return formatSandboxTimeoutError(err.message);
      case import_connect2.Code.Canceled:
        return new TimeoutError(
          `${err.message}: This error is likely due to exceeding 'requestTimeoutMs'. You can pass the request timeout value as an option when making the request.`
        );
      case import_connect2.Code.DeadlineExceeded:
        return new TimeoutError(
          `${err.message}: This error is likely due to exceeding 'timeoutMs' \u2014 the total time a long running request (like command execution or directory watch) can be active. It can be modified by passing 'timeoutMs' when making the request. Use '0' to disable the timeout.`
        );
      default:
        return new SandboxError(`${err.code}: ${err.message}`);
    }
  }
  return err;
}
function encode64(value) {
  switch (runtime) {
    case "deno":
      return btoa(value);
    case "node":
      return Buffer.from(value).toString("base64");
    case "bun":
      return Buffer.from(value).toString("base64");
    default:
      return btoa(value);
  }
}
function authenticationHeader(envdVersion, username) {
  if (username == void 0 && (0, import_compare_versions.compareVersions)(envdVersion, ENVD_DEFAULT_USER) < 0) {
    username = defaultUsername;
  }
  if (!username) {
    return {};
  }
  const value = `${username}:`;
  const encoded = encode64(value);
  return { Authorization: `Basic ${encoded}` };
}

// src/envd/filesystem/filesystem_pb.ts
var import_codegenv2 = require("@bufbuild/protobuf/codegenv2");
var import_wkt = require("@bufbuild/protobuf/wkt");
var file_filesystem_filesystem = /* @__PURE__ */ (0, import_codegenv2.fileDesc)(
  "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",
  [import_wkt.file_google_protobuf_timestamp]
);
var Filesystem = /* @__PURE__ */ (0, import_codegenv2.serviceDesc)(file_filesystem_filesystem, 0);

// src/sandbox/filesystem/watchHandle.ts
var FilesystemEventType = /* @__PURE__ */ ((FilesystemEventType2) => {
  FilesystemEventType2["CHMOD"] = "chmod";
  FilesystemEventType2["CREATE"] = "create";
  FilesystemEventType2["REMOVE"] = "remove";
  FilesystemEventType2["RENAME"] = "rename";
  FilesystemEventType2["WRITE"] = "write";
  return FilesystemEventType2;
})(FilesystemEventType || {});
function mapEventType(type) {
  switch (type) {
    case 5 /* CHMOD */:
      return "chmod" /* CHMOD */;
    case 1 /* CREATE */:
      return "create" /* CREATE */;
    case 3 /* REMOVE */:
      return "remove" /* REMOVE */;
    case 4 /* RENAME */:
      return "rename" /* RENAME */;
    case 2 /* WRITE */:
      return "write" /* WRITE */;
  }
}
var WatchHandle = class {
  constructor(handleStop, events, onEvent, onExit) {
    this.handleStop = handleStop;
    this.events = events;
    this.onEvent = onEvent;
    this.onExit = onExit;
    this.handleEvents();
  }
  /**
   * Stop watching the directory.
   */
  async stop() {
    this.handleStop();
  }
  iterateEvents() {
    return __asyncGenerator(this, null, function* () {
      try {
        try {
          for (var iter = __forAwait(this.events), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
            const event = temp.value;
            switch (event.event.case) {
              case "filesystem":
                yield event.event;
                break;
            }
          }
        } catch (temp) {
          error = [temp];
        } finally {
          try {
            more && (temp = iter.return) && (yield new __await(temp.call(iter)));
          } finally {
            if (error)
              throw error[0];
          }
        }
      } catch (err) {
        throw handleRpcError(err);
      }
    });
  }
  async handleEvents() {
    var _a3, _b, _c;
    try {
      try {
        for (var iter = __forAwait(this.iterateEvents()), more, temp, error; more = !(temp = await iter.next()).done; more = false) {
          const event = temp.value;
          const eventType = mapEventType(event.value.type);
          if (eventType === void 0) {
            continue;
          }
          (_a3 = this.onEvent) == null ? void 0 : _a3.call(this, {
            name: event.value.name,
            type: eventType
          });
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && await temp.call(iter);
        } finally {
          if (error)
            throw error[0];
        }
      }
      (_b = this.onExit) == null ? void 0 : _b.call(this);
    } catch (err) {
      (_c = this.onExit) == null ? void 0 : _c.call(this, err);
    }
  }
};

// src/sandbox/filesystem/index.ts
var import_compare_versions2 = require("compare-versions");
var FileType2 = /* @__PURE__ */ ((FileType3) => {
  FileType3["FILE"] = "file";
  FileType3["DIR"] = "dir";
  return FileType3;
})(FileType2 || {});
function mapFileType(fileType) {
  switch (fileType) {
    case 2 /* DIRECTORY */:
      return "dir" /* DIR */;
    case 1 /* FILE */:
      return "file" /* FILE */;
  }
}
function mapModifiedTime(modifiedTime) {
  if (!modifiedTime) return void 0;
  return new Date(
    Number(modifiedTime.seconds) * 1e3 + Math.floor(modifiedTime.nanos / 1e6)
  );
}
var Filesystem2 = class {
  constructor(transport, envdApi, connectionConfig) {
    this.envdApi = envdApi;
    this.connectionConfig = connectionConfig;
    this.defaultWatchTimeout = 6e4;
    // 60 seconds
    this.defaultWatchRecursive = false;
    this.rpc = (0, import_connect3.createClient)(Filesystem, transport);
  }
  async read(path2, opts) {
    var _a3;
    const format = (_a3 = opts == null ? void 0 : opts.format) != null ? _a3 : "text";
    let user = opts == null ? void 0 : opts.user;
    if (user == void 0 && (0, import_compare_versions2.compareVersions)(this.envdApi.version, ENVD_DEFAULT_USER) < 0) {
      user = defaultUsername;
    }
    const res = await this.envdApi.api.GET("/files", {
      params: {
        query: {
          path: path2,
          username: user
        }
      },
      parseAs: format === "bytes" ? "arrayBuffer" : format,
      signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    const err = await handleEnvdApiError(res);
    if (err) {
      throw err;
    }
    if (format === "bytes") {
      return new Uint8Array(res.data);
    }
    if (res.response.headers.get("content-length") === "0") {
      return "";
    }
    return res.data;
  }
  async write(pathOrFiles, dataOrOpts, opts) {
    if (typeof pathOrFiles !== "string" && !Array.isArray(pathOrFiles)) {
      throw new Error("Path or files are required");
    }
    if (typeof pathOrFiles === "string" && Array.isArray(dataOrOpts)) {
      throw new Error(
        "Cannot specify both path and array of files. You have to specify either path and data for a single file or an array for multiple files."
      );
    }
    const { path: path2, writeOpts, writeFiles } = typeof pathOrFiles === "string" ? {
      path: pathOrFiles,
      writeOpts: opts,
      writeFiles: [
        {
          data: dataOrOpts
        }
      ]
    } : {
      path: void 0,
      writeOpts: dataOrOpts,
      writeFiles: pathOrFiles
    };
    if (writeFiles.length === 0) return [];
    const formData = new FormData();
    for (let i = 0; i < writeFiles.length; i++) {
      const file = writeFiles[i];
      formData.append("file", await toBlob(file.data), writeFiles[i].path);
    }
    let user = writeOpts == null ? void 0 : writeOpts.user;
    if (user == void 0 && (0, import_compare_versions2.compareVersions)(this.envdApi.version, ENVD_DEFAULT_USER) < 0) {
      user = defaultUsername;
    }
    const res = await this.envdApi.api.POST("/files", {
      params: {
        query: {
          path: path2,
          username: user
        }
      },
      bodySerializer: () => formData,
      signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs),
      body: {}
    });
    const err = await handleEnvdApiError(res);
    if (err) {
      throw err;
    }
    const files = res.data;
    if (!files) {
      throw new Error("Expected to receive information about written file");
    }
    return files.length === 1 && path2 ? files[0] : files;
  }
  /**
   * Write multiple files.
   *
   *
   * Writing to a file that doesn't exist creates the file.
   *
   * Writing to a file that already exists overwrites the file.
   *
   * Writing to a file at path that doesn't exist creates the necessary directories.
   *
   * @param files list of files to write as `WriteEntry` objects, each containing `path` and `data`.
   * @param opts connection options.
   *
   * @returns information about the written files
   */
  async writeFiles(files, opts) {
    return this.write(files, opts);
  }
  /**
   * List entries in a directory.
   *
   * @param path path to the directory.
   * @param opts connection options.
   *
   * @returns list of entries in the sandbox filesystem directory.
   */
  async list(path2, opts) {
    var _a3;
    if (typeof (opts == null ? void 0 : opts.depth) === "number" && opts.depth < 1) {
      throw new InvalidArgumentError("depth should be at least one");
    }
    try {
      const res = await this.rpc.listDir(
        {
          path: path2,
          depth: (_a3 = opts == null ? void 0 : opts.depth) != null ? _a3 : 1
        },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      const entries = [];
      for (const e of res.entries) {
        const type = mapFileType(e.type);
        if (type) {
          entries.push({
            name: e.name,
            type,
            path: e.path,
            size: Number(e.size),
            mode: e.mode,
            permissions: e.permissions,
            owner: e.owner,
            group: e.group,
            modifiedTime: mapModifiedTime(e.modifiedTime),
            symlinkTarget: e.symlinkTarget
          });
        }
      }
      return entries;
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Create a new directory and all directories along the way if needed on the specified path.
   *
   * @param path path to a new directory. For example '/dirA/dirB' when creating 'dirB'.
   * @param opts connection options.
   *
   * @returns `true` if the directory was created, `false` if it already exists.
   */
  async makeDir(path2, opts) {
    try {
      await this.rpc.makeDir(
        { path: path2 },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      return true;
    } catch (err) {
      if (err instanceof import_connect3.ConnectError) {
        if (err.code === import_connect3.Code.AlreadyExists) {
          return false;
        }
      }
      throw handleRpcError(err);
    }
  }
  /**
   * Rename a file or directory.
   *
   * @param oldPath path to the file or directory to rename.
   * @param newPath new path for the file or directory.
   * @param opts connection options.
   *
   * @returns information about renamed file or directory.
   */
  async rename(oldPath, newPath, opts) {
    try {
      const res = await this.rpc.move(
        {
          source: oldPath,
          destination: newPath
        },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      const entry = res.entry;
      if (!entry) {
        throw new Error("Expected to receive information about moved object");
      }
      return {
        name: entry.name,
        type: mapFileType(entry.type),
        path: entry.path,
        size: Number(entry.size),
        mode: entry.mode,
        permissions: entry.permissions,
        owner: entry.owner,
        group: entry.group,
        modifiedTime: mapModifiedTime(entry.modifiedTime),
        symlinkTarget: entry.symlinkTarget
      };
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Remove a file or directory.
   *
   * @param path path to a file or directory.
   * @param opts connection options.
   */
  async remove(path2, opts) {
    try {
      await this.rpc.remove(
        { path: path2 },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Check if a file or a directory exists.
   *
   * @param path path to a file or a directory
   * @param opts connection options.
   *
   * @returns `true` if the file or directory exists, `false` otherwise
   */
  async exists(path2, opts) {
    try {
      await this.rpc.stat(
        { path: path2 },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      return true;
    } catch (err) {
      if (err instanceof import_connect3.ConnectError) {
        if (err.code === import_connect3.Code.NotFound) {
          return false;
        }
      }
      throw handleRpcError(err);
    }
  }
  /**
   * Get information about a file or directory.
   *
   * @param path path to a file or directory.
   * @param opts connection options.
   *
   * @returns information about the file or directory like name, type, and path.
   */
  async getInfo(path2, opts) {
    try {
      const res = await this.rpc.stat(
        { path: path2 },
        {
          headers: authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user),
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      if (!res.entry) {
        throw new Error(
          "Expected to receive information about the file or directory"
        );
      }
      return {
        name: res.entry.name,
        type: mapFileType(res.entry.type),
        path: res.entry.path,
        size: Number(res.entry.size),
        mode: res.entry.mode,
        permissions: res.entry.permissions,
        owner: res.entry.owner,
        group: res.entry.group,
        modifiedTime: mapModifiedTime(res.entry.modifiedTime),
        symlinkTarget: res.entry.symlinkTarget
      };
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Start watching a directory for filesystem events.
   *
   * @param path path to directory to watch.
   * @param onEvent callback to call when an event in the directory occurs.
   * @param opts connection options.
   *
   * @returns `WatchHandle` object for stopping watching directory.
   */
  async watchDir(path2, onEvent, opts) {
    var _a3, _b, _c;
    if ((opts == null ? void 0 : opts.recursive) && this.envdApi.version && (0, import_compare_versions2.compareVersions)(this.envdApi.version, ENVD_VERSION_RECURSIVE_WATCH) < 0) {
      throw new TemplateError(
        "You need to update the template to use recursive watching. You can do this by running `e2b template build` in the directory with the template."
      );
    }
    const requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : this.connectionConfig.requestTimeoutMs;
    const controller = new AbortController();
    const reqTimeout = requestTimeoutMs ? setTimeout(() => {
      controller.abort();
    }, requestTimeoutMs) : void 0;
    const events = this.rpc.watchDir(
      {
        path: path2,
        recursive: (_b = opts == null ? void 0 : opts.recursive) != null ? _b : this.defaultWatchRecursive
      },
      {
        headers: __spreadProps(__spreadValues({}, authenticationHeader(this.envdApi.version, opts == null ? void 0 : opts.user)), {
          [KEEPALIVE_PING_HEADER]: KEEPALIVE_PING_INTERVAL_SEC.toString()
        }),
        signal: controller.signal,
        timeoutMs: (_c = opts == null ? void 0 : opts.timeoutMs) != null ? _c : this.defaultWatchTimeout
      }
    );
    try {
      await handleWatchDirStartEvent(events);
      clearTimeout(reqTimeout);
      return new WatchHandle(
        () => controller.abort(),
        events,
        onEvent,
        opts == null ? void 0 : opts.onExit
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
};

// src/sandbox/commands/commandHandle.ts
var CommandExitError = class extends SandboxError {
  constructor(result) {
    super(result.error);
    this.result = result;
    this.name = "CommandExitError";
  }
  /**
   * Command execution exit code.
   * `0` if the command finished successfully.
   */
  get exitCode() {
    return this.result.exitCode;
  }
  /**
   * Error message from command execution.
   */
  get error() {
    return this.result.error;
  }
  /**
   * Command execution stdout output.
   */
  get stdout() {
    return this.result.stdout;
  }
  /**
   * Command execution stderr output.
   */
  get stderr() {
    return this.result.stderr;
  }
};
var CommandHandle = class {
  /**
   * @hidden
   * @internal
   * @access protected
   */
  constructor(pid, handleDisconnect, handleKill, events, onStdout, onStderr, onPty) {
    this.pid = pid;
    this.handleDisconnect = handleDisconnect;
    this.handleKill = handleKill;
    this.events = events;
    this.onStdout = onStdout;
    this.onStderr = onStderr;
    this.onPty = onPty;
    this._stdout = "";
    this._stderr = "";
    this._wait = this.handleEvents();
  }
  /**
   * Command execution exit code.
   * `0` if the command finished successfully.
   *
   * It is `undefined` if the command is still running.
   */
  get exitCode() {
    var _a3;
    return (_a3 = this.result) == null ? void 0 : _a3.exitCode;
  }
  /**
   * Error message from command execution.
   */
  get error() {
    var _a3;
    return (_a3 = this.result) == null ? void 0 : _a3.error;
  }
  /**
   * Command execution stderr output.
   */
  get stderr() {
    return this._stderr;
  }
  /**
   * Command execution stdout output.
   */
  get stdout() {
    return this._stdout;
  }
  /**
   * Wait for the command to finish and return the result.
   * If the command exits with a non-zero exit code, it throws a `CommandExitError`.
   *
   * @returns `CommandResult` result of command execution.
   */
  async wait() {
    await this._wait;
    if (this.iterationError) {
      throw this.iterationError;
    }
    if (!this.result) {
      throw new SandboxError("Process exited without a result");
    }
    if (this.result.exitCode !== 0) {
      throw new CommandExitError(this.result);
    }
    return this.result;
  }
  /**
   * Disconnect from the command.
   *
   * The command is not killed, but SDK stops receiving events from the command.
   * You can reconnect to the command using {@link Commands.connect}.
   */
  async disconnect() {
    this.handleDisconnect();
  }
  /**
   * Kill the command.
   * It uses `SIGKILL` signal to kill the command.
   *
   * @returns `true` if the command was killed successfully, `false` if the command was not found.
   */
  async kill() {
    return await this.handleKill();
  }
  iterateEvents() {
    return __asyncGenerator(this, null, function* () {
      var _a3;
      try {
        for (var iter = __forAwait(this.events), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const event = temp.value;
          const e = (_a3 = event == null ? void 0 : event.event) == null ? void 0 : _a3.event;
          let out;
          switch (e == null ? void 0 : e.case) {
            case "data":
              switch (e.value.output.case) {
                case "stdout":
                  out = new TextDecoder().decode(e.value.output.value);
                  this._stdout += out;
                  yield [out, null, null];
                  break;
                case "stderr":
                  out = new TextDecoder().decode(e.value.output.value);
                  this._stderr += out;
                  yield [null, out, null];
                  break;
                case "pty":
                  yield [null, null, e.value.output.value];
                  break;
              }
              break;
            case "end":
              this.result = {
                exitCode: e.value.exitCode,
                error: e.value.error,
                stdout: this.stdout,
                stderr: this.stderr
              };
              break;
          }
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
    });
  }
  async handleEvents() {
    var _a3, _b, _c;
    try {
      try {
        for (var iter = __forAwait(this.iterateEvents()), more, temp, error; more = !(temp = await iter.next()).done; more = false) {
          const [stdout, stderr, pty] = temp.value;
          if (stdout !== null) {
            (_a3 = this.onStdout) == null ? void 0 : _a3.call(this, stdout);
          } else if (stderr !== null) {
            (_b = this.onStderr) == null ? void 0 : _b.call(this, stderr);
          } else if (pty) {
            (_c = this.onPty) == null ? void 0 : _c.call(this, pty);
          }
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && await temp.call(iter);
        } finally {
          if (error)
            throw error[0];
        }
      }
    } catch (e) {
      this.iterationError = handleRpcError(e);
    }
  }
};

// src/sandbox/network.ts
var ALL_TRAFFIC = "0.0.0.0/0";

// src/sandbox/git/utils.ts
function shellEscape(value) {
  return `'${value.replace(/'/g, `'"'"'`)}'`;
}
function withCredentials(url, username, password) {
  if (!username && !password) {
    return url;
  }
  if (!username || !password) {
    throw new InvalidArgumentError(
      "Both username and password are required when using Git credentials."
    );
  }
  let parsed;
  try {
    parsed = new URL(url);
  } catch (e) {
    throw new InvalidArgumentError(`Invalid Git URL: ${url}`);
  }
  if (parsed.protocol !== "http:" && parsed.protocol !== "https:") {
    throw new InvalidArgumentError(
      "Only http(s) Git URLs support username/password credentials."
    );
  }
  parsed.username = username;
  parsed.password = password;
  return parsed.toString();
}
function stripCredentials(url) {
  let parsed;
  try {
    parsed = new URL(url);
  } catch (e) {
    return url;
  }
  if (parsed.protocol !== "http:" && parsed.protocol !== "https:") {
    return url;
  }
  if (!parsed.username && !parsed.password) {
    return url;
  }
  parsed.username = "";
  parsed.password = "";
  return parsed.toString();
}
function deriveRepoDirFromUrl(url) {
  let parsed;
  try {
    parsed = new URL(url);
  } catch (e) {
    return void 0;
  }
  const trimmedPath = parsed.pathname.replace(/\/+$/, "");
  const lastSegment = trimmedPath.split("/").pop();
  if (!lastSegment) {
    return void 0;
  }
  return lastSegment.endsWith(".git") ? lastSegment.slice(0, -4) : lastSegment;
}
function buildGitCommand(args, repoPath) {
  const parts = ["git"];
  if (repoPath) {
    parts.push("-C", repoPath);
  }
  parts.push(...args);
  return parts.map((part) => shellEscape(part)).join(" ");
}
function buildPushArgs(remoteName, opts) {
  const { remote, branch, setUpstream } = opts;
  const args = ["push"];
  const targetRemote = remoteName != null ? remoteName : remote;
  if (setUpstream && targetRemote) {
    args.push("--set-upstream");
  }
  if (targetRemote) {
    args.push(targetRemote);
  }
  if (branch) {
    args.push(branch);
  }
  return args;
}
function parseAheadBehind(segment) {
  if (!segment) {
    return { ahead: 0, behind: 0 };
  }
  let ahead = 0;
  let behind = 0;
  if (segment.includes("ahead")) {
    try {
      ahead = Number.parseInt(
        segment.split("ahead")[1].split(",")[0].trim(),
        10
      );
    } catch (e) {
      ahead = 0;
    }
  }
  if (segment.includes("behind")) {
    try {
      behind = Number.parseInt(
        segment.split("behind")[1].split(",")[0].trim(),
        10
      );
    } catch (e) {
      behind = 0;
    }
  }
  return { ahead, behind };
}
function normalizeBranchName(name) {
  if (name.startsWith("HEAD (detached at ")) {
    return name.replace("HEAD (detached at ", "").replace(/\)$/, "");
  }
  return name.replace("HEAD (no branch)", "HEAD").replace("No commits yet on ", "").replace("Initial commit on ", "");
}
function deriveStatus(indexStatus, workingStatus) {
  const statuses = /* @__PURE__ */ new Set([indexStatus, workingStatus]);
  if (statuses.has("U")) return "conflict";
  if (statuses.has("R")) return "renamed";
  if (statuses.has("C")) return "copied";
  if (statuses.has("D")) return "deleted";
  if (statuses.has("A")) return "added";
  if (statuses.has("M")) return "modified";
  if (statuses.has("T")) return "typechange";
  if (statuses.has("?")) return "untracked";
  return "unknown";
}
function parseGitStatus(output) {
  const lines = output.split("\n").map((line) => line.replace(/\r$/, "")).filter((line) => line.trim().length > 0);
  let currentBranch;
  let upstream;
  let ahead = 0;
  let behind = 0;
  let detached = false;
  const fileStatus = [];
  if (lines.length === 0) {
    return {
      currentBranch,
      upstream,
      ahead,
      behind,
      detached,
      fileStatus,
      isClean: true,
      hasChanges: false,
      hasStaged: false,
      hasUntracked: false,
      hasConflicts: false,
      totalCount: 0,
      stagedCount: 0,
      unstagedCount: 0,
      untrackedCount: 0,
      conflictCount: 0
    };
  }
  const branchLine = lines[0];
  if (branchLine.startsWith("## ")) {
    const branchInfo = branchLine.slice(3);
    const aheadStart = branchInfo.indexOf(" [");
    const branchPart = aheadStart === -1 ? branchInfo : branchInfo.slice(0, aheadStart);
    const aheadPart = aheadStart === -1 ? void 0 : branchInfo.slice(aheadStart + 2, -1);
    const normalizedBranch = normalizeBranchName(branchPart);
    const rawBranch = branchPart;
    const isDetached = rawBranch.startsWith("HEAD (detached at ") || rawBranch.includes("detached");
    if (isDetached || normalizedBranch.startsWith("HEAD")) {
      detached = true;
    } else if (normalizedBranch.includes("...")) {
      const [branch, upstreamBranch] = normalizedBranch.split("...");
      currentBranch = branch || void 0;
      upstream = upstreamBranch || void 0;
    } else {
      currentBranch = normalizedBranch || void 0;
    }
    const aheadBehind = parseAheadBehind(aheadPart);
    ahead = aheadBehind.ahead;
    behind = aheadBehind.behind;
  }
  for (const line of lines.slice(1)) {
    if (line.startsWith("?? ")) {
      const name2 = line.slice(3);
      fileStatus.push({
        name: name2,
        status: "untracked",
        indexStatus: "?",
        workingTreeStatus: "?",
        staged: false
      });
      continue;
    }
    if (line.length < 3) {
      continue;
    }
    const indexStatus = line[0];
    const workingTreeStatus = line[1];
    const path2 = line.slice(3);
    let renamedFrom;
    let name = path2;
    if (path2.includes(" -> ")) {
      const parts = path2.split(" -> ");
      renamedFrom = parts[0];
      name = parts.slice(1).join(" -> ");
    }
    fileStatus.push(__spreadValues({
      name,
      status: deriveStatus(indexStatus, workingTreeStatus),
      indexStatus,
      workingTreeStatus,
      staged: indexStatus !== " " && indexStatus !== "?"
    }, renamedFrom ? { renamedFrom } : {}));
  }
  const totalCount = fileStatus.length;
  const stagedCount = fileStatus.filter((item) => item.staged).length;
  const untrackedCount = fileStatus.filter(
    (item) => item.status === "untracked"
  ).length;
  const conflictCount = fileStatus.filter(
    (item) => item.status === "conflict"
  ).length;
  const unstagedCount = totalCount - stagedCount;
  return {
    currentBranch,
    upstream,
    ahead,
    behind,
    detached,
    fileStatus,
    isClean: totalCount === 0,
    hasChanges: totalCount > 0,
    hasStaged: stagedCount > 0,
    hasUntracked: untrackedCount > 0,
    hasConflicts: conflictCount > 0,
    totalCount,
    stagedCount,
    unstagedCount,
    untrackedCount,
    conflictCount
  };
}
function parseGitBranches(output) {
  const branches = [];
  let currentBranch;
  const lines = output.split("\n").map((line) => line.trim()).filter((line) => line.length > 0);
  for (const line of lines) {
    const parts = line.split("	");
    const name = parts[0];
    branches.push(name);
    if (parts.length > 1 && parts[1] === "*") {
      currentBranch = name;
    }
  }
  return { branches, currentBranch };
}
function isAuthFailure(err) {
  if (!(err instanceof CommandExitError)) {
    return false;
  }
  const message = `${err.stderr}
${err.stdout}`.toLowerCase();
  const authSnippets = [
    "authentication failed",
    "terminal prompts disabled",
    "could not read username",
    "invalid username or password",
    "access denied",
    "permission denied",
    "not authorized"
  ];
  return authSnippets.some((snippet) => message.includes(snippet));
}
function getScopeFlag(scope) {
  if (scope !== "global" && scope !== "local" && scope !== "system") {
    throw new InvalidArgumentError(
      "Git config scope must be one of: global, local, system."
    );
  }
  return `--${scope}`;
}
function isMissingUpstream(err) {
  if (!(err instanceof CommandExitError)) {
    return false;
  }
  const message = `${err.stderr}
${err.stdout}`.toLowerCase();
  const upstreamSnippets = [
    "has no upstream branch",
    "no upstream branch",
    "no upstream configured",
    "no tracking information for the current branch",
    "no tracking information",
    "set the remote as upstream",
    "set the upstream branch",
    "please specify which branch you want to merge with"
  ];
  return upstreamSnippets.some((snippet) => message.includes(snippet));
}
function buildAuthErrorMessage(action, missingPassword) {
  if (missingPassword) {
    return `Git ${action} requires a password/token for private repositories.`;
  }
  return `Git ${action} requires credentials for private repositories.`;
}
function buildUpstreamErrorMessage(action) {
  if (action === "push") {
    return "Git push failed because no upstream branch is configured. Set upstream once with { setUpstream: true } (and optional remote/branch), or pass remote and branch explicitly.";
  }
  return "Git pull failed because no upstream branch is configured. Pass remote and branch explicitly, or set upstream once (push with { setUpstream: true } or run: git branch --set-upstream-to=origin/<branch> <branch>).";
}
function getRepoPathForScope(scope, path2) {
  if (scope !== "local") {
    return void 0;
  }
  if (!path2) {
    throw new InvalidArgumentError(
      'A repository path is required when using scope "local".'
    );
  }
  return path2;
}

// src/sandbox/git/index.ts
var DEFAULT_GIT_ENV = {
  GIT_TERMINAL_PROMPT: "0"
};
var Git = class {
  constructor(commands) {
    this.commands = commands;
  }
  /**
   * Clone a git repository into the sandbox.
   *
   * @param url Git repository URL.
   * @param opts Clone options.
   * @returns Command result from the command runner.
   */
  async clone(url, opts) {
    const _a3 = opts != null ? opts : {}, {
      username,
      password,
      branch,
      depth,
      path: path2,
      dangerouslyStoreCredentials
    } = _a3, rest = __objRest(_a3, [
      "username",
      "password",
      "branch",
      "depth",
      "path",
      "dangerouslyStoreCredentials"
    ]);
    if (password && !username) {
      throw new InvalidArgumentError(
        "Username is required when using a password or token for git clone."
      );
    }
    const attemptClone = async (authUsername, authPassword) => {
      const urlWithCreds = authUsername && authPassword ? withCredentials(url, authUsername, authPassword) : url;
      const sanitizedUrl = stripCredentials(urlWithCreds);
      const stripInlineCreds = !dangerouslyStoreCredentials && sanitizedUrl !== urlWithCreds;
      const repoPath = stripInlineCreds ? path2 != null ? path2 : deriveRepoDirFromUrl(url) : path2;
      if (stripInlineCreds && !repoPath) {
        throw new InvalidArgumentError(
          "A destination path is required when using credentials without storing them."
        );
      }
      const args = ["clone", urlWithCreds];
      if (branch) args.push("--branch", branch, "--single-branch");
      if (depth) args.push("--depth", depth.toString());
      if (repoPath) args.push(repoPath);
      const result = await this.runGit(args, void 0, rest);
      if (stripInlineCreds) {
        await this.runGit(
          ["remote", "set-url", "origin", sanitizedUrl],
          repoPath,
          rest
        );
      }
      return result;
    };
    try {
      return await attemptClone(username, password);
    } catch (err) {
      if (isAuthFailure(err)) {
        throw new GitAuthError(
          buildAuthErrorMessage("clone", Boolean(username) && !password)
        );
      }
      throw err;
    }
  }
  /**
   * Initialize a new git repository.
   *
   * @param path Destination path for the repository.
   * @param opts Init options.
   * @returns Command result from the command runner.
   */
  async init(path2, opts) {
    const _a3 = opts != null ? opts : {}, { bare, initialBranch } = _a3, rest = __objRest(_a3, ["bare", "initialBranch"]);
    const args = ["init"];
    if (initialBranch) {
      args.push("--initial-branch", initialBranch);
    }
    if (bare) {
      args.push("--bare");
    }
    args.push(path2);
    return this.runGit(args, void 0, rest);
  }
  /**
   * Add (or update) a remote for a repository.
   *
   * @param path Repository path.
   * @param name Remote name (for example, `"origin"`).
   * @param url Remote URL.
   * @param opts Remote add options.
   * @returns Command result from the command runner.
   */
  async remoteAdd(path2, name, url, opts) {
    if (!name || !url) {
      throw new InvalidArgumentError(
        "Both remote name and URL are required to add a git remote."
      );
    }
    const _a3 = opts != null ? opts : {}, { fetch: fetch2, overwrite } = _a3, rest = __objRest(_a3, ["fetch", "overwrite"]);
    const addArgs = ["remote", "add"];
    if (fetch2) {
      addArgs.push("-f");
    }
    addArgs.push(name, url);
    if (!overwrite) {
      return this.runGit(addArgs, path2, rest);
    }
    const addCmd = buildGitCommand(addArgs, path2);
    const setUrlCmd = buildGitCommand(["remote", "set-url", name, url], path2);
    let cmd = `${addCmd} || ${setUrlCmd}`;
    if (fetch2) {
      const fetchCmd = buildGitCommand(["fetch", name], path2);
      cmd = `(${cmd}) && ${fetchCmd}`;
    }
    return this.runShell(cmd, rest);
  }
  /**
   * Get the URL for a git remote.
   *
   * Returns `undefined` when the remote does not exist.
   *
   * @param path Repository path.
   * @param name Remote name (for example, `"origin"`).
   * @param opts Command execution options.
   * @returns Remote URL if present.
   */
  async remoteGet(path2, name, opts) {
    if (!name) {
      throw new InvalidArgumentError("Remote name is required.");
    }
    const cmd = `${buildGitCommand(["remote", "get-url", name], path2)} || true`;
    const result = await this.runShell(cmd, opts);
    const trimmed = result.stdout.trim();
    return trimmed.length > 0 ? trimmed : void 0;
  }
  /**
   * Get repository status information.
   *
   * @param path Repository path.
   * @param opts Command execution options.
   * @returns Parsed git status.
   */
  async status(path2, opts) {
    const result = await this.runGit(
      ["status", "--porcelain=1", "-b"],
      path2,
      opts
    );
    return parseGitStatus(result.stdout);
  }
  /**
   * List branches in a repository.
   *
   * @param path Repository path.
   * @param opts Command execution options.
   * @returns Parsed branch list.
   */
  async branches(path2, opts) {
    const result = await this.runGit(
      ["branch", "--format=%(refname:short)	%(HEAD)"],
      path2,
      opts
    );
    return parseGitBranches(result.stdout);
  }
  /**
   * Create and check out a new branch.
   *
   * @param path Repository path.
   * @param branch Branch name to create.
   * @param opts Command execution options.
   * @returns Command result from the command runner.
   */
  async createBranch(path2, branch, opts) {
    return this.runGit(["checkout", "-b", branch], path2, opts);
  }
  /**
   * Check out an existing branch.
   *
   * @param path Repository path.
   * @param branch Branch name to check out.
   * @param opts Command execution options.
   * @returns Command result from the command runner.
   */
  async checkoutBranch(path2, branch, opts) {
    return this.runGit(["checkout", branch], path2, opts);
  }
  /**
   * Delete a branch.
   *
   * @param path Repository path.
   * @param branch Branch name to delete.
   * @param opts Delete options.
   * @returns Command result from the command runner.
   */
  async deleteBranch(path2, branch, opts) {
    const _a3 = opts != null ? opts : {}, { force } = _a3, rest = __objRest(_a3, ["force"]);
    const args = ["branch", force ? "-D" : "-d", branch];
    return this.runGit(args, path2, rest);
  }
  /**
   * Stage files for commit.
   *
   * @param path Repository path.
   * @param opts Add options.
   * @returns Command result from the command runner.
   */
  async add(path2, opts) {
    const _a3 = opts != null ? opts : {}, { files, all = true } = _a3, rest = __objRest(_a3, ["files", "all"]);
    const args = ["add"];
    if (!files || files.length === 0) {
      args.push(all ? "-A" : ".");
    } else {
      args.push("--", ...files);
    }
    return this.runGit(args, path2, rest);
  }
  /**
   * Create a commit in the repository.
   *
   * @param path Repository path.
   * @param message Commit message.
   * @param opts Commit options.
   * @returns Command result from the command runner.
   */
  async commit(path2, message, opts) {
    const _a3 = opts != null ? opts : {}, { authorName, authorEmail, allowEmpty } = _a3, rest = __objRest(_a3, ["authorName", "authorEmail", "allowEmpty"]);
    const args = ["commit", "-m", message];
    if (allowEmpty) {
      args.push("--allow-empty");
    }
    const authorArgs = [];
    if (authorName) {
      authorArgs.push("-c", `user.name=${authorName}`);
    }
    if (authorEmail) {
      authorArgs.push("-c", `user.email=${authorEmail}`);
    }
    return this.runGit([...authorArgs, ...args], path2, rest);
  }
  /**
   * Reset the current HEAD to a specified state.
   *
   * @param path Repository path.
   * @param opts Reset options.
   * @returns Command result from the command runner.
   */
  async reset(path2, opts) {
    const _a3 = opts != null ? opts : {}, { mode, target, paths: paths2 } = _a3, rest = __objRest(_a3, ["mode", "target", "paths"]);
    const allowedModes = [
      "soft",
      "mixed",
      "hard",
      "merge",
      "keep"
    ];
    if (mode && !allowedModes.includes(mode)) {
      throw new InvalidArgumentError(
        `Reset mode must be one of ${allowedModes.join(", ")}.`
      );
    }
    const args = ["reset"];
    if (mode) {
      args.push(`--${mode}`);
    }
    if (target) {
      args.push(target);
    }
    if (paths2 && paths2.length > 0) {
      args.push("--", ...paths2);
    }
    return this.runGit(args, path2, rest);
  }
  /**
   * Restore working tree files or unstage changes.
   *
   * @param path Repository path.
   * @param opts Restore options.
   * @returns Command result from the command runner.
   */
  async restore(path2, opts) {
    const _a3 = opts, { paths: paths2, staged, worktree, source } = _a3, rest = __objRest(_a3, ["paths", "staged", "worktree", "source"]);
    if (!paths2 || paths2.length === 0) {
      throw new InvalidArgumentError("At least one path is required.");
    }
    let resolvedStaged = staged;
    let resolvedWorktree = worktree;
    if (staged === void 0 && worktree === void 0) {
      resolvedWorktree = true;
    } else if (staged === true && worktree === void 0) {
      resolvedWorktree = false;
    } else if (staged === void 0 && worktree !== void 0) {
      resolvedStaged = false;
    }
    if (resolvedStaged === false && resolvedWorktree === false) {
      throw new InvalidArgumentError(
        "At least one of staged or worktree must be true."
      );
    }
    const args = ["restore"];
    if (resolvedWorktree) {
      args.push("--worktree");
    }
    if (resolvedStaged) {
      args.push("--staged");
    }
    if (source) {
      args.push("--source", source);
    }
    args.push("--", ...paths2);
    return this.runGit(args, path2, rest);
  }
  /**
   * Push commits to a remote.
   *
   * @param path Repository path.
   * @param opts Push options.
   * @returns Command result from the command runner.
   */
  async push(path2, opts) {
    const _a3 = opts != null ? opts : {}, {
      remote,
      branch,
      setUpstream = true,
      username,
      password
    } = _a3, rest = __objRest(_a3, [
      "remote",
      "branch",
      "setUpstream",
      "username",
      "password"
    ]);
    if (password && !username) {
      throw new InvalidArgumentError(
        "Username is required when using a password or token for git push."
      );
    }
    if (username && password) {
      const remoteName = await this.resolveRemoteName(path2, remote, rest);
      return this.withRemoteCredentials(
        path2,
        remoteName,
        username,
        password,
        rest,
        () => this.runGit(
          buildPushArgs(remoteName, { remote, branch, setUpstream }),
          path2,
          rest
        )
      );
    }
    try {
      return await this.runGit(
        buildPushArgs(void 0, { remote, branch, setUpstream }),
        path2,
        rest
      );
    } catch (err) {
      if (isAuthFailure(err)) {
        throw new GitAuthError(
          buildAuthErrorMessage("push", Boolean(username) && !password)
        );
      }
      if (isMissingUpstream(err)) {
        throw new GitUpstreamError(buildUpstreamErrorMessage("push"));
      }
      throw err;
    }
  }
  /**
   * Pull changes from a remote.
   *
   * @param path Repository path.
   * @param opts Pull options.
   * @returns Command result from the command runner.
   */
  async pull(path2, opts) {
    const _a3 = opts != null ? opts : {}, { remote, branch, username, password } = _a3, rest = __objRest(_a3, ["remote", "branch", "username", "password"]);
    if (password && !username) {
      throw new InvalidArgumentError(
        "Username is required when using a password or token for git pull."
      );
    }
    if (!remote && !branch) {
      const hasUpstream = await this.hasUpstream(path2, rest);
      if (!hasUpstream) {
        throw new GitUpstreamError(buildUpstreamErrorMessage("pull"));
      }
    }
    const buildArgs = (remoteName) => {
      const args = ["pull"];
      const targetRemote = remoteName != null ? remoteName : remote;
      if (targetRemote) {
        args.push(targetRemote);
      }
      if (branch) {
        args.push(branch);
      }
      return args;
    };
    if (username && password) {
      const remoteName = await this.resolveRemoteName(path2, remote, rest);
      return this.withRemoteCredentials(
        path2,
        remoteName,
        username,
        password,
        rest,
        () => this.runGit(buildArgs(remoteName), path2, rest)
      );
    }
    try {
      return await this.runGit(buildArgs(), path2, rest);
    } catch (err) {
      if (isAuthFailure(err)) {
        throw new GitAuthError(
          buildAuthErrorMessage("pull", Boolean(username) && !password)
        );
      }
      if (isMissingUpstream(err)) {
        throw new GitUpstreamError(buildUpstreamErrorMessage("pull"));
      }
      throw err;
    }
  }
  /**
   * Set a git config value.
   *
   * Use `scope: "local"` together with `path` to configure a specific repository.
   *
   * @param key Git config key (for example, `"pull.rebase"`).
   * @param value Git config value.
   * @param opts Config options.
   * @returns Command result from the command runner.
   */
  async setConfig(key, value, opts) {
    var _a3;
    if (!key) {
      throw new InvalidArgumentError("Git config key is required.");
    }
    const scope = (_a3 = opts == null ? void 0 : opts.scope) != null ? _a3 : "global";
    const scopeFlag = getScopeFlag(scope);
    const repoPath = getRepoPathForScope(scope, opts == null ? void 0 : opts.path);
    return this.runGit(["config", scopeFlag, key, value], repoPath, opts);
  }
  /**
   * Get a git config value.
   *
   * Returns `undefined` when the key is not set in the requested scope.
   *
   * @param key Git config key (for example, `"pull.rebase"`).
   * @param opts Config options.
   * @returns The config value if present.
   */
  async getConfig(key, opts) {
    var _a3;
    if (!key) {
      throw new InvalidArgumentError("Git config key is required.");
    }
    const scope = (_a3 = opts == null ? void 0 : opts.scope) != null ? _a3 : "global";
    const scopeFlag = getScopeFlag(scope);
    const repoPath = getRepoPathForScope(scope, opts == null ? void 0 : opts.path);
    const cmd = `${buildGitCommand(["config", scopeFlag, "--get", key], repoPath)} || true`;
    const result = await this.runShell(cmd, opts);
    const trimmed = result.stdout.trim();
    return trimmed.length > 0 ? trimmed : void 0;
  }
  /**
   * Dangerously authenticate git globally via the credential helper.
   *
   * This persists credentials in the credential store.
   * Prefer short-lived credentials when possible.
   *
   * @param opts Authentication options.
   * @returns Command result from the command runner.
   */
  async dangerouslyAuthenticate(opts) {
    const _a3 = opts, { username, password, host, protocol } = _a3, rest = __objRest(_a3, ["username", "password", "host", "protocol"]);
    if (!username || !password) {
      throw new InvalidArgumentError(
        "Both username and password are required to authenticate git."
      );
    }
    const targetHost = (host != null ? host : "github.com").trim();
    const targetProtocol = (protocol != null ? protocol : "https").trim();
    const credentialInput = [
      `protocol=${targetProtocol}`,
      `host=${targetHost}`,
      `username=${username}`,
      `password=${password}`,
      "",
      ""
    ].join("\n");
    await this.runGit(
      ["config", "--global", "credential.helper", "store"],
      void 0,
      rest
    );
    const approveCmd = `printf %s ${shellEscape(credentialInput)} | ${buildGitCommand(
      ["credential", "approve"]
    )}`;
    return this.runShell(approveCmd, rest);
  }
  /**
   * Configure git user name and email.
   *
   * @param name Git user name.
   * @param email Git user email.
   * @param opts Config options.
   * @returns Command result from the command runner.
   */
  async configureUser(name, email, opts) {
    var _a3;
    if (!name || !email) {
      throw new InvalidArgumentError("Both name and email are required.");
    }
    const scope = (_a3 = opts == null ? void 0 : opts.scope) != null ? _a3 : "global";
    const configOpts = __spreadProps(__spreadValues({}, opts), { scope });
    await this.setConfig("user.name", name, configOpts);
    return this.setConfig("user.email", email, configOpts);
  }
  /**
   * Build and execute a git command inside the sandbox.
   *
   * @param args Git arguments to pass to the git binary.
   * @param repoPath Repository path used with `git -C`, if provided.
   * @param opts Command execution options.
   * @returns Command result from the command runner.
   */
  async runGit(args, repoPath, opts) {
    const _a3 = opts != null ? opts : {}, { envs } = _a3, rest = __objRest(_a3, ["envs"]);
    const cmd = buildGitCommand(args, repoPath);
    const mergedEnvs = __spreadValues(__spreadValues({}, DEFAULT_GIT_ENV), envs != null ? envs : {});
    return this.commands.run(cmd, __spreadProps(__spreadValues({}, rest), {
      envs: mergedEnvs
    }));
  }
  /**
   * Execute a raw shell command while applying default git environment variables.
   * 
   Note: We can liekly just modify runGit later to allow appending commands to the git but for now it's separate.
   */
  async runShell(cmd, opts) {
    const _a3 = opts != null ? opts : {}, { envs } = _a3, rest = __objRest(_a3, ["envs"]);
    const mergedEnvs = __spreadValues(__spreadValues({}, DEFAULT_GIT_ENV), envs != null ? envs : {});
    return this.commands.run(cmd, __spreadProps(__spreadValues({}, rest), {
      envs: mergedEnvs
    }));
  }
  async getRemoteUrl(path2, remote, opts) {
    const result = await this.runGit(["remote", "get-url", remote], path2, opts);
    const url = result.stdout.trim();
    if (!url) {
      throw new InvalidArgumentError(
        `Remote "${remote}" URL not found in repository.`
      );
    }
    return url;
  }
  async resolveRemoteName(path2, remote, opts) {
    if (remote) {
      return remote;
    }
    const result = await this.runGit(["remote"], path2, opts);
    const remotes = result.stdout.split("\n").map((line) => line.trim()).filter(Boolean);
    if (remotes.length === 1) {
      return remotes[0];
    }
    throw new InvalidArgumentError(
      "Remote is required when using username/password and the repository has multiple remotes."
    );
  }
  async withRemoteCredentials(path2, remote, username, password, opts, operation) {
    const originalUrl = await this.getRemoteUrl(path2, remote, opts);
    const credentialUrl = withCredentials(originalUrl, username, password);
    await this.runGit(["remote", "set-url", remote, credentialUrl], path2, opts);
    let result;
    let operationError;
    try {
      result = await operation();
    } catch (err) {
      operationError = err;
    }
    let restoreError;
    try {
      await this.runGit(["remote", "set-url", remote, originalUrl], path2, opts);
    } catch (err) {
      restoreError = err;
    }
    if (operationError) {
      throw operationError;
    }
    if (restoreError) {
      throw restoreError;
    }
    return result;
  }
  async hasUpstream(path2, opts) {
    try {
      const result = await this.runGit(
        ["rev-parse", "--abbrev-ref", "--symbolic-full-name", "@{u}"],
        path2,
        opts
      );
      return result.stdout.trim().length > 0;
    } catch (e) {
      return false;
    }
  }
};

// src/sandbox/index.ts
var import_connect_web = require("@connectrpc/connect-web");

// src/sandbox/commands/index.ts
var import_connect5 = require("@connectrpc/connect");
var import_compare_versions3 = require("compare-versions");

// src/envd/process/process_pb.ts
var import_codegenv22 = require("@bufbuild/protobuf/codegenv2");
var file_process_process = /* @__PURE__ */ (0, import_codegenv22.fileDesc)(
  "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"
);
var Process = /* @__PURE__ */ (0, import_codegenv22.serviceDesc)(file_process_process, 0);

// src/sandbox/commands/pty.ts
var import_connect4 = require("@connectrpc/connect");
var Pty = class {
  // 60 seconds
  constructor(transport, connectionConfig, metadata) {
    this.transport = transport;
    this.connectionConfig = connectionConfig;
    this.defaultPtyConnectionTimeout = 6e4;
    this.rpc = (0, import_connect4.createClient)(Process, this.transport);
    this.envdVersion = metadata.version;
  }
  /**
   * Create a new PTY (pseudo-terminal).
   *
   * @param opts options for creating the PTY.
   *
   * @returns handle to interact with the PTY.
   */
  async create(opts) {
    var _a3, _b, _c, _d, _e, _f;
    const requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : this.connectionConfig.requestTimeoutMs;
    const envs = (_b = opts == null ? void 0 : opts.envs) != null ? _b : {};
    envs.TERM = (_c = envs.TERM) != null ? _c : "xterm-256color";
    envs.LANG = (_d = envs.LANG) != null ? _d : "C.UTF-8";
    envs.LC_ALL = (_e = envs.LC_ALL) != null ? _e : "C.UTF-8";
    const controller = new AbortController();
    const reqTimeout = setTimeout(() => {
      controller.abort();
    }, requestTimeoutMs);
    const events = this.rpc.start(
      {
        process: {
          cmd: "/bin/bash",
          args: ["-i", "-l"],
          envs,
          cwd: opts == null ? void 0 : opts.cwd
        },
        pty: {
          size: {
            cols: opts.cols,
            rows: opts.rows
          }
        }
      },
      {
        headers: __spreadProps(__spreadValues({}, authenticationHeader(this.envdVersion, opts == null ? void 0 : opts.user)), {
          [KEEPALIVE_PING_HEADER]: KEEPALIVE_PING_INTERVAL_SEC.toString()
        }),
        signal: controller.signal,
        timeoutMs: (_f = opts == null ? void 0 : opts.timeoutMs) != null ? _f : this.defaultPtyConnectionTimeout
      }
    );
    try {
      const pid = await handleProcessStartEvent(events);
      clearTimeout(reqTimeout);
      return new CommandHandle(
        pid,
        () => controller.abort(),
        () => this.kill(pid),
        events,
        void 0,
        void 0,
        opts.onData
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Connect to a running PTY.
   *
   * @param pid process ID of the PTY to connect to. You can get the list of running PTYs using {@link Commands.list}.
   * @param opts connection options.
   *
   * @returns handle to interact with the PTY.
   */
  async connect(pid, opts) {
    var _a3, _b;
    const requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : this.connectionConfig.requestTimeoutMs;
    const controller = new AbortController();
    const reqTimeout = requestTimeoutMs ? setTimeout(() => {
      controller.abort();
    }, requestTimeoutMs) : void 0;
    const events = this.rpc.connect(
      {
        process: {
          selector: {
            case: "pid",
            value: pid
          }
        }
      },
      {
        signal: controller.signal,
        headers: {
          [KEEPALIVE_PING_HEADER]: KEEPALIVE_PING_INTERVAL_SEC.toString()
        },
        timeoutMs: (_b = opts == null ? void 0 : opts.timeoutMs) != null ? _b : this.defaultPtyConnectionTimeout
      }
    );
    try {
      const pid2 = await handleProcessStartEvent(events);
      clearTimeout(reqTimeout);
      return new CommandHandle(
        pid2,
        () => controller.abort(),
        () => this.kill(pid2),
        events,
        void 0,
        void 0,
        opts == null ? void 0 : opts.onData
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Send input to a PTY.
   *
   * @param pid process ID of the PTY.
   * @param data input data to send to the PTY.
   * @param opts connection options.
   */
  async sendInput(pid, data, opts) {
    try {
      await this.rpc.sendInput(
        {
          input: {
            input: {
              case: "pty",
              value: data
            }
          },
          process: {
            selector: {
              case: "pid",
              value: pid
            }
          }
        },
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Resize PTY.
   * Call this when the terminal window is resized and the number of columns and rows has changed.
   *
   * @param pid process ID of the PTY.
   * @param size new size of the PTY.
   * @param opts connection options.
   */
  async resize(pid, size, opts) {
    try {
      await this.rpc.update(
        {
          process: {
            selector: {
              case: "pid",
              value: pid
            }
          },
          pty: {
            size
          }
        },
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Kill a running PTY specified by process ID.
   * It uses `SIGKILL` signal to kill the PTY.
   *
   * @param pid process ID of the PTY.
   * @param opts connection options.
   *
   * @returns `true` if the PTY was killed, `false` if the PTY was not found.
   */
  async kill(pid, opts) {
    try {
      await this.rpc.sendSignal(
        {
          process: {
            selector: {
              case: "pid",
              value: pid
            }
          },
          signal: 9 /* SIGKILL */
        },
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      return true;
    } catch (err) {
      if (err instanceof import_connect4.ConnectError) {
        if (err.code === import_connect4.Code.NotFound) {
          return false;
        }
      }
      throw handleRpcError(err);
    }
  }
};

// src/sandbox/commands/index.ts
var Commands = class {
  constructor(transport, connectionConfig, metadata) {
    this.connectionConfig = connectionConfig;
    this.defaultProcessConnectionTimeout = 6e4;
    this.rpc = (0, import_connect5.createClient)(Process, transport);
    this.envdVersion = metadata.version;
  }
  /**
   * List all running commands and PTY sessions.
   *
   * @param opts connection options.
   *
   * @returns list of running commands and PTY sessions.
   */
  async list(opts) {
    try {
      const res = await this.rpc.list(
        {},
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      return res.processes.map((p) => __spreadValues(__spreadProps(__spreadValues({
        pid: p.pid
      }, p.tag && { tag: p.tag }), {
        args: p.config.args,
        envs: p.config.envs,
        cmd: p.config.cmd
      }), p.config.cwd && { cwd: p.config.cwd }));
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Send data to command stdin.
   *
   * @param pid process ID of the command. You can get the list of running commands using {@link Commands.list}.
   * @param data data to send to the command.
   * @param opts connection options.
   */
  async sendStdin(pid, data, opts) {
    try {
      await this.rpc.sendInput(
        {
          process: {
            selector: {
              case: "pid",
              value: pid
            }
          },
          input: {
            input: {
              case: "stdin",
              value: new TextEncoder().encode(data)
            }
          }
        },
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  /**
   * Kill a running command specified by its process ID.
   * It uses `SIGKILL` signal to kill the command.
   *
   * @param pid process ID of the command. You can get the list of running commands using {@link Commands.list}.
   * @param opts connection options.
   *
   * @returns `true` if the command was killed, `false` if the command was not found.
   */
  async kill(pid, opts) {
    try {
      await this.rpc.sendSignal(
        {
          process: {
            selector: {
              case: "pid",
              value: pid
            }
          },
          signal: 9 /* SIGKILL */
        },
        {
          signal: this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
        }
      );
      return true;
    } catch (err) {
      if (err instanceof import_connect5.ConnectError) {
        if (err.code === import_connect5.Code.NotFound) {
          return false;
        }
      }
      throw handleRpcError(err);
    }
  }
  /**
   * Connect to a running command.
   * You can use {@link CommandHandle.wait} to wait for the command to finish and get execution results.
   *
   * @param pid process ID of the command to connect to. You can get the list of running commands using {@link Commands.list}.
   * @param opts connection options.
   *
   * @returns `CommandHandle` handle to interact with the running command.
   */
  async connect(pid, opts) {
    var _a3, _b;
    const requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : this.connectionConfig.requestTimeoutMs;
    const controller = new AbortController();
    const reqTimeout = requestTimeoutMs ? setTimeout(() => {
      controller.abort();
    }, requestTimeoutMs) : void 0;
    const events = this.rpc.connect(
      {
        process: {
          selector: {
            case: "pid",
            value: pid
          }
        }
      },
      {
        signal: controller.signal,
        headers: {
          [KEEPALIVE_PING_HEADER]: KEEPALIVE_PING_INTERVAL_SEC.toString()
        },
        timeoutMs: (_b = opts == null ? void 0 : opts.timeoutMs) != null ? _b : this.defaultProcessConnectionTimeout
      }
    );
    try {
      const pid2 = await handleProcessStartEvent(events);
      clearTimeout(reqTimeout);
      return new CommandHandle(
        pid2,
        () => controller.abort(),
        () => this.kill(pid2),
        events,
        opts == null ? void 0 : opts.onStdout,
        opts == null ? void 0 : opts.onStderr,
        void 0
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
  async run(cmd, opts) {
    const proc = await this.start(cmd, opts);
    return (opts == null ? void 0 : opts.background) ? proc : proc.wait();
  }
  async start(cmd, opts) {
    var _a3, _b;
    const requestTimeoutMs = (_a3 = opts == null ? void 0 : opts.requestTimeoutMs) != null ? _a3 : this.connectionConfig.requestTimeoutMs;
    const controller = new AbortController();
    const reqTimeout = requestTimeoutMs ? setTimeout(() => {
      controller.abort();
    }, requestTimeoutMs) : void 0;
    if ((opts == null ? void 0 : opts.stdin) === false && (0, import_compare_versions3.compareVersions)(this.envdVersion, ENVD_COMMANDS_STDIN) < 0) {
      throw new SandboxError(
        `Sandbox envd version ${this.envdVersion} can't specify stdin, it's always turned on. Please rebuild your template if you need this feature.`
      );
    }
    const events = this.rpc.start(
      {
        process: {
          cmd: "/bin/bash",
          cwd: opts == null ? void 0 : opts.cwd,
          envs: opts == null ? void 0 : opts.envs,
          args: ["-l", "-c", cmd]
        },
        stdin: (opts == null ? void 0 : opts.stdin) || false
      },
      {
        headers: __spreadProps(__spreadValues({}, authenticationHeader(this.envdVersion, opts == null ? void 0 : opts.user)), {
          [KEEPALIVE_PING_HEADER]: KEEPALIVE_PING_INTERVAL_SEC.toString()
        }),
        signal: controller.signal,
        timeoutMs: (_b = opts == null ? void 0 : opts.timeoutMs) != null ? _b : this.defaultProcessConnectionTimeout
      }
    );
    try {
      const pid = await handleProcessStartEvent(events);
      clearTimeout(reqTimeout);
      return new CommandHandle(
        pid,
        () => controller.abort(),
        () => this.kill(pid),
        events,
        opts == null ? void 0 : opts.onStdout,
        opts == null ? void 0 : opts.onStderr,
        void 0
      );
    } catch (err) {
      throw handleRpcError(err);
    }
  }
};

// src/sandbox/sandboxApi.ts
var import_compare_versions4 = require("compare-versions");
var SandboxApi = class {
  constructor() {
  }
  /**
   * Kill the sandbox specified by sandbox ID.
   *
   * @param sandboxId sandbox ID.
   * @param opts connection options.
   *
   * @returns `true` if the sandbox was found and killed, `false` otherwise.
   */
  static async kill(sandboxId, opts) {
    var _a3;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.DELETE("/sandboxes/{sandboxID}", {
      params: {
        path: {
          sandboxID: sandboxId
        }
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    if (((_a3 = res.error) == null ? void 0 : _a3.code) === 404) {
      return false;
    }
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    return true;
  }
  /**
   * Get sandbox information like sandbox ID, template, metadata, started at/end at date.
   *
   * @param sandboxId sandbox ID.
   * @param opts connection options.
   *
   * @returns sandbox information.
   */
  static async getInfo(sandboxId, opts) {
    const fullInfo = await this.getFullInfo(sandboxId, opts);
    delete fullInfo.envdAccessToken;
    delete fullInfo.sandboxDomain;
    return fullInfo;
  }
  /**
   * Get the metrics of the sandbox.
   *
   * @param sandboxId sandbox ID.
   * @param opts sandbox metrics options.
   *
   * @returns  List of sandbox metrics containing CPU, memory and disk usage information.
   */
  static async getMetrics(sandboxId, opts) {
    var _a3, _b;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const start = (opts == null ? void 0 : opts.start) ? Math.round(opts.start.getTime() / 1e3) : void 0;
    const end = (opts == null ? void 0 : opts.end) ? Math.round(opts.end.getTime() / 1e3) : void 0;
    const res = await client.api.GET("/sandboxes/{sandboxID}/metrics", {
      params: {
        path: {
          sandboxID: sandboxId,
          start,
          end
        }
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    return (_b = (_a3 = res.data) == null ? void 0 : _a3.map((metric) => ({
      timestamp: new Date(metric.timestamp),
      cpuUsedPct: metric.cpuUsedPct,
      cpuCount: metric.cpuCount,
      memUsed: metric.memUsed,
      memTotal: metric.memTotal,
      diskUsed: metric.diskUsed,
      diskTotal: metric.diskTotal
    }))) != null ? _b : [];
  }
  /**
   * Set the timeout of the specified sandbox.
   * After the timeout expires the sandbox will be automatically killed.
   *
   * This method can extend or reduce the sandbox timeout set when creating the sandbox or from the last call to {@link Sandbox.setTimeout}.
   *
   * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
   *
   * @param sandboxId sandbox ID.
   * @param timeoutMs timeout in **milliseconds**.
   * @param opts connection options.
   */
  static async setTimeout(sandboxId, timeoutMs, opts) {
    var _a3;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.POST("/sandboxes/{sandboxID}/timeout", {
      params: {
        path: {
          sandboxID: sandboxId
        }
      },
      body: {
        timeout: timeoutToSeconds(timeoutMs)
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    if (((_a3 = res.error) == null ? void 0 : _a3.code) === 404) {
      throw new NotFoundError(`Sandbox ${sandboxId} not found`);
    }
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
  }
  static async getFullInfo(sandboxId, opts) {
    var _a3, _b;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.GET("/sandboxes/{sandboxID}", {
      params: {
        path: {
          sandboxID: sandboxId
        }
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    if (((_a3 = res.error) == null ? void 0 : _a3.code) === 404) {
      throw new NotFoundError(`Sandbox ${sandboxId} not found`);
    }
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    if (!res.data) {
      throw new Error("Sandbox not found");
    }
    return __spreadProps(__spreadValues({
      sandboxId: res.data.sandboxID,
      templateId: res.data.templateID
    }, res.data.alias && { name: res.data.alias }), {
      metadata: (_b = res.data.metadata) != null ? _b : {},
      envdVersion: res.data.envdVersion,
      envdAccessToken: res.data.envdAccessToken,
      startedAt: new Date(res.data.startedAt),
      endAt: new Date(res.data.endAt),
      state: res.data.state,
      cpuCount: res.data.cpuCount,
      memoryMB: res.data.memoryMB,
      sandboxDomain: res.data.domain || void 0
    });
  }
  /**
   * Pause the sandbox specified by sandbox ID.
   *
   * @param sandboxId sandbox ID.
   * @param opts connection options.
   *
   * @returns `true` if the sandbox got paused, `false` if the sandbox was already paused.
   */
  static async betaPause(sandboxId, opts) {
    var _a3, _b;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.POST("/sandboxes/{sandboxID}/pause", {
      params: {
        path: {
          sandboxID: sandboxId
        }
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    if (((_a3 = res.error) == null ? void 0 : _a3.code) === 404) {
      throw new NotFoundError(`Sandbox ${sandboxId} not found`);
    }
    if (((_b = res.error) == null ? void 0 : _b.code) === 409) {
      return false;
    }
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    return true;
  }
  static async createSandbox(template, timeoutMs, opts) {
    var _a3, _b, _c;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.POST("/sandboxes", {
      body: {
        autoPause: (_a3 = opts == null ? void 0 : opts.autoPause) != null ? _a3 : false,
        templateID: template,
        metadata: opts == null ? void 0 : opts.metadata,
        mcp: opts == null ? void 0 : opts.mcp,
        envVars: opts == null ? void 0 : opts.envs,
        timeout: timeoutToSeconds(timeoutMs),
        secure: (_b = opts == null ? void 0 : opts.secure) != null ? _b : true,
        allow_internet_access: (_c = opts == null ? void 0 : opts.allowInternetAccess) != null ? _c : true,
        network: opts == null ? void 0 : opts.network
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    if ((0, import_compare_versions4.compareVersions)(res.data.envdVersion, "0.1.0") < 0) {
      await this.kill(res.data.sandboxID, opts);
      throw new TemplateError(
        "You need to update the template to use the new SDK. You can do this by running `e2b template build` in the directory with the template."
      );
    }
    return {
      sandboxId: res.data.sandboxID,
      sandboxDomain: res.data.domain || void 0,
      envdVersion: res.data.envdVersion,
      envdAccessToken: res.data.envdAccessToken,
      trafficAccessToken: res.data.trafficAccessToken || void 0
    };
  }
  static async connectSandbox(sandboxId, opts) {
    var _a3, _b;
    const timeoutMs = (_a3 = opts == null ? void 0 : opts.timeoutMs) != null ? _a3 : DEFAULT_SANDBOX_TIMEOUT_MS;
    const config = new ConnectionConfig(opts);
    const client = new ApiClient(config);
    const res = await client.api.POST("/sandboxes/{sandboxID}/connect", {
      params: {
        path: {
          sandboxID: sandboxId
        }
      },
      body: {
        timeout: timeoutToSeconds(timeoutMs)
      },
      signal: config.getSignal(opts == null ? void 0 : opts.requestTimeoutMs)
    });
    if (((_b = res.error) == null ? void 0 : _b.code) === 404) {
      throw new NotFoundError(`Paused sandbox ${sandboxId} not found`);
    }
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    return {
      sandboxId: res.data.sandboxID,
      sandboxDomain: res.data.domain || void 0,
      envdVersion: res.data.envdVersion,
      envdAccessToken: res.data.envdAccessToken,
      trafficAccessToken: res.data.trafficAccessToken || void 0
    };
  }
};
var SandboxPaginator = class {
  constructor(opts) {
    this.config = new ConnectionConfig(opts);
    this.client = new ApiClient(this.config);
    this._hasNext = true;
    this._nextToken = opts == null ? void 0 : opts.nextToken;
    this.query = opts == null ? void 0 : opts.query;
    this.limit = opts == null ? void 0 : opts.limit;
  }
  /**
   * Returns True if there are more items to fetch.
   */
  get hasNext() {
    return this._hasNext;
  }
  /**
   * Returns the next token to use for pagination.
   */
  get nextToken() {
    return this._nextToken;
  }
  /**
   * Get the next page of sandboxes.
   *
   * @throws Error if there are no more items to fetch. Call this method only if `hasNext` is `true`.
   *
   * @returns List of sandboxes
   */
  async nextItems() {
    var _a3, _b, _c;
    if (!this.hasNext) {
      throw new Error("No more items to fetch");
    }
    let metadata = void 0;
    if ((_a3 = this.query) == null ? void 0 : _a3.metadata) {
      const encodedPairs = Object.fromEntries(
        Object.entries(this.query.metadata).map(([key, value]) => [
          encodeURIComponent(key),
          encodeURIComponent(value)
        ])
      );
      metadata = new URLSearchParams(encodedPairs).toString();
    }
    const res = await this.client.api.GET("/v2/sandboxes", {
      params: {
        query: {
          metadata,
          state: (_b = this.query) == null ? void 0 : _b.state,
          limit: this.limit,
          nextToken: this.nextToken
        }
      },
      // requestTimeoutMs is already passed here via the connectionConfig.
      signal: this.config.getSignal()
    });
    const err = handleApiError(res);
    if (err) {
      throw err;
    }
    this._nextToken = res.response.headers.get("x-next-token") || void 0;
    this._hasNext = !!this._nextToken;
    return ((_c = res.data) != null ? _c : []).map(
      (sandbox) => {
        var _a4;
        return __spreadProps(__spreadValues({
          sandboxId: sandbox.sandboxID,
          templateId: sandbox.templateID
        }, sandbox.alias && { name: sandbox.alias }), {
          metadata: (_a4 = sandbox.metadata) != null ? _a4 : {},
          startedAt: new Date(sandbox.startedAt),
          endAt: new Date(sandbox.endAt),
          state: sandbox.state,
          cpuCount: sandbox.cpuCount,
          memoryMB: sandbox.memoryMB,
          envdVersion: sandbox.envdVersion
        });
      }
    );
  }
};

// src/sandbox/index.ts
var import_compare_versions5 = require("compare-versions");
var Sandbox = class extends SandboxApi {
  /**
   * Use {@link Sandbox.create} to create a new Sandbox instead.
   *
   * @hidden
   * @hide
   * @internal
   * @access protected
   */
  constructor(opts) {
    var _a3, _b, _c;
    super();
    this.envdPort = 49983;
    this.mcpPort = 50005;
    this.connectionConfig = new ConnectionConfig(opts);
    this.sandboxId = opts.sandboxId;
    this.sandboxDomain = (_a3 = opts.sandboxDomain) != null ? _a3 : this.connectionConfig.domain;
    this.envdAccessToken = opts.envdAccessToken;
    this.trafficAccessToken = opts.trafficAccessToken;
    this.envdApiUrl = this.connectionConfig.getSandboxUrl(this.sandboxId, {
      sandboxDomain: this.sandboxDomain,
      envdPort: this.envdPort
    });
    const sandboxHeaders = {
      "E2b-Sandbox-Id": this.sandboxId,
      "E2b-Sandbox-Port": this.envdPort.toString()
    };
    const rpcTransport = (0, import_connect_web.createConnectTransport)({
      baseUrl: this.envdApiUrl,
      useBinaryFormat: false,
      interceptors: (opts == null ? void 0 : opts.logger) ? [createRpcLogger(opts.logger)] : void 0,
      fetch: (url, options) => {
        const headers = new Headers(this.connectionConfig.headers);
        new Headers(options == null ? void 0 : options.headers).forEach(
          (value, key) => headers.append(key, value)
        );
        new Headers(sandboxHeaders).forEach(
          (value, key) => headers.append(key, value)
        );
        if (this.envdAccessToken) {
          headers.append("X-Access-Token", this.envdAccessToken);
        }
        options = __spreadProps(__spreadValues({}, options != null ? options : {}), {
          headers,
          redirect: "follow"
        });
        return fetch(url, options);
      }
    });
    this.envdApi = new EnvdApiClient(
      {
        apiUrl: this.envdApiUrl,
        logger: opts == null ? void 0 : opts.logger,
        accessToken: this.envdAccessToken,
        headers: __spreadValues({
          "User-Agent": (_c = (_b = this.connectionConfig.headers) == null ? void 0 : _b["User-Agent"]) != null ? _c : ""
        }, this.envdAccessToken ? { "X-Access-Token": this.envdAccessToken } : {})
      },
      {
        version: opts.envdVersion
      }
    );
    this.files = new Filesystem2(
      rpcTransport,
      this.envdApi,
      this.connectionConfig
    );
    this.commands = new Commands(rpcTransport, this.connectionConfig, {
      version: opts.envdVersion
    });
    this.pty = new Pty(rpcTransport, this.connectionConfig, {
      version: opts.envdVersion
    });
    this.git = new Git(this.commands);
  }
  /**
   * List all sandboxes.
   *
   * @param opts connection options.
   *
   * @returns paginator for listing sandboxes.
   */
  static list(opts) {
    return new SandboxPaginator(opts);
  }
  static async create(templateOrOpts, opts) {
    var _a3, _b;
    const { template, sandboxOpts } = typeof templateOrOpts === "string" ? {
      template: templateOrOpts,
      sandboxOpts: opts
    } : {
      template: (templateOrOpts == null ? void 0 : templateOrOpts.mcp) ? this.defaultMcpTemplate : this.defaultTemplate,
      sandboxOpts: templateOrOpts
    };
    const config = new ConnectionConfig(sandboxOpts);
    if (config.debug) {
      return new this(__spreadValues({
        sandboxId: "debug_sandbox_id",
        envdVersion: ENVD_DEBUG_FALLBACK
      }, config));
    }
    const sandboxInfo = await SandboxApi.createSandbox(
      template,
      (_a3 = sandboxOpts == null ? void 0 : sandboxOpts.timeoutMs) != null ? _a3 : this.defaultSandboxTimeoutMs,
      sandboxOpts
    );
    const sandbox = new this(__spreadValues(__spreadValues({}, sandboxInfo), config));
    if (sandboxOpts == null ? void 0 : sandboxOpts.mcp) {
      sandbox.mcpToken = crypto.randomUUID();
      const res = await sandbox.commands.run(
        `mcp-gateway --config '${JSON.stringify(sandboxOpts == null ? void 0 : sandboxOpts.mcp)}'`,
        {
          user: "root",
          envs: {
            GATEWAY_ACCESS_TOKEN: (_b = sandbox.mcpToken) != null ? _b : ""
          }
        }
      );
      if (res.exitCode !== 0) {
        throw new Error(`Failed to start MCP gateway: ${res.stderr}`);
      }
    }
    return sandbox;
  }
  static async betaCreate(templateOrOpts, opts) {
    var _a3, _b;
    const { template, sandboxOpts } = typeof templateOrOpts === "string" ? {
      template: templateOrOpts,
      sandboxOpts: opts
    } : {
      template: (templateOrOpts == null ? void 0 : templateOrOpts.mcp) ? this.defaultMcpTemplate : this.defaultTemplate,
      sandboxOpts: templateOrOpts
    };
    const config = new ConnectionConfig(sandboxOpts);
    if (config.debug) {
      return new this(__spreadValues({
        sandboxId: "debug_sandbox_id",
        envdVersion: ENVD_DEBUG_FALLBACK
      }, config));
    }
    const sandboxInfo = await SandboxApi.createSandbox(
      template,
      (_a3 = sandboxOpts == null ? void 0 : sandboxOpts.timeoutMs) != null ? _a3 : this.defaultSandboxTimeoutMs,
      sandboxOpts
    );
    const sandbox = new this(__spreadValues(__spreadValues({}, sandboxInfo), config));
    if (sandboxOpts == null ? void 0 : sandboxOpts.mcp) {
      sandbox.mcpToken = crypto.randomUUID();
      const res = await sandbox.commands.run(
        `mcp-gateway --config '${JSON.stringify(sandboxOpts == null ? void 0 : sandboxOpts.mcp)}'`,
        {
          user: "root",
          envs: {
            GATEWAY_ACCESS_TOKEN: (_b = sandbox.mcpToken) != null ? _b : ""
          }
        }
      );
      if (res.exitCode !== 0) {
        throw new Error(`Failed to start MCP gateway: ${res.stderr}`);
      }
    }
    return sandbox;
  }
  /**
   * Connect to a sandbox. If the sandbox is paused, it will be automatically resumed.
   * Sandbox must be either running or be paused.
   *
   * With sandbox ID you can connect to the same sandbox from different places or environments (serverless functions, etc).
   *
   * @param sandboxId sandbox ID.
   * @param opts connection options.
   *
   * @returns A running sandbox instance
   *
   * @example
   * ```ts
   * const sandbox = await Sandbox.create()
   * const sandboxId = sandbox.sandboxId
   *
   * // Connect to the same sandbox.
   * const sameSandbox = await Sandbox.connect(sandboxId)
   * ```
   */
  static async connect(sandboxId, opts) {
    const sandbox = await SandboxApi.connectSandbox(sandboxId, opts);
    const config = new ConnectionConfig(opts);
    return new this(__spreadValues({
      sandboxId,
      sandboxDomain: sandbox.sandboxDomain,
      envdAccessToken: sandbox.envdAccessToken,
      trafficAccessToken: sandbox.trafficAccessToken,
      envdVersion: sandbox.envdVersion
    }, config));
  }
  /**
   * Connect to a sandbox. If the sandbox is paused, it will be automatically resumed.
   * Sandbox must be either running or be paused.
   *
   * With sandbox ID you can connect to the same sandbox from different places or environments (serverless functions, etc).
   *
   * @param opts connection options.
   *
   * @returns A running sandbox instance
   *
   * @example
   * ```ts
   * const sandbox = await Sandbox.create()
   * await sandbox.betaPause()
   *
   * // Connect to the same sandbox.
   * const sameSandbox = await sandbox.connect()
   * ```
   */
  async connect(opts) {
    await SandboxApi.connectSandbox(this.sandboxId, opts);
    return this;
  }
  /**
   * Get the host address for the specified sandbox port.
   * You can then use this address to connect to the sandbox port from outside the sandbox via HTTP or WebSocket.
   *
   * @param port number of the port in the sandbox.
   *
   * @returns host address of the sandbox port.
   *
   * @example
   * ```ts
   * const sandbox = await Sandbox.create()
   * // Start an HTTP server
   * await sandbox.commands.exec('python3 -m http.server 3000')
   * // Get the hostname of the HTTP server
   * const serverURL = sandbox.getHost(3000)
   * ```
   */
  getHost(port) {
    return this.connectionConfig.getHost(
      this.sandboxId,
      port,
      this.sandboxDomain
    );
  }
  /**
   * Check if the sandbox is running.
   *
   * @returns `true` if the sandbox is running, `false` otherwise.
   *
   * @example
   * ```ts
   * const sandbox = await Sandbox.create()
   * await sandbox.isRunning() // Returns true
   *
   * await sandbox.kill()
   * await sandbox.isRunning() // Returns false
   * ```
   */
  async isRunning(opts) {
    const signal = this.connectionConfig.getSignal(opts == null ? void 0 : opts.requestTimeoutMs);
    const res = await this.envdApi.api.GET("/health", {
      signal
    });
    if (res.response.status == 502) {
      return false;
    }
    const err = await handleEnvdApiError(res);
    if (err) {
      throw err;
    }
    return true;
  }
  /**
   * Set the timeout of the sandbox.
   *
   * This method can extend or reduce the sandbox timeout set when creating the sandbox or from the last call to `.setTimeout`.
   * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
   *
   * @param timeoutMs timeout in **milliseconds**.
   * @param opts connection options.
   */
  async setTimeout(timeoutMs, opts) {
    if (this.connectionConfig.debug) {
      return;
    }
    await SandboxApi.setTimeout(this.sandboxId, timeoutMs, __spreadValues(__spreadValues({}, this.connectionConfig), opts));
  }
  /**
   * Kill the sandbox.
   *
   * @param opts connection options.
   */
  async kill(opts) {
    if (this.connectionConfig.debug) {
      return;
    }
    await SandboxApi.kill(this.sandboxId, __spreadValues(__spreadValues({}, this.connectionConfig), opts));
  }
  /**
   * @beta This feature is in beta and may change in the future.
   *
   * Pause a sandbox by its ID.
   *
   * @param opts connection options.
   *
   * @returns sandbox ID that can be used to resume the sandbox.
   */
  async betaPause(opts) {
    return await SandboxApi.betaPause(this.sandboxId, opts);
  }
  /**
   *
   * Get the MCP URL for the sandbox.
   *
   * @returns MCP URL for the sandbox.
   */
  getMcpUrl() {
    return `https://${this.getHost(this.mcpPort)}/mcp`;
  }
  /**
   * Get the MCP token for the sandbox.
   *
   * @returns MCP token for the sandbox, or undefined if MCP is not enabled.
   */
  async getMcpToken() {
    if (!this.mcpToken) {
      this.mcpToken = await this.files.read("/etc/mcp-gateway/.token", {
        user: "root"
      });
    }
    return this.mcpToken;
  }
  /**
   * Get the URL to upload a file to the sandbox.
   *
   * You have to send a POST request to this URL with the file as multipart/form-data.
   *
   * @param path path to the file in the sandbox.
   *
   * @param opts download url options.
   *
   * @returns URL for uploading file.
   */
  async uploadUrl(path2, opts) {
    opts = opts != null ? opts : {};
    const useSignature = !!this.envdAccessToken;
    if (!useSignature && opts.useSignatureExpiration != void 0) {
      throw new Error(
        "Signature expiration can be used only when sandbox is created as secured."
      );
    }
    let username = opts.user;
    if (username == void 0 && (0, import_compare_versions5.compareVersions)(this.envdApi.version, ENVD_DEFAULT_USER) < 0) {
      username = defaultUsername;
    }
    const filePath = path2 != null ? path2 : "";
    const fileUrl = this.fileUrl(filePath, username);
    if (useSignature) {
      const url = new URL(fileUrl);
      const sig = await getSignature({
        path: filePath,
        operation: "write",
        user: username,
        expirationInSeconds: opts.useSignatureExpiration,
        envdAccessToken: this.envdAccessToken
      });
      url.searchParams.set("signature", sig.signature);
      if (sig.expiration) {
        url.searchParams.set("signature_expiration", sig.expiration.toString());
      }
      return url.toString();
    }
    return fileUrl;
  }
  /**
   * Get the URL to download a file from the sandbox.
   *
   * @param path path to the file in the sandbox.
   *
   * @param opts download url options.
   *
   * @returns URL for downloading file.
   */
  async downloadUrl(path2, opts) {
    opts = opts != null ? opts : {};
    const useSignature = !!this.envdAccessToken;
    if (!useSignature && opts.useSignatureExpiration != void 0) {
      throw new Error(
        "Signature expiration can be used only when sandbox is created as secured."
      );
    }
    let username = opts.user;
    if (username == void 0 && (0, import_compare_versions5.compareVersions)(this.envdApi.version, ENVD_DEFAULT_USER) < 0) {
      username = defaultUsername;
    }
    const fileUrl = this.fileUrl(path2, username);
    if (useSignature) {
      const url = new URL(fileUrl);
      const sig = await getSignature({
        path: path2,
        operation: "read",
        user: username,
        expirationInSeconds: opts.useSignatureExpiration,
        envdAccessToken: this.envdAccessToken
      });
      url.searchParams.set("signature", sig.signature);
      if (sig.expiration) {
        url.searchParams.set("signature_expiration", sig.expiration.toString());
      }
      return url.toString();
    }
    return fileUrl;
  }
  /**
   * Get sandbox information like sandbox ID, template, metadata, started at/end at date.
   *
   * @param opts connection options.
   *
   * @returns information about the sandbox
   */
  async getInfo(opts) {
    return await SandboxApi.getInfo(this.sandboxId, __spreadValues(__spreadValues({}, this.connectionConfig), opts));
  }
  /**
   * Get the metrics of the sandbox.
   *
   * @param opts connection options.
   *
   * @returns  List of sandbox metrics containing CPU, memory and disk usage information.
   */
  async getMetrics(opts) {
    var _a3, _b;
    if (this.envdApi.version) {
      if ((0, import_compare_versions5.compareVersions)(this.envdApi.version, "0.1.5") < 0) {
        throw new SandboxError(
          "You need to update the template to use the new SDK. You can do this by running `e2b template build` in the directory with the template."
        );
      }
      if ((0, import_compare_versions5.compareVersions)(this.envdApi.version, "0.2.4") < 0) {
        (_b = (_a3 = this.connectionConfig.logger) == null ? void 0 : _a3.warn) == null ? void 0 : _b.call(
          _a3,
          "Disk metrics are not supported in this version of the sandbox, please rebuild the template to get disk metrics."
        );
      }
    }
    return await SandboxApi.getMetrics(this.sandboxId, __spreadValues(__spreadValues({}, this.connectionConfig), opts));
  }
  fileUrl(path2, username) {
    const url = new URL("/files", this.envdApiUrl);
    if (username) {
      url.searchParams.set("username", username);
    }
    if (path2) {
      url.searchParams.set("path", path2);
    }
    return url.toString();
  }
};
Sandbox.defaultTemplate = "base";
Sandbox.defaultMcpTemplate = "mcp-gateway";
Sandbox.defaultSandboxTimeoutMs = DEFAULT_SANDBOX_TIMEOUT_MS;

// src/template/logger.ts
var import_chalk = __toESM(require("chalk"));
var LogEntry = class {
  constructor(timestamp, level, message) {
    this.timestamp = timestamp;
    this.level = level;
    this.message = message;
  }
  toString() {
    return `[${this.timestamp.toISOString()}] [${this.level}] ${stripAnsi(
      this.message
    )}`;
  }
};
var LogEntryStart = class extends LogEntry {
  constructor(timestamp, message) {
    super(timestamp, "debug", message);
  }
};
var LogEntryEnd = class extends LogEntry {
  constructor(timestamp, message) {
    super(timestamp, "debug", message);
  }
};
var TIMER_UPDATE_INTERVAL_MS = 150;
var DEFAULT_LEVEL = "info";
var levels = {
  error: import_chalk.default.red("ERROR"),
  warn: import_chalk.default.hex("#FF4400")("WARN "),
  info: import_chalk.default.hex("#FF8800")("INFO "),
  debug: import_chalk.default.gray("DEBUG")
};
var level_order = {
  debug: 0,
  info: 1,
  warn: 2,
  error: 3
};
var DefaultBuildLogger = class {
  constructor(minLevel) {
    this.minLevel = minLevel != null ? minLevel : DEFAULT_LEVEL;
    this.state = this.getInitialState();
  }
  logger(logEntry) {
    if (logEntry instanceof LogEntryStart) {
      this.startTimer();
      return;
    }
    if (logEntry instanceof LogEntryEnd) {
      clearInterval(this.state.timerInterval);
      return;
    }
    if (level_order[logEntry.level] < level_order[this.minLevel]) {
      return;
    }
    const formattedLine = this.formatLogLine(logEntry);
    process.stdout.write(`${formattedLine}
`);
    this.updateTimer();
  }
  getInitialState(timerInterval) {
    return {
      startTime: Date.now(),
      animationFrame: 0,
      timerInterval
    };
  }
  formatTimerLine() {
    const elapsedSeconds = ((Date.now() - this.state.startTime) / 1e3).toFixed(
      1
    );
    return `${elapsedSeconds}s`;
  }
  animateStatus() {
    const frames = ["\u28FE", "\u28FD", "\u28FB", "\u28BF", "\u287F", "\u28DF", "\u28EF", "\u28F7"];
    const idx = this.state.animationFrame % frames.length;
    return `${frames[idx]}`;
  }
  formatLogLine(line) {
    const timer = this.formatTimerLine().padEnd(5);
    const timestamp = import_chalk.default.dim(
      line.timestamp.toLocaleTimeString(void 0, {
        hour: "2-digit",
        minute: "2-digit",
        second: "2-digit"
      })
    );
    const level = levels[line.level] || levels[DEFAULT_LEVEL];
    const msg = line.message;
    return `${timer} | ${timestamp} ${level} ${msg}`;
  }
  startTimer() {
    if (!process.stdout.isTTY) {
      return;
    }
    const timerInterval = setInterval(
      this.updateTimer.bind(this),
      TIMER_UPDATE_INTERVAL_MS
    );
    this.state = this.getInitialState(timerInterval);
    this.updateTimer();
  }
  updateTimer() {
    if (!process.stdout.isTTY) {
      return;
    }
    this.state.animationFrame++;
    const jumpingSquares = this.animateStatus();
    process.stdout.write(
      `${jumpingSquares} Building ${this.formatTimerLine()}\r`
    );
  }
};
function defaultBuildLogger(options) {
  const buildLogger = new DefaultBuildLogger(options == null ? void 0 : options.minLevel);
  return buildLogger.logger.bind(buildLogger);
}

// src/template/utils.ts
var import_node_crypto = __toESM(require("crypto"));
var import_node_fs = __toESM(require("fs"));
var import_node_path = __toESM(require("path"));

// src/template/consts.ts
var FINALIZE_STEP_NAME = "finalize";
var BASE_STEP_NAME = "base";
var STACK_TRACE_DEPTH = 3;
var RESOLVE_SYMLINKS = false;

// src/template/utils.ts
function normalizeBuildArguments(nameOrOptions, options) {
  let name;
  let buildOptions;
  if (typeof nameOrOptions === "string") {
    name = nameOrOptions;
    buildOptions = options != null ? options : {};
  } else {
    const _a3 = nameOrOptions, { alias } = _a3, restOpts = __objRest(_a3, ["alias"]);
    name = alias;
    buildOptions = restOpts;
  }
  if (!name || name.length === 0) {
    throw new TemplateError("Name must be provided");
  }
  return { name, buildOptions };
}
function readDockerignore(contextPath) {
  const dockerignorePath = import_node_path.default.join(contextPath, ".dockerignore");
  if (!import_node_fs.default.existsSync(dockerignorePath)) {
    return [];
  }
  const content = import_node_fs.default.readFileSync(dockerignorePath, "utf-8");
  return content.split("\n").map((line) => line.trim()).filter((line) => line && !line.startsWith("#"));
}
function normalizePath(path2) {
  return path2.replace(/\\/g, "/");
}
async function getAllFilesInPath(src, contextPath, ignorePatterns, includeDirectories = true) {
  const { glob } = await dynamicImport("glob");
  const files = /* @__PURE__ */ new Map();
  const globFiles = await glob(src, {
    ignore: ignorePatterns,
    withFileTypes: true,
    // this is required so that the ignore pattern is relative to the file path
    cwd: contextPath
  });
  for (const file of globFiles) {
    if (file.isDirectory()) {
      if (includeDirectories) {
        files.set(file.fullpath(), file);
      }
      const dirPattern = normalizePath(
        // When the matched directory is '.', `file.relative()` can be an empty string.
        // In that case, we want to match all files under the current directory instead of
        // creating an absolute glob like '/**/*' which would traverse the entire filesystem.
        import_node_path.default.join(file.relative() || ".", "**/*")
      );
      const dirFiles = await glob(dirPattern, {
        ignore: ignorePatterns,
        withFileTypes: true,
        cwd: contextPath
      });
      dirFiles.forEach((f) => files.set(f.fullpath(), f));
    } else {
      files.set(file.fullpath(), file);
    }
  }
  return Array.from(files.values()).sort();
}
async function calculateFilesHash(src, dest, contextPath, ignorePatterns, resolveSymlinks, stackTrace) {
  const srcPath = import_node_path.default.join(contextPath, src);
  const hash = import_node_crypto.default.createHash("sha256");
  const content = `COPY ${src} ${dest}`;
  hash.update(content);
  const files = await getAllFilesInPath(src, contextPath, ignorePatterns, true);
  if (files.length === 0) {
    const error = new Error(`No files found in ${srcPath}`);
    if (stackTrace) {
      error.stack = stackTrace;
    }
    throw error;
  }
  const hashStats = (stats) => {
    hash.update(stats.mode.toString());
    hash.update(stats.size.toString());
  };
  for (const file of files) {
    const relativePath = file.relativePosix();
    hash.update(relativePath);
    if (file.isSymbolicLink()) {
      const stats2 = import_node_fs.default.statSync(file.fullpath(), { throwIfNoEntry: false });
      const shouldFollow = resolveSymlinks && ((stats2 == null ? void 0 : stats2.isFile()) || (stats2 == null ? void 0 : stats2.isDirectory()));
      if (!shouldFollow) {
        const stats3 = import_node_fs.default.lstatSync(file.fullpath());
        hashStats(stats3);
        const content2 = import_node_fs.default.readlinkSync(file.fullpath());
        hash.update(content2);
        continue;
      }
    }
    const stats = import_node_fs.default.statSync(file.fullpath());
    hashStats(stats);
    if (stats.isFile()) {
      const content2 = import_node_fs.default.readFileSync(file.fullpath());
      hash.update(new Uint8Array(content2));
    }
  }
  return hash.digest("hex");
}
function getCallerFrame(depth) {
  const stackTrace = new Error().stack;
  if (!stackTrace) {
    return;
  }
  const lines = stackTrace.split("\n").slice(1);
  if (lines.length < depth + 1) {
    return;
  }
  return lines.slice(depth).join("\n");
}
function callsites(depth) {
  const _originalPrepareStackTrace = Error.prepareStackTrace;
  try {
    let result = [];
    Error.prepareStackTrace = (_, callSites) => {
      const callSitesWithoutCurrent = callSites.slice(depth);
      result = callSitesWithoutCurrent;
      return callSitesWithoutCurrent;
    };
    new Error().stack;
    return result;
  } finally {
    Error.prepareStackTrace = _originalPrepareStackTrace;
  }
}
function getCallerDirectory(depth) {
  const callSites = callsites(depth + 1);
  if (callSites.length === 0) {
    return void 0;
  }
  let fileName = callSites[0].getFileName();
  if (!fileName) {
    return void 0;
  }
  if (fileName.startsWith("file:")) {
    const { fileURLToPath } = dynamicRequire("node:url");
    fileName = fileURLToPath(fileName);
  }
  return import_node_path.default.dirname(fileName);
}
function padOctal(mode) {
  return mode.toString(8).padStart(4, "0");
}
async function tarFileStream(fileName, fileContextPath, ignorePatterns, resolveSymlinks) {
  const { create } = await dynamicImport("tar");
  const allFiles = await getAllFilesInPath(
    fileName,
    fileContextPath,
    ignorePatterns,
    true
  );
  const filePaths = allFiles.map((file) => file.relativePosix());
  return create(
    {
      gzip: { portable: true },
      cwd: fileContextPath,
      follow: resolveSymlinks,
      noDirRecurse: true
    },
    filePaths
  );
}
async function tarFileStreamUpload(fileName, fileContextPath, ignorePatterns, resolveSymlinks) {
  const sizeCalculationStream = await tarFileStream(
    fileName,
    fileContextPath,
    ignorePatterns,
    resolveSymlinks
  );
  let contentLength = 0;
  try {
    for (var iter = __forAwait(sizeCalculationStream), more, temp, error; more = !(temp = await iter.next()).done; more = false) {
      const chunk = temp.value;
      contentLength += chunk.length;
    }
  } catch (temp) {
    error = [temp];
  } finally {
    try {
      more && (temp = iter.return) && await temp.call(iter);
    } finally {
      if (error)
        throw error[0];
    }
  }
  return {
    contentLength,
    uploadStream: await tarFileStream(
      fileName,
      fileContextPath,
      ignorePatterns,
      resolveSymlinks
    )
  };
}
function getBuildStepIndex(step, stackTracesLength) {
  if (step === BASE_STEP_NAME) {
    return 0;
  }
  if (step === FINALIZE_STEP_NAME) {
    return stackTracesLength - 1;
  }
  return Number(step);
}
function readGCPServiceAccountJSON(contextPath, pathOrContent) {
  if (typeof pathOrContent === "string") {
    return import_node_fs.default.readFileSync(import_node_path.default.join(contextPath, pathOrContent), "utf-8");
  }
  return JSON.stringify(pathOrContent);
}

// src/template/buildApi.ts
async function requestBuild(client, { name, tags, cpuCount, memoryMB }) {
  const requestBuildRes = await client.api.POST("/v3/templates", {
    body: {
      name,
      tags,
      cpuCount,
      memoryMB
    }
  });
  const error = handleApiError(requestBuildRes, BuildError);
  if (error) {
    throw error;
  }
  if (!requestBuildRes.data) {
    throw new BuildError("Failed to request build");
  }
  return requestBuildRes.data;
}
async function getFileUploadLink(client, { templateID, filesHash }, stackTrace) {
  const fileUploadLinkRes = await client.api.GET(
    "/templates/{templateID}/files/{hash}",
    {
      params: {
        path: {
          templateID,
          hash: filesHash
        }
      }
    }
  );
  const error = handleApiError(fileUploadLinkRes, FileUploadError, stackTrace);
  if (error) {
    throw error;
  }
  if (!fileUploadLinkRes.data) {
    throw new FileUploadError("Failed to get file upload link", stackTrace);
  }
  return fileUploadLinkRes.data;
}
async function uploadFile(options, stackTrace) {
  const { fileName, url, fileContextPath, ignorePatterns, resolveSymlinks } = options;
  try {
    const { contentLength, uploadStream } = await tarFileStreamUpload(
      fileName,
      fileContextPath,
      ignorePatterns,
      resolveSymlinks
    );
    const res = await fetch(url, {
      method: "PUT",
      // @ts-expect-error
      body: uploadStream,
      headers: {
        "Content-Length": contentLength.toString()
      },
      duplex: "half"
    });
    if (!res.ok) {
      throw new FileUploadError(
        `Failed to upload file: ${res.statusText}`,
        stackTrace
      );
    }
  } catch (error) {
    if (error instanceof FileUploadError) {
      throw error;
    }
    throw new FileUploadError(`Failed to upload file: ${error}`, stackTrace);
  }
}
async function triggerBuild(client, { templateID, buildID, template }) {
  const triggerBuildRes = await client.api.POST(
    "/v2/templates/{templateID}/builds/{buildID}",
    {
      params: {
        path: {
          templateID,
          buildID
        }
      },
      body: template
    }
  );
  const error = handleApiError(triggerBuildRes, BuildError);
  if (error) {
    throw error;
  }
}
function mapLogEntry(entry) {
  return new LogEntry(new Date(entry.timestamp), entry.level, entry.message);
}
function mapBuildStatusReason(reason) {
  var _a3;
  if (!reason) {
    return void 0;
  }
  return {
    message: reason.message,
    step: reason.step,
    logEntries: ((_a3 = reason.logEntries) != null ? _a3 : []).map(mapLogEntry)
  };
}
async function getBuildStatus(client, { templateID, buildID, logsOffset }) {
  const buildStatusRes = await client.api.GET(
    "/templates/{templateID}/builds/{buildID}/status",
    {
      params: {
        path: {
          templateID,
          buildID
        },
        query: {
          logsOffset
        }
      }
    }
  );
  const error = handleApiError(buildStatusRes, BuildError);
  if (error) {
    throw error;
  }
  if (!buildStatusRes.data) {
    throw new BuildError("Failed to get build status");
  }
  return {
    buildID: buildStatusRes.data.buildID,
    templateID: buildStatusRes.data.templateID,
    status: buildStatusRes.data.status,
    logEntries: buildStatusRes.data.logEntries.map(mapLogEntry),
    logs: buildStatusRes.data.logs,
    reason: mapBuildStatusReason(buildStatusRes.data.reason)
  };
}
async function checkAliasExists(client, { alias }) {
  const aliasRes = await client.api.GET("/templates/aliases/{alias}", {
    params: {
      path: {
        alias
      }
    }
  });
  if (aliasRes.response.status === 404) {
    return false;
  }
  if (aliasRes.response.status === 403) {
    return true;
  }
  const error = handleApiError(aliasRes, TemplateError);
  if (error) {
    throw error;
  }
  return aliasRes.data !== void 0;
}
async function waitForBuildFinish(client, {
  templateID,
  buildID,
  onBuildLogs,
  logsRefreshFrequency,
  stackTraces
}) {
  var _a3, _b, _c;
  let logsOffset = 0;
  let status = "building";
  while (status === "building" || status === "waiting") {
    const buildStatus = await getBuildStatus(client, {
      templateID,
      buildID,
      logsOffset
    });
    logsOffset += buildStatus.logEntries.length;
    buildStatus.logEntries.forEach(
      (logEntry) => onBuildLogs == null ? void 0 : onBuildLogs(
        new LogEntry(
          logEntry.timestamp,
          logEntry.level,
          stripAnsi(logEntry.message)
        )
      )
    );
    status = buildStatus.status;
    switch (status) {
      case "ready": {
        return;
      }
      case "waiting": {
        break;
      }
      case "error": {
        let stackError;
        if (((_a3 = buildStatus.reason) == null ? void 0 : _a3.step) !== void 0) {
          const step = getBuildStepIndex(
            buildStatus.reason.step,
            stackTraces.length
          );
          stackError = stackTraces[step];
        }
        throw new BuildError(
          (_c = (_b = buildStatus == null ? void 0 : buildStatus.reason) == null ? void 0 : _b.message) != null ? _c : "Unknown error",
          stackError
        );
      }
    }
    await new Promise((resolve) => setTimeout(resolve, logsRefreshFrequency));
  }
  throw new BuildError("Unknown build error occurred.");
}
async function assignTags(client, { targetName, tags }) {
  const res = await client.api.POST("/templates/tags", {
    body: { target: targetName, tags }
  });
  const error = handleApiError(res, TemplateError);
  if (error) {
    throw error;
  }
  if (!res.data) {
    throw new TemplateError("Failed to assign tags");
  }
  return {
    buildId: res.data.buildID,
    tags: res.data.tags
  };
}
async function removeTags(client, { name, tags }) {
  const res = await client.api.DELETE("/templates/tags", {
    body: { name, tags }
  });
  const error = handleApiError(res, TemplateError);
  if (error) {
    throw error;
  }
}

// src/template/dockerfileParser.ts
var import_dockerfile_ast = require("dockerfile-ast");
var import_node_fs2 = __toESM(require("fs"));

// src/template/readycmd.ts
var ReadyCmd = class {
  constructor(cmd) {
    this.cmd = cmd;
  }
  getCmd() {
    return this.cmd;
  }
};
function waitForPort(port) {
  const cmd = `ss -tuln | grep :${port}`;
  return new ReadyCmd(cmd);
}
function waitForURL(url, statusCode = 200) {
  const cmd = `curl -s -o /dev/null -w "%{http_code}" ${url} | grep -q "${statusCode}"`;
  return new ReadyCmd(cmd);
}
function waitForProcess(processName) {
  const cmd = `pgrep ${processName} > /dev/null`;
  return new ReadyCmd(cmd);
}
function waitForFile(filename) {
  const cmd = `[ -f ${filename} ]`;
  return new ReadyCmd(cmd);
}
function waitForTimeout(timeout) {
  const seconds = Math.max(1, Math.floor(timeout / 1e3));
  const cmd = `sleep ${seconds}`;
  return new ReadyCmd(cmd);
}

// src/template/dockerfileParser.ts
function parseDockerfile(dockerfileContentOrPath, templateBuilder) {
  let dockerfileContent;
  try {
    if (import_node_fs2.default.existsSync(dockerfileContentOrPath) && import_node_fs2.default.statSync(dockerfileContentOrPath).isFile()) {
      dockerfileContent = import_node_fs2.default.readFileSync(dockerfileContentOrPath, "utf-8");
    } else {
      dockerfileContent = dockerfileContentOrPath;
    }
  } catch (e) {
    dockerfileContent = dockerfileContentOrPath;
  }
  const dockerfile = import_dockerfile_ast.DockerfileParser.parse(dockerfileContent);
  const instructions = dockerfile.getInstructions();
  const fromInstructions = instructions.filter(
    (instruction) => instruction.getKeyword() === "FROM"
  );
  if (fromInstructions.length > 1) {
    throw new Error("Multi-stage Dockerfiles are not supported");
  }
  if (fromInstructions.length === 0) {
    throw new Error("Dockerfile must contain a FROM instruction");
  }
  const fromInstruction = fromInstructions[0];
  const argumentsData = fromInstruction.getArguments();
  let baseImage = "e2bdev/base";
  let userChanged = false;
  let workdirChanged = false;
  if (argumentsData && argumentsData.length > 0) {
    baseImage = argumentsData[0].getValue();
  }
  templateBuilder.setUser("root");
  templateBuilder.setWorkdir("/");
  for (const instruction of instructions) {
    const keyword = instruction.getKeyword();
    switch (keyword) {
      case "FROM":
        break;
      case "RUN":
        handleRunInstruction(instruction, templateBuilder);
        break;
      case "COPY":
      case "ADD":
        handleCopyInstruction(
          instruction,
          templateBuilder
        );
        break;
      case "WORKDIR":
        handleWorkdirInstruction(instruction, templateBuilder);
        workdirChanged = true;
        break;
      case "USER":
        handleUserInstruction(instruction, templateBuilder);
        userChanged = true;
        break;
      case "ENV":
      case "ARG":
        handleEnvInstruction(instruction, templateBuilder);
        break;
      case "EXPOSE":
        break;
      case "VOLUME":
        break;
      case "CMD":
      case "ENTRYPOINT":
        handleCmdEntrypointInstruction(instruction, templateBuilder);
        break;
      default:
        console.warn(`Unsupported instruction: ${keyword}`);
        break;
    }
  }
  if (!userChanged) {
    templateBuilder.setUser("user");
  }
  if (!workdirChanged) {
    templateBuilder.setWorkdir("/home/user");
  }
  return {
    baseImage
  };
}
function handleRunInstruction(instruction, templateBuilder) {
  const argumentsData = instruction.getArguments();
  if (argumentsData && argumentsData.length > 0) {
    const command = argumentsData.map((arg) => arg.getValue()).join(" ");
    templateBuilder.runCmd(command);
  }
}
function handleCopyInstruction(instruction, templateBuilder) {
  var _a3;
  const argumentsData = instruction.getArguments();
  if (argumentsData && argumentsData.length >= 2) {
    const src = argumentsData[0].getValue();
    const dest = argumentsData[argumentsData.length - 1].getValue();
    let user;
    const flags = instruction.getFlags();
    const chownFlag = flags.find((flag) => flag.getName() === "chown");
    if (chownFlag) {
      user = (_a3 = chownFlag.getValue()) != null ? _a3 : void 0;
    }
    templateBuilder.copy(src, dest, { user });
  }
}
function handleWorkdirInstruction(instruction, templateBuilder) {
  const argumentsData = instruction.getArguments();
  if (argumentsData && argumentsData.length > 0) {
    const workdir = argumentsData[0].getValue();
    templateBuilder.setWorkdir(workdir);
  }
}
function handleUserInstruction(instruction, templateBuilder) {
  const argumentsData = instruction.getArguments();
  if (argumentsData && argumentsData.length > 0) {
    const user = argumentsData[0].getValue();
    templateBuilder.setUser(user);
  }
}
function handleEnvInstruction(instruction, templateBuilder) {
  const argumentsData = instruction.getArguments();
  const keyword = instruction.getKeyword();
  if (argumentsData && argumentsData.length >= 1) {
    const envVars = {};
    if (argumentsData.length === 2) {
      const firstArg = argumentsData[0].getValue();
      const secondArg = argumentsData[1].getValue();
      if (firstArg.includes("=") && secondArg.includes("=")) {
        for (const arg of argumentsData) {
          const envString = arg.getValue();
          const equalIndex = envString.indexOf("=");
          if (equalIndex > 0) {
            const key = envString.substring(0, equalIndex);
            const value = envString.substring(equalIndex + 1);
            envVars[key] = value;
          }
        }
      } else {
        envVars[firstArg] = secondArg;
      }
    } else if (argumentsData.length === 1) {
      const envString = argumentsData[0].getValue();
      const equalIndex = envString.indexOf("=");
      if (equalIndex > 0) {
        const key = envString.substring(0, equalIndex);
        const value = envString.substring(equalIndex + 1);
        envVars[key] = value;
      } else if (keyword === "ARG" && envString.trim()) {
        const key = envString.trim();
        envVars[key] = "";
      }
    } else {
      for (const arg of argumentsData) {
        const envString = arg.getValue();
        const equalIndex = envString.indexOf("=");
        if (equalIndex > 0) {
          const key = envString.substring(0, equalIndex);
          const value = envString.substring(equalIndex + 1);
          envVars[key] = value;
        } else if (keyword === "ARG") {
          const key = envString;
          envVars[key] = "";
        }
      }
    }
    if (Object.keys(envVars).length > 0) {
      templateBuilder.setEnvs(envVars);
    }
  }
}
function handleCmdEntrypointInstruction(instruction, templateBuilder) {
  const argumentsData = instruction.getArguments();
  if (argumentsData && argumentsData.length > 0) {
    let command = argumentsData.map((arg) => arg.getValue()).join(" ");
    try {
      const parsedCommand = JSON.parse(command);
      if (Array.isArray(parsedCommand)) {
        command = parsedCommand.join(" ");
      }
    } catch (e) {
    }
    templateBuilder.setStartCmd(command, waitForTimeout(2e4));
  }
}

// src/template/index.ts
var _a2;
var TemplateBase = class _TemplateBase {
  constructor(options) {
    this.defaultBaseImage = "e2bdev/base";
    this.baseImage = this.defaultBaseImage;
    this.baseTemplate = void 0;
    this.registryConfig = void 0;
    this.startCmd = void 0;
    this.readyCmd = void 0;
    // Force the whole template to be rebuilt
    this.force = false;
    // Force the next layer to be rebuilt
    this.forceNextLayer = false;
    this.instructions = [];
    this.fileContextPath = runtime === "browser" ? "." : (_a2 = getCallerDirectory(STACK_TRACE_DEPTH)) != null ? _a2 : ".";
    this.fileIgnorePatterns = [];
    this.logsRefreshFrequency = 200;
    this.stackTraces = [];
    this.stackTracesEnabled = true;
    this.stackTracesOverride = void 0;
    var _a3, _b;
    this.fileContextPath = (_a3 = options == null ? void 0 : options.fileContextPath) != null ? _a3 : this.fileContextPath;
    this.fileIgnorePatterns = (_b = options == null ? void 0 : options.fileIgnorePatterns) != null ? _b : this.fileIgnorePatterns;
  }
  /**
   * Convert a template to JSON representation.
   *
   * @param template The template to convert
   * @param computeHashes Whether to compute file hashes for cache invalidation
   * @returns JSON string representation of the template
   */
  static toJSON(template, computeHashes = true) {
    return template.toJSON(computeHashes);
  }
  /**
   * Convert a template to Dockerfile format.
   * Note: Templates based on other E2B templates cannot be converted to Dockerfile.
   *
   * @param template The template to convert
   * @returns Dockerfile string representation
   * @throws Error if the template is based on another E2B template
   */
  static toDockerfile(template) {
    return template.toDockerfile();
  }
  static async build(template, nameOrOptions, options) {
    var _a3, _b, _c;
    const { name, buildOptions } = normalizeBuildArguments(
      nameOrOptions,
      options
    );
    try {
      (_a3 = buildOptions.onBuildLogs) == null ? void 0 : _a3.call(buildOptions, new LogEntryStart(/* @__PURE__ */ new Date(), "Build started"));
      const baseTemplate = template;
      const config = new ConnectionConfig(buildOptions);
      const client = new ApiClient(config);
      const data = await baseTemplate.build(client, name, buildOptions);
      (_b = buildOptions.onBuildLogs) == null ? void 0 : _b.call(
        buildOptions,
        new LogEntry(/* @__PURE__ */ new Date(), "info", "Waiting for logs...")
      );
      await waitForBuildFinish(client, {
        templateID: data.templateId,
        buildID: data.buildId,
        onBuildLogs: buildOptions.onBuildLogs,
        logsRefreshFrequency: baseTemplate.logsRefreshFrequency,
        stackTraces: baseTemplate.stackTraces
      });
      return data;
    } finally {
      (_c = buildOptions.onBuildLogs) == null ? void 0 : _c.call(buildOptions, new LogEntryEnd(/* @__PURE__ */ new Date(), "Build finished"));
    }
  }
  static async buildInBackground(template, nameOrOptions, options) {
    const { name, buildOptions } = normalizeBuildArguments(
      nameOrOptions,
      options
    );
    const config = new ConnectionConfig(buildOptions);
    const client = new ApiClient(config);
    return template.build(client, name, buildOptions);
  }
  /**
   * Get the status of a build.
   *
   * @param data Build identifiers
   * @param options Authentication options
   *
   * @example
   * ```ts
   * const status = await Template.getBuildStatus(data, { logsOffset: 0 })
   * ```
   */
  static async getBuildStatus(data, options) {
    const config = new ConnectionConfig(options);
    const client = new ApiClient(config);
    return await getBuildStatus(client, {
      templateID: data.templateId,
      buildID: data.buildId,
      logsOffset: options == null ? void 0 : options.logsOffset
    });
  }
  /**
   * Check if a template with the given name exists.
   *
   * @param name Template name to check
   * @param options Authentication options
   * @returns True if the name exists, false otherwise
   *
   * @example
   * ```ts
   * const exists = await Template.exists('my-python-env')
   * if (exists) {
   *   console.log('Template exists!')
   * }
   * ```
   */
  static async exists(name, options) {
    return _TemplateBase.aliasExists(name, options);
  }
  /**
   * Check if a template with the given alias exists.
   *
   * @param alias Template alias to check
   * @param options Authentication options
   * @returns True if the alias exists, false otherwise
   *
   * @deprecated Use `exists` instead.
   * @example
   * ```ts
   * const exists = await Template.aliasExists('my-python-env')
   * if (exists) {
   *   console.log('Template exists!')
   * }
   * ```
   */
  static async aliasExists(alias, options) {
    const config = new ConnectionConfig(options);
    const client = new ApiClient(config);
    return checkAliasExists(client, { alias });
  }
  /**
   * Assign tag(s) to an existing template build.
   *
   * @param targetName Template name in 'name:tag' format (the source build to tag from)
   * @param tags Tag or tags to assign
   * @param options Authentication options
   * @returns Tag info with buildId and assigned tags
   *
   * @example
   * ```ts
   * // Assign a single tag
   * await Template.assignTags('my-template:v1.0', 'production')
   *
   * // Assign multiple tags
   * await Template.assignTags('my-template:v1.0', ['production', 'stable'])
   * ```
   */
  static async assignTags(targetName, tags, options) {
    const config = new ConnectionConfig(options);
    const client = new ApiClient(config);
    const normalizedTags = Array.isArray(tags) ? tags : [tags];
    return assignTags(client, { targetName, tags: normalizedTags });
  }
  /**
   * Remove tag(s) from a template.
   *
   * @param name Template name
   * @param tags Tag or tags to remove
   * @param options Authentication options
   *
   * @example
   * ```ts
   * // Remove a single tag
   * await Template.removeTags('my-template', 'production')
   *
   * // Remove multiple tags from a template
   * await Template.removeTags('my-template', ['production', 'staging'])
   * ```
   */
  static async removeTags(name, tags, options) {
    const config = new ConnectionConfig(options);
    const client = new ApiClient(config);
    const normalizedTags = Array.isArray(tags) ? tags : [tags];
    return removeTags(client, { name, tags: normalizedTags });
  }
  fromDebianImage(variant = "stable") {
    return this.fromImage(`debian:${variant}`);
  }
  fromUbuntuImage(variant = "latest") {
    return this.fromImage(`ubuntu:${variant}`);
  }
  fromPythonImage(version2 = "3") {
    return this.fromImage(`python:${version2}`);
  }
  fromNodeImage(variant = "lts") {
    return this.fromImage(`node:${variant}`);
  }
  fromBunImage(variant = "latest") {
    return this.fromImage(`oven/bun:${variant}`);
  }
  fromBaseImage() {
    return this.fromImage(this.defaultBaseImage);
  }
  fromImage(baseImage, credentials) {
    this.baseImage = baseImage;
    this.baseTemplate = void 0;
    if (credentials) {
      this.registryConfig = {
        type: "registry",
        username: credentials.username,
        password: credentials.password
      };
    }
    if (this.forceNextLayer) {
      this.force = true;
    }
    this.collectStackTrace();
    return this;
  }
  fromTemplate(template) {
    this.baseTemplate = template;
    this.baseImage = void 0;
    if (this.forceNextLayer) {
      this.force = true;
    }
    this.collectStackTrace();
    return this;
  }
  fromDockerfile(dockerfileContentOrPath) {
    const { baseImage } = this.runInStackTraceOverrideContext(
      () => parseDockerfile(dockerfileContentOrPath, this),
      // -1 as we're going up the call stack from the parseDockerfile function
      getCallerFrame(STACK_TRACE_DEPTH - 1)
    );
    this.baseImage = baseImage;
    this.baseTemplate = void 0;
    if (this.forceNextLayer) {
      this.force = true;
    }
    this.collectStackTrace();
    return this;
  }
  fromAWSRegistry(image, credentials) {
    this.baseImage = image;
    this.baseTemplate = void 0;
    this.registryConfig = {
      type: "aws",
      awsAccessKeyId: credentials.accessKeyId,
      awsSecretAccessKey: credentials.secretAccessKey,
      awsRegion: credentials.region
    };
    if (this.forceNextLayer) {
      this.force = true;
    }
    this.collectStackTrace();
    return this;
  }
  fromGCPRegistry(image, credentials) {
    this.baseImage = image;
    this.baseTemplate = void 0;
    this.registryConfig = {
      type: "gcp",
      serviceAccountJson: readGCPServiceAccountJSON(
        this.fileContextPath.toString(),
        credentials.serviceAccountJSON
      )
    };
    if (this.forceNextLayer) {
      this.force = true;
    }
    this.collectStackTrace();
    return this;
  }
  copy(src, dest, options) {
    var _a3;
    if (runtime === "browser") {
      throw new Error("Browser runtime is not supported for copy");
    }
    const srcs = Array.isArray(src) ? src : [src];
    for (const src2 of srcs) {
      const args = [
        src2.toString(),
        dest.toString(),
        (_a3 = options == null ? void 0 : options.user) != null ? _a3 : "",
        (options == null ? void 0 : options.mode) ? padOctal(options.mode) : ""
      ];
      this.instructions.push({
        type: "COPY" /* COPY */,
        args,
        force: (options == null ? void 0 : options.forceUpload) || this.forceNextLayer,
        forceUpload: options == null ? void 0 : options.forceUpload,
        resolveSymlinks: options == null ? void 0 : options.resolveSymlinks
      });
    }
    this.collectStackTrace();
    return this;
  }
  copyItems(items) {
    if (runtime === "browser") {
      throw new Error("Browser runtime is not supported for copyItems");
    }
    this.runInNewStackTraceContext(() => {
      for (const item of items) {
        this.copy(item.src, item.dest, {
          forceUpload: item.forceUpload,
          user: item.user,
          mode: item.mode,
          resolveSymlinks: item.resolveSymlinks
        });
      }
    });
    return this;
  }
  remove(path2, options) {
    const paths2 = Array.isArray(path2) ? path2 : [path2];
    const args = ["rm"];
    if (options == null ? void 0 : options.recursive) {
      args.push("-r");
    }
    if (options == null ? void 0 : options.force) {
      args.push("-f");
    }
    args.push(...paths2.map((p) => p.toString()));
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), { user: options == null ? void 0 : options.user })
    );
  }
  rename(src, dest, options) {
    const args = ["mv", src.toString(), dest.toString()];
    if (options == null ? void 0 : options.force) {
      args.push("-f");
    }
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), { user: options == null ? void 0 : options.user })
    );
  }
  makeDir(path2, options) {
    const paths2 = Array.isArray(path2) ? path2 : [path2];
    const args = ["mkdir", "-p"];
    if (options == null ? void 0 : options.mode) {
      args.push(`-m ${padOctal(options.mode)}`);
    }
    args.push(...paths2.map((p) => p.toString()));
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), { user: options == null ? void 0 : options.user })
    );
  }
  makeSymlink(src, dest, options) {
    const args = ["ln", "-s"];
    if (options == null ? void 0 : options.force) {
      args.push("-f");
    }
    args.push(src.toString(), dest.toString());
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), { user: options == null ? void 0 : options.user })
    );
  }
  runCmd(commandOrCommands, options) {
    const cmds = Array.isArray(commandOrCommands) ? commandOrCommands : [commandOrCommands];
    const args = [cmds.join(" && ")];
    if (options == null ? void 0 : options.user) {
      args.push(options.user);
    }
    this.instructions.push({
      type: "RUN" /* RUN */,
      args,
      force: this.forceNextLayer
    });
    this.collectStackTrace();
    return this;
  }
  setWorkdir(workdir) {
    this.instructions.push({
      type: "WORKDIR" /* WORKDIR */,
      args: [workdir.toString()],
      force: this.forceNextLayer
    });
    this.collectStackTrace();
    return this;
  }
  setUser(user) {
    this.instructions.push({
      type: "USER" /* USER */,
      args: [user],
      force: this.forceNextLayer
    });
    this.collectStackTrace();
    return this;
  }
  pipInstall(packages, options) {
    var _a3;
    const g = (_a3 = options == null ? void 0 : options.g) != null ? _a3 : true;
    const args = ["pip", "install"];
    const packageList = packages ? Array.isArray(packages) ? packages : [packages] : void 0;
    if (g === false) {
      args.push("--user");
    }
    if (packageList) {
      args.push(...packageList);
    } else {
      args.push(".");
    }
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), {
        user: g ? "root" : void 0
      })
    );
  }
  npmInstall(packages, options) {
    const args = ["npm", "install"];
    const packageList = packages ? Array.isArray(packages) ? packages : [packages] : void 0;
    if (options == null ? void 0 : options.g) {
      args.push("-g");
    }
    if (options == null ? void 0 : options.dev) {
      args.push("--save-dev");
    }
    if (packageList) {
      args.push(...packageList);
    }
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), {
        user: (options == null ? void 0 : options.g) ? "root" : void 0
      })
    );
  }
  bunInstall(packages, options) {
    const args = ["bun", "install"];
    const packageList = packages ? Array.isArray(packages) ? packages : [packages] : void 0;
    if (options == null ? void 0 : options.g) {
      args.push("-g");
    }
    if (options == null ? void 0 : options.dev) {
      args.push("--dev");
    }
    if (packageList) {
      args.push(...packageList);
    }
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), {
        user: (options == null ? void 0 : options.g) ? "root" : void 0
      })
    );
  }
  aptInstall(packages, options) {
    const packageList = Array.isArray(packages) ? packages : [packages];
    return this.runInNewStackTraceContext(
      () => this.runCmd(
        [
          "apt-get update",
          `DEBIAN_FRONTEND=noninteractive DEBCONF_NOWARNINGS=yes apt-get install -y ${(options == null ? void 0 : options.noInstallRecommends) ? "--no-install-recommends " : ""}${packageList.join(
            " "
          )}`
        ],
        { user: "root" }
      )
    );
  }
  addMcpServer(servers) {
    if (this.baseTemplate !== "mcp-gateway") {
      throw new BuildError(
        "MCP servers can only be added to mcp-gateway template",
        getCallerFrame(STACK_TRACE_DEPTH - 1)
      );
    }
    const serverList = Array.isArray(servers) ? servers : [servers];
    return this.runInNewStackTraceContext(
      () => this.runCmd(`mcp-gateway pull ${serverList.join(" ")}`, {
        user: "root"
      })
    );
  }
  gitClone(url, path2, options) {
    const args = ["git", "clone", url];
    if (options == null ? void 0 : options.branch) {
      args.push(`--branch ${options.branch}`);
      args.push("--single-branch");
    }
    if (options == null ? void 0 : options.depth) {
      args.push(`--depth ${options.depth}`);
    }
    if (path2) {
      args.push(path2.toString());
    }
    return this.runInNewStackTraceContext(
      () => this.runCmd(args.join(" "), { user: options == null ? void 0 : options.user })
    );
  }
  setStartCmd(startCommand, readyCommand) {
    this.startCmd = startCommand;
    if (readyCommand instanceof ReadyCmd) {
      this.readyCmd = readyCommand.getCmd();
    } else {
      this.readyCmd = readyCommand;
    }
    this.collectStackTrace();
    return this;
  }
  setReadyCmd(readyCommand) {
    if (readyCommand instanceof ReadyCmd) {
      this.readyCmd = readyCommand.getCmd();
    } else {
      this.readyCmd = readyCommand;
    }
    this.collectStackTrace();
    return this;
  }
  setEnvs(envs) {
    if (Object.keys(envs).length === 0) {
      return this;
    }
    this.instructions.push({
      type: "ENV" /* ENV */,
      args: Object.entries(envs).flatMap(([key, value]) => [key, value]),
      force: this.forceNextLayer
    });
    this.collectStackTrace();
    return this;
  }
  skipCache() {
    this.forceNextLayer = true;
    return this;
  }
  betaDevContainerPrebuild(devcontainerDirectory) {
    if (this.baseTemplate !== "devcontainer") {
      throw new BuildError(
        "Devcontainers can only used in the devcontainer template",
        getCallerFrame(STACK_TRACE_DEPTH - 1)
      );
    }
    return this.runInNewStackTraceContext(() => {
      return this.runCmd(
        `devcontainer build --workspace-folder ${devcontainerDirectory}`,
        { user: "root" }
      );
    });
  }
  betaSetDevContainerStart(devcontainerDirectory) {
    if (this.baseTemplate !== "devcontainer") {
      throw new BuildError(
        "Devcontainers can only used in the devcontainer template",
        getCallerFrame(STACK_TRACE_DEPTH - 1)
      );
    }
    return this.runInNewStackTraceContext(() => {
      return this.setStartCmd(
        `sudo devcontainer up --workspace-folder ${devcontainerDirectory} && sudo /prepare-exec.sh ${devcontainerDirectory} | sudo tee /devcontainer.sh > /dev/null && sudo chmod +x /devcontainer.sh && sudo touch /devcontainer.up`,
        waitForFile("/devcontainer.up")
      );
    });
  }
  /**
   * Collect the current stack trace for debugging purposes.
   *
   * @param stackTracesDepth Depth to traverse in the call stack
   * @returns this for method chaining
   */
  collectStackTrace(stackTracesDepth = STACK_TRACE_DEPTH) {
    if (!this.stackTracesEnabled) {
      return this;
    }
    if (this.stackTracesOverride) {
      this.stackTraces.push(this.stackTracesOverride);
      return this;
    }
    this.stackTraces.push(getCallerFrame(stackTracesDepth));
    return this;
  }
  /**
   * Temporarily disable stack trace collection.
   *
   * @returns this for method chaining
   */
  disableStackTrace() {
    this.stackTracesEnabled = false;
    return this;
  }
  /**
   * Re-enable stack trace collection.
   *
   * @returns this for method chaining
   */
  enableStackTrace() {
    this.stackTracesEnabled = true;
    return this;
  }
  /**
   * Execute a function in a clean stack trace context.
   *
   * @param fn Function to execute
   * @returns The result of the function
   */
  runInNewStackTraceContext(fn) {
    this.disableStackTrace();
    const result = fn();
    this.enableStackTrace();
    this.collectStackTrace(STACK_TRACE_DEPTH + 1);
    return result;
  }
  runInStackTraceOverrideContext(fn, stackTraceOverride) {
    this.stackTracesOverride = stackTraceOverride;
    const result = fn();
    this.stackTracesOverride = void 0;
    return result;
  }
  /**
   * Convert the template to JSON representation.
   *
   * @param computeHashes Whether to compute file hashes for COPY instructions
   * @returns JSON string representation of the template
   */
  async toJSON(computeHashes) {
    let instructions = this.instructions;
    if (computeHashes) {
      instructions = await this.instructionsWithHashes();
    }
    return JSON.stringify(this.serialize(instructions), void 0, 2);
  }
  /**
   * Convert the template to Dockerfile format.
   *
   * Note: Only templates based on Docker images can be converted to Dockerfile.
   * Templates based on other E2B templates cannot be converted because they
   * may use features not available in standard Dockerfiles.
   *
   * @returns Dockerfile string representation
   * @throws Error if template is based on another E2B template or has no base image
   */
  toDockerfile() {
    if (this.baseTemplate !== void 0) {
      throw new Error(
        "Cannot convert template built from another template to Dockerfile. Templates based on other templates can only be built using the E2B API."
      );
    }
    if (this.baseImage === void 0) {
      throw new Error("No base image specified for template");
    }
    let dockerfile = `FROM ${this.baseImage}
`;
    for (const instruction of this.instructions) {
      if (instruction.type === "RUN" /* RUN */) {
        dockerfile += `RUN ${instruction.args[0]}
`;
        continue;
      }
      if (instruction.type === "COPY" /* COPY */) {
        dockerfile += `COPY ${instruction.args[0]} ${instruction.args[1]}
`;
        continue;
      }
      if (instruction.type === "ENV" /* ENV */) {
        const values = [];
        for (let i = 0; i < instruction.args.length; i += 2) {
          values.push(`${instruction.args[i]}=${instruction.args[i + 1]}`);
        }
        dockerfile += `ENV ${values.join(" ")}
`;
        continue;
      }
      dockerfile += `${instruction.type} ${instruction.args.join(" ")}
`;
    }
    if (this.startCmd) {
      dockerfile += `ENTRYPOINT ${this.startCmd}
`;
    }
    return dockerfile;
  }
  /**
   * Internal implementation of the template build process.
   *
   * @param client API client for communicating with E2B backend
   * @param name Template name in 'name' or 'name:tag' format
   * @param tags Additional tags to assign to the build
   * @param options Build configuration options
   * @throws BuildError if the build fails
   */
  async build(client, name, options) {
    var _a3, _b, _c, _d, _e, _f;
    if (options.skipCache) {
      this.force = true;
    }
    (_a3 = options.onBuildLogs) == null ? void 0 : _a3.call(
      options,
      new LogEntry(
        /* @__PURE__ */ new Date(),
        "info",
        `Requesting build for template: ${name}${options.tags && options.tags.length > 0 ? ` with tags ${options.tags.join(", ")}` : ""}`
      )
    );
    const {
      templateID,
      buildID,
      tags: responseTags
    } = await requestBuild(client, {
      name,
      tags: options.tags,
      cpuCount: (_b = options.cpuCount) != null ? _b : 2,
      memoryMB: (_c = options.memoryMB) != null ? _c : 1024
    });
    (_d = options.onBuildLogs) == null ? void 0 : _d.call(
      options,
      new LogEntry(
        /* @__PURE__ */ new Date(),
        "info",
        `Template created with ID: ${templateID}, Build ID: ${buildID}`
      )
    );
    const instructionsWithHashes = await this.instructionsWithHashes();
    const uploadPromises = instructionsWithHashes.map(
      async (instruction, index) => {
        var _a4, _b2, _c2, _d2;
        if (instruction.type !== "COPY" /* COPY */) {
          return;
        }
        const src = instruction.args.length > 0 ? instruction.args[0] : null;
        const filesHash = (_a4 = instruction.filesHash) != null ? _a4 : null;
        if (src === null || filesHash === null) {
          throw new Error("Source path and files hash are required");
        }
        const forceUpload = instruction.forceUpload;
        let stackTrace = void 0;
        if (index + 1 >= 0 && index + 1 < this.stackTraces.length) {
          stackTrace = this.stackTraces[index + 1];
        }
        const { present, url } = await getFileUploadLink(
          client,
          {
            templateID,
            filesHash
          },
          stackTrace
        );
        if (forceUpload && url != null || present === false && url != null) {
          await uploadFile(
            {
              fileName: src,
              fileContextPath: this.fileContextPath.toString(),
              url,
              ignorePatterns: [
                ...this.fileIgnorePatterns,
                ...readDockerignore(this.fileContextPath.toString())
              ],
              resolveSymlinks: (_b2 = instruction.resolveSymlinks) != null ? _b2 : RESOLVE_SYMLINKS
            },
            stackTrace
          );
          (_c2 = options.onBuildLogs) == null ? void 0 : _c2.call(
            options,
            new LogEntry(/* @__PURE__ */ new Date(), "info", `Uploaded '${src}'`)
          );
        } else {
          (_d2 = options.onBuildLogs) == null ? void 0 : _d2.call(
            options,
            new LogEntry(
              /* @__PURE__ */ new Date(),
              "info",
              `Skipping upload of '${src}', already cached`
            )
          );
        }
      }
    );
    await Promise.all(uploadPromises);
    (_e = options.onBuildLogs) == null ? void 0 : _e.call(
      options,
      new LogEntry(/* @__PURE__ */ new Date(), "info", "All file uploads completed")
    );
    (_f = options.onBuildLogs) == null ? void 0 : _f.call(
      options,
      new LogEntry(/* @__PURE__ */ new Date(), "info", "Starting building...")
    );
    await triggerBuild(client, {
      templateID,
      buildID,
      template: this.serialize(instructionsWithHashes)
    });
    return {
      alias: name,
      name,
      tags: responseTags,
      templateId: templateID,
      buildId: buildID
    };
  }
  /**
   * Add file hashes to COPY instructions for cache invalidation.
   *
   * @returns Copy of instructions array with filesHash added to COPY instructions
   */
  async instructionsWithHashes() {
    return Promise.all(
      this.instructions.map(async (instruction, index) => {
        var _a3;
        if (instruction.type !== "COPY" /* COPY */) {
          return instruction;
        }
        const src = instruction.args.length > 0 ? instruction.args[0] : null;
        const dest = instruction.args.length > 1 ? instruction.args[1] : null;
        if (src === null || dest === null) {
          throw new Error("Source path and destination path are required");
        }
        let stackTrace = void 0;
        if (index + 1 >= 0 && index + 1 < this.stackTraces.length) {
          stackTrace = this.stackTraces[index + 1];
        }
        return __spreadProps(__spreadValues({}, instruction), {
          filesHash: await calculateFilesHash(
            src,
            dest,
            this.fileContextPath.toString(),
            [
              ...this.fileIgnorePatterns,
              ...runtime === "browser" ? [] : readDockerignore(this.fileContextPath.toString())
            ],
            (_a3 = instruction.resolveSymlinks) != null ? _a3 : RESOLVE_SYMLINKS,
            stackTrace
          )
        });
      })
    );
  }
  /**
   * Serialize the template to the API request format.
   *
   * @param steps Array of build instructions with file hashes
   * @returns Template data formatted for the API
   */
  serialize(steps) {
    const templateData = {
      startCmd: this.startCmd,
      readyCmd: this.readyCmd,
      steps,
      force: this.force
    };
    if (this.baseImage !== void 0) {
      templateData.fromImage = this.baseImage;
    }
    if (this.baseTemplate !== void 0) {
      templateData.fromTemplate = this.baseTemplate;
    }
    if (this.registryConfig !== void 0) {
      templateData.fromImageRegistry = this.registryConfig;
    }
    return templateData;
  }
};
function Template(options) {
  return new TemplateBase(options);
}
Template.build = TemplateBase.build;
Template.buildInBackground = TemplateBase.buildInBackground;
Template.getBuildStatus = TemplateBase.getBuildStatus;
Template.exists = TemplateBase.exists;
Template.aliasExists = TemplateBase.aliasExists;
Template.assignTags = TemplateBase.assignTags;
Template.removeTags = TemplateBase.removeTags;
Template.toJSON = TemplateBase.toJSON;
Template.toDockerfile = TemplateBase.toDockerfile;

// src/index.ts
var src_default = Sandbox;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  ALL_TRAFFIC,
  ApiClient,
  AuthenticationError,
  BuildError,
  CommandExitError,
  ConnectionConfig,
  FileType,
  FileUploadError,
  FilesystemEventType,
  Git,
  GitAuthError,
  GitUpstreamError,
  InvalidArgumentError,
  LogEntry,
  LogEntryEnd,
  LogEntryStart,
  NotEnoughSpaceError,
  NotFoundError,
  RateLimitError,
  ReadyCmd,
  Sandbox,
  SandboxError,
  Template,
  TemplateBase,
  TemplateError,
  TimeoutError,
  defaultBuildLogger,
  getSignature,
  waitForFile,
  waitForPort,
  waitForProcess,
  waitForTimeout,
  waitForURL
});
//# sourceMappingURL=index.js.map