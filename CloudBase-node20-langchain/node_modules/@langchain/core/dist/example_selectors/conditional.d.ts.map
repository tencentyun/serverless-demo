{"version":3,"file":"conditional.d.ts","names":["BaseChatModel","BasePromptTemplate","BaseLanguageModelInterface","BaseLLM","PartialValues","BaseGetPromptAsyncOptions","BasePromptSelector","Promise","ConditionalPromptSelector","Array","isLLM","isChatModel"],"sources":["../../src/example_selectors/conditional.d.ts"],"sourcesContent":["import type { BaseChatModel } from \"../language_models/chat_models.js\";\nimport type { BasePromptTemplate } from \"../prompts/base.js\";\nimport type { BaseLanguageModelInterface } from \"../language_models/base.js\";\nimport type { BaseLLM } from \"../language_models/llms.js\";\nimport type { PartialValues } from \"../utils/types/index.js\";\nexport type BaseGetPromptAsyncOptions = {\n    partialVariables?: PartialValues;\n};\n/**\n * Abstract class that defines the interface for selecting a prompt for a\n * given language model.\n */\nexport declare abstract class BasePromptSelector {\n    /**\n     * Abstract method that must be implemented by any class that extends\n     * `BasePromptSelector`. It takes a language model as an argument and\n     * returns a prompt template.\n     * @param llm The language model for which to get a prompt.\n     * @returns A prompt template.\n     */\n    abstract getPrompt(llm: BaseLanguageModelInterface): BasePromptTemplate;\n    /**\n     * Asynchronous version of `getPrompt` that also accepts an options object\n     * for partial variables.\n     * @param llm The language model for which to get a prompt.\n     * @param options Optional object for partial variables.\n     * @returns A Promise that resolves to a prompt template.\n     */\n    getPromptAsync(llm: BaseLanguageModelInterface, options?: BaseGetPromptAsyncOptions): Promise<BasePromptTemplate>;\n}\n/**\n * Concrete implementation of `BasePromptSelector` that selects a prompt\n * based on a set of conditions. It has a default prompt that it returns\n * if none of the conditions are met.\n */\nexport declare class ConditionalPromptSelector extends BasePromptSelector {\n    defaultPrompt: BasePromptTemplate;\n    conditionals: Array<[\n        condition: (llm: BaseLanguageModelInterface) => boolean,\n        prompt: BasePromptTemplate\n    ]>;\n    constructor(default_prompt: BasePromptTemplate, conditionals?: Array<[\n        condition: (llm: BaseLanguageModelInterface) => boolean,\n        prompt: BasePromptTemplate\n    ]>);\n    /**\n     * Method that selects a prompt based on a set of conditions. If none of\n     * the conditions are met, it returns the default prompt.\n     * @param llm The language model for which to get a prompt.\n     * @returns A prompt template.\n     */\n    getPrompt(llm: BaseLanguageModelInterface): BasePromptTemplate;\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseLLM`.\n */\nexport declare function isLLM(llm: BaseLanguageModelInterface): llm is BaseLLM;\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseChatModel`.\n */\nexport declare function isChatModel(llm: BaseLanguageModelInterface): llm is BaseChatModel;\n//# sourceMappingURL=conditional.d.ts.map"],"mappings":";;;;;;;KAKYK,yBAAAA;qBACWD;AADvB,CAAA;AAOA;;;;AAgB8DC,uBAhBhCC,kBAAAA,CAgBgCD;EAAoCJ;;AAAD;AAOjG;;;;EAEkBQ,SAAAA,SAAAA,CAAAA,GAAAA,EAjBUP,0BAiBVO,CAAAA,EAjBuCR,kBAiBvCQ;EAIcR;;;;;;;EANyC,cAAA,CAAA,GAAA,EAPjDC,0BAOiD,EAAA,OAAA,CAAA,EAPXG,yBAOW,CAAA,EAPiBE,OAOjB,CAPyBN,kBAOzB,CAAA;AAsBzE;AAKA;;;;;cA3BqBO,yBAAAA,SAAkCF,kBAAAA;iBACpCL;gBACDQ,wBACOP,gDACTD;8BAEgBA,mCAAmCQ,wBAC1CP,gDACTD;;;;;;;iBAQGC,6BAA6BD;;;;;;iBAMxBS,KAAAA,MAAWR,oCAAoCC;;;;;iBAK/CQ,WAAAA,MAAiBT,oCAAoCF"}