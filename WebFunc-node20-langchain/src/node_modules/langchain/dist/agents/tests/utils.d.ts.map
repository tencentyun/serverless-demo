{"version":3,"file":"utils.d.ts","names":["CallbackManagerForLLMRun","BaseChatModel","BaseChatModelParams","BindToolsInput","ToolChoice","StructuredTool","BaseMessage","AIMessage","HumanMessage","BaseMessageFields","AIMessageFields","ToolMessage","ToolMessageFields","ChatResult","Runnable","RunnableConfig","RunnableLambda","RunnableBinding","MemorySaver","Checkpoint","CheckpointMetadata","BaseCheckpointSaver","LanguageModelLike","z","_AnyIdAIMessage","_AnyIdHumanMessage","_AnyIdToolMessage","FakeConfigurableModel","Record","Promise","FakeToolCallingChatModel","RunOutput","MemorySaverAssertImmutable","Uint8Array","ToolCall","FakeToolCallingModelFields","createCheckpointer","FakeToolCallingModel","toolCalls","toolStyle","index","structuredResponse","indexRef","SearchAPI","ZodString","ZodTypeAny","ZodObject","infer"],"sources":["../../../src/agents/tests/utils.d.ts"],"sourcesContent":["import { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { BaseChatModel, BaseChatModelParams, BindToolsInput, ToolChoice } from \"@langchain/core/language_models/chat_models\";\nimport { StructuredTool } from \"@langchain/core/tools\";\nimport { BaseMessage, AIMessage, HumanMessage, BaseMessageFields, AIMessageFields, ToolMessage, ToolMessageFields } from \"@langchain/core/messages\";\nimport { ChatResult } from \"@langchain/core/outputs\";\nimport { Runnable, RunnableConfig, RunnableLambda, RunnableBinding } from \"@langchain/core/runnables\";\nimport { MemorySaver, Checkpoint, CheckpointMetadata, type BaseCheckpointSaver } from \"@langchain/langgraph-checkpoint\";\nimport { LanguageModelLike } from \"@langchain/core/language_models/base\";\nimport { z } from \"zod/v3\";\nexport declare class _AnyIdAIMessage extends AIMessage {\n    get lc_id(): string[];\n    constructor(fields: AIMessageFields | string);\n}\nexport declare class _AnyIdHumanMessage extends HumanMessage {\n    get lc_id(): string[];\n    constructor(fields: BaseMessageFields | string);\n}\nexport declare class _AnyIdToolMessage extends ToolMessage {\n    get lc_id(): string[];\n    constructor(fields: ToolMessageFields);\n}\nexport declare class FakeConfigurableModel extends BaseChatModel {\n    _queuedMethodOperations: Record<string, any>;\n    _chatModel: LanguageModelLike;\n    constructor(fields: {\n        model: LanguageModelLike;\n    } & BaseChatModelParams);\n    _llmType(): string;\n    _generate(_messages: BaseMessage[], _options: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    _model(): Promise<LanguageModelLike>;\n    bindTools(tools: BindToolsInput[]): FakeConfigurableModel;\n}\nexport declare class FakeToolCallingChatModel extends BaseChatModel {\n    sleep?: number;\n    responses?: BaseMessage[];\n    thrownErrorString?: string;\n    idx: number;\n    toolStyle: \"openai\" | \"anthropic\" | \"bedrock\" | \"google\";\n    structuredResponse?: Record<string, unknown>;\n    structuredOutputMessages: BaseMessage[][];\n    constructor(fields: {\n        sleep?: number;\n        responses?: BaseMessage[];\n        thrownErrorString?: string;\n        toolStyle?: \"openai\" | \"anthropic\" | \"bedrock\" | \"google\";\n        structuredResponse?: Record<string, unknown>;\n    } & BaseChatModelParams);\n    _llmType(): string;\n    _generate(messages: BaseMessage[], _options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    bindTools(tools: BindToolsInput[]): Runnable<any>;\n    withStructuredOutput<RunOutput extends Record<string, any> = Record<string, any>>(_: unknown): Runnable<any>;\n}\nexport declare class MemorySaverAssertImmutable extends MemorySaver {\n    storageForCopies: Record<string, Record<string, Uint8Array>>;\n    constructor();\n    put(config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata): Promise<RunnableConfig>;\n}\ninterface ToolCall {\n    name: string;\n    args: Record<string, any>;\n    id: string;\n    type?: \"tool_call\";\n}\ninterface FakeToolCallingModelFields {\n    toolCalls?: ToolCall[][];\n    toolStyle?: \"openai\" | \"anthropic\";\n    index?: number;\n    structuredResponse?: any;\n}\nexport declare function createCheckpointer(): BaseCheckpointSaver;\n/**\n * Fake chat model for testing tool calling functionality\n */\nexport declare class FakeToolCallingModel extends BaseChatModel {\n    toolCalls: ToolCall[][];\n    toolStyle: \"openai\" | \"anthropic\";\n    private indexRef;\n    structuredResponse?: any;\n    private tools;\n    constructor({ toolCalls, toolStyle, index, structuredResponse, indexRef, ...rest }?: FakeToolCallingModelFields & {\n        indexRef?: {\n            current: number;\n        };\n    });\n    get index(): number;\n    set index(value: number);\n    _llmType(): string;\n    _combineLLMOutput(): never[];\n    bindTools(tools: StructuredTool[]): FakeToolCallingModel | RunnableBinding<any, any, any & {\n        tool_choice?: ToolChoice | undefined;\n    }>;\n    withStructuredOutput(_schema: any): RunnableLambda<unknown, any, RunnableConfig<Record<string, any>>>;\n    _generate(messages: BaseMessage[], _options?: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n}\nexport declare class SearchAPI extends StructuredTool {\n    name: string;\n    description: string;\n    schema: z.ZodObject<{\n        query: z.ZodString;\n    }, \"strip\", z.ZodTypeAny, {\n        query: string;\n    }, {\n        query: string;\n    }>;\n    _call(input: z.infer<typeof this.schema>): Promise<string>;\n}\nexport {};\n//# sourceMappingURL=utils.d.ts.map"],"mappings":";;;;;;;;;;;;UAyDUkC,UAAAA;;QAEAN;;;;UAIAO,0BAAAA;cACMD;;;;;;;;cASKG,oBAAAA,SAA6BpC,aAAAA;aACnCiC;;;;;;;;;;;;MAK0EC;;;;;;;;;mBASpE9B,mBAAmBgC,uBAAuBpB;kBACzCb;;sCAEkBY,6BAA6BD,eAAea;sBAC5DtB,mEAAmEN,2BAA2B6B,QAAQhB"}