{"version":3,"file":"llms.d.cts","names":["BasePromptValueInterface","LLMResult","Generation","GenerationChunk","BaseCallbackConfig","CallbackManagerForLLMRun","Callbacks","BaseLanguageModel","BaseLanguageModelCallOptions","BaseLanguageModelInput","BaseLanguageModelParams","RunnableConfig","BaseCache","SerializedLLM","Record","BaseLLMParams","BaseLLMCallOptions","BaseLLM","CallOptions","Exclude","Omit","Promise","AsyncGenerator","Partial","prompts","cache","llmStringKey","parsedOptions","handledOptions","runId","LLM"],"sources":["../../src/language_models/llms.d.ts"],"sourcesContent":["import type { BasePromptValueInterface } from \"../prompt_values.js\";\nimport { type LLMResult, type Generation, GenerationChunk } from \"../outputs.js\";\nimport { type BaseCallbackConfig, type CallbackManagerForLLMRun, type Callbacks } from \"../callbacks/manager.js\";\nimport { BaseLanguageModel, type BaseLanguageModelCallOptions, type BaseLanguageModelInput, type BaseLanguageModelParams } from \"./base.js\";\nimport type { RunnableConfig } from \"../runnables/config.js\";\nimport type { BaseCache } from \"../caches/index.js\";\nexport type SerializedLLM = {\n    _model: string;\n    _type: string;\n} & Record<string, any>;\nexport interface BaseLLMParams extends BaseLanguageModelParams {\n}\nexport interface BaseLLMCallOptions extends BaseLanguageModelCallOptions {\n}\n/**\n * LLM Wrapper. Takes in a prompt (or prompts) and returns a string.\n */\nexport declare abstract class BaseLLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLanguageModel<string, CallOptions> {\n    ParsedCallOptions: Omit<CallOptions, Exclude<keyof RunnableConfig, \"signal\" | \"timeout\" | \"maxConcurrency\">>;\n    lc_namespace: string[];\n    /**\n     * This method takes an input and options, and returns a string. It\n     * converts the input to a prompt value and generates a result based on\n     * the prompt.\n     * @param input Input for the LLM.\n     * @param options Options for the LLM call.\n     * @returns A string result based on the prompt.\n     */\n    invoke(input: BaseLanguageModelInput, options?: CallOptions): Promise<string>;\n    _streamResponseChunks(_input: string, _options: this[\"ParsedCallOptions\"], _runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;\n    protected _separateRunnableConfigFromCallOptionsCompat(options?: Partial<CallOptions>): [RunnableConfig, this[\"ParsedCallOptions\"]];\n    _streamIterator(input: BaseLanguageModelInput, options?: CallOptions): AsyncGenerator<string>;\n    /**\n     * This method takes prompt values, options, and callbacks, and generates\n     * a result based on the prompts.\n     * @param promptValues Prompt values for the LLM.\n     * @param options Options for the LLM call.\n     * @param callbacks Callbacks for the LLM call.\n     * @returns An LLMResult based on the prompts.\n     */\n    generatePrompt(promptValues: BasePromptValueInterface[], options?: string[] | CallOptions, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Run the LLM on the given prompts and input.\n     */\n    abstract _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(_options?: this[\"ParsedCallOptions\"]): any;\n    _flattenLLMResult(llmResult: LLMResult): LLMResult[];\n    /** @ignore */\n    _generateUncached(prompts: string[], parsedOptions: this[\"ParsedCallOptions\"], handledOptions: BaseCallbackConfig, startedRunManagers?: CallbackManagerForLLMRun[]): Promise<LLMResult>;\n    _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }: {\n        prompts: string[];\n        cache: BaseCache<Generation[]>;\n        llmStringKey: string;\n        parsedOptions: any;\n        handledOptions: RunnableConfig;\n        runId?: string;\n    }): Promise<LLMResult & {\n        missingPromptIndices: number[];\n        startedRunManagers?: CallbackManagerForLLMRun[];\n    }>;\n    /**\n     * Run the LLM on the given prompts and input, handling caching.\n     */\n    generate(prompts: string[], options?: string[] | CallOptions, callbacks?: Callbacks): Promise<LLMResult>;\n    /**\n     * Get the identifying parameters of the LLM.\n     */\n    _identifyingParams(): Record<string, any>;\n    /**\n     * Return the string type key uniquely identifying this class of LLM.\n     */\n    abstract _llmType(): string;\n    _modelType(): string;\n}\n/**\n * LLM class that provides a simpler interface to subclass than {@link BaseLLM}.\n *\n * Requires only implementing a simpler {@link _call} method instead of {@link _generate}.\n *\n * @augments BaseLLM\n */\nexport declare abstract class LLM<CallOptions extends BaseLLMCallOptions = BaseLLMCallOptions> extends BaseLLM<CallOptions> {\n    /**\n     * Run the LLM on the given prompt and input.\n     */\n    abstract _call(prompt: string, options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<string>;\n    _generate(prompts: string[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;\n}\n//# sourceMappingURL=llms.d.ts.map"],"mappings":";;;;;;;;KAMYa,aAAAA;;EAAAA,KAAAA,EAAAA,MAAAA;AAIZ,CAAA,GADIC,MACaC,CAAAA,MAAAA,EAAAA,GAAa,CAAA;AAEbC,UAFAD,aAAAA,SAAsBL,uBAEKF,CAAAA,CAK5C;AAA0DQ,UALzCA,kBAAAA,SAA2BR,4BAKcQ,CAAAA;;;;AACjBG,uBADXF,OACWE,CAAAA,oBADiBH,kBACjBG,GADsCH,kBACtCG,CAAAA,SADkEZ,iBAClEY,CAAAA,MAAAA,EAD4FD,WAC5FC,CAAAA,CAAAA;EAAlBC,iBAAAA,EAAAA,IAAAA,CAAKF,WAALE,EAAkBD,OAAlBC,CAAAA,MAAgCT,cAAhCS,EAAAA,QAAAA,GAAAA,SAAAA,GAAAA,gBAAAA,CAAAA,CAAAA;EAULX,YAAAA,EAAAA,MAAAA,EAAAA;EAAkCS;;;;;;;;EAGzBT,MAAAA,CAAAA,KAAAA,EAHTA,sBAGSA,EAAAA,OAAAA,CAAAA,EAHyBS,WAGzBT,CAAAA,EAHuCY,OAGvCZ,CAAAA,MAAAA,CAAAA;EAAkCS,qBAAAA,CAAAA,MAAAA,EAAAA,MAAAA,EAAAA,QAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,WAAAA,CAAAA,EAFgCb,wBAEhCa,CAAAA,EAF2DI,cAE3DJ,CAF0Ef,eAE1Ee,CAAAA;EAAcI,UAAAA,4CAAAA,CAAAA,OAAAA,CAAAA,EADNC,OACMD,CADEJ,WACFI,CAAAA,CAAAA,EAAAA,CADkBX,cAClBW,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA;EAS1CtB,eAAAA,CAAAA,KAAAA,EATNS,sBASMT,EAAAA,OAAAA,CAAAA,EAT4BkB,WAS5BlB,CAAAA,EAT0CsB,cAS1CtB,CAAAA,MAAAA,CAAAA;EAAiDkB;;;;;;;;EASrCjB,cAAAA,CAAAA,YAAAA,EATZD,wBASYC,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GATqCiB,WASrCjB,EAAAA,SAAAA,CAAAA,EAT8DK,SAS9DL,CAAAA,EAT0EoB,OAS1EpB,CATkFA,SASlFA,CAAAA;EAEsDG;;;EAAsEiB,SAAAA,SAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,UAAAA,CAAAA,EAP9EhB,wBAO8EgB,CAAAA,EAPnDA,OAOmDA,CAP3CpB,SAO2CoB,CAAAA;EACnJG;;;EAA8BG,gBAAAA,CAAAA,QAAAA,CAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,CAAAA,EAAAA,GAAAA;EAAeC,iBAAAA,CAAAA,SAAAA,EAHlC3B,SAGkC2B,CAAAA,EAHtB3B,SAGsB2B,EAAAA;EAAgBC;EAE1D3B,iBAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,aAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,cAAAA,EAH0EE,kBAG1EF,EAAAA,kBAAAA,CAAAA,EAHmHG,wBAGnHH,EAAAA,CAAAA,EAHgJmB,OAGhJnB,CAHwJD,SAGxJC,CAAAA;EAAVU,eAAAA,CAAAA;IAAAA,OAAAA;IAAAA,KAAAA;IAAAA,YAAAA;IAAAA,aAAAA;IAAAA,cAAAA;IAAAA;EAYmFX,CAZnFW,EAAAA;IAGSD,OAAAA,EAAAA,MAAAA,EAAAA;IAERV,KAAAA,EALDW,SAKCX,CALSC,UAKTD,EAAAA,CAAAA;IAEaI,YAAAA,EAAAA,MAAAA;IAFrBgB,aAAAA,EAAAA,GAAAA;IAO6CH,cAAAA,EAT7BP,cAS6BO;IAAyBZ,KAAAA,CAAAA,EAAAA,MAAAA;EAAoBL,CAAAA,CAAAA,EAP1FoB,OAO0FpB,CAPlFA,SAOkFA,GAAAA;IAARoB,oBAAAA,EAAAA,MAAAA,EAAAA;IAIhEP,kBAAAA,CAAAA,EATGT,wBASHS,EAAAA;EArDiFP,CAAAA,CAAAA;EAAiB;AAmE5H;;EAA2ES,QAAAA,CAAAA,OAAAA,EAAAA,MAAAA,EAAAA,EAAAA,OAAAA,CAAAA,EAAAA,MAAAA,EAAAA,GAlBtBE,WAkBsBF,EAAAA,SAAAA,CAAAA,EAlBGV,SAkBHU,CAAAA,EAlBeK,OAkBfL,CAlBuBf,SAkBvBe,CAAAA;EAAoCE;;;EAK7Bb,kBAAAA,CAAAA,CAAAA,EAnBxDS,MAmBwDT,CAAAA,MAAAA,EAAAA,GAAAA,CAAAA;EAAmCJ;;;EALP,SAAA,QAAA,CAAA,CAAA,EAAA,MAAA;;;;;;;;;;uBAAhF6B,wBAAwBd,qBAAqBA,4BAA4BC,QAAQC;;;;kFAI3Bb,2BAA2BgB;gFAC7BhB,2BAA2BgB,QAAQpB"}