import createClient from 'openapi-fetch';
import { Transport, Client } from '@connectrpc/connect';
import { Message } from '@bufbuild/protobuf';
import { GenService, GenMessage } from '@bufbuild/protobuf/codegenv2';
import { PathLike } from 'node:fs';

/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */
interface paths {
    "/sandboxes": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List all running sandboxes */
        get: {
            parameters: {
                query?: {
                    /** @description Metadata query used to filter the sandboxes (e.g. "user=abc&app=prod"). Each key and values must be URL encoded. */
                    metadata?: string;
                };
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned all running sandboxes */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ListedSandbox"][];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        /** @description Create a sandbox from the template */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["NewSandbox"];
                };
            };
            responses: {
                /** @description The sandbox was created successfully */
                201: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Sandbox"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get a sandbox by id */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the sandbox */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["SandboxDetail"];
                    };
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        /** @description Kill a sandbox */
        delete: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description The sandbox was killed successfully */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/connect": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Returns sandbox details. If the sandbox is paused, it will be resumed. TTL is only extended. */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["ConnectSandbox"];
                };
            };
            responses: {
                /** @description The sandbox was already running */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Sandbox"];
                    };
                };
                /** @description The sandbox was resumed successfully */
                201: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Sandbox"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/logs": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get sandbox logs */
        get: {
            parameters: {
                query?: {
                    /** @description Maximum number of logs that should be returned */
                    limit?: number;
                    /** @description Starting timestamp of the logs that should be returned in milliseconds */
                    start?: number;
                };
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the sandbox logs */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["SandboxLogs"];
                    };
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/metrics": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get sandbox metrics */
        get: {
            parameters: {
                query?: {
                    end?: number;
                    /** @description Unix timestamp for the start of the interval, in seconds, for which the metrics */
                    start?: number;
                };
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the sandbox metrics */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["SandboxMetric"][];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/pause": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Pause the sandbox */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description The sandbox was paused successfully and can be resumed */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                409: components["responses"]["409"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/refreshes": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Refresh the sandbox extending its time to live */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: {
                content: {
                    "application/json": {
                        /** @description Duration for which the sandbox should be kept alive in seconds */
                        duration?: number;
                    };
                };
            };
            responses: {
                /** @description Successfully refreshed the sandbox */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/resume": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * @deprecated
         * @description Resume the sandbox
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["ResumedSandbox"];
                };
            };
            responses: {
                /** @description The sandbox was resumed successfully */
                201: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Sandbox"];
                    };
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                409: components["responses"]["409"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/{sandboxID}/timeout": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Set the timeout for the sandbox. The sandbox will expire x seconds from the time of the request. Calling this method multiple times overwrites the TTL, each time using the current timestamp as the starting point to measure the timeout duration. */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    sandboxID: components["parameters"]["sandboxID"];
                };
                cookie?: never;
            };
            requestBody?: {
                content: {
                    "application/json": {
                        /**
                         * Format: int32
                         * @description Timeout in seconds from the current time after which the sandbox should expire
                         */
                        timeout: number;
                    };
                };
            };
            responses: {
                /** @description Successfully set the sandbox timeout */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sandboxes/metrics": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List metrics for given sandboxes */
        get: {
            parameters: {
                query: {
                    /** @description Comma-separated list of sandbox IDs to get metrics for */
                    sandbox_ids: string[];
                };
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned all running sandboxes with metrics */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["SandboxesWithMetrics"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/teams": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List all teams */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned all teams */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Team"][];
                    };
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/teams/{teamID}/metrics": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get metrics for the team */
        get: {
            parameters: {
                query?: {
                    end?: number;
                    /** @description Unix timestamp for the start of the interval, in seconds, for which the metrics */
                    start?: number;
                };
                header?: never;
                path: {
                    teamID: components["parameters"]["teamID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the team metrics */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TeamMetric"][];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                403: components["responses"]["403"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/teams/{teamID}/metrics/max": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get the maximum metrics for the team in the given interval */
        get: {
            parameters: {
                query: {
                    end?: number;
                    /** @description Metric to retrieve the maximum value for */
                    metric: "concurrent_sandboxes" | "sandbox_start_rate";
                    /** @description Unix timestamp for the start of the interval, in seconds, for which the metrics */
                    start?: number;
                };
                header?: never;
                path: {
                    teamID: components["parameters"]["teamID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the team metrics */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["MaxTeamMetric"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                403: components["responses"]["403"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List all templates */
        get: {
            parameters: {
                query?: {
                    teamID?: string;
                };
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned all templates */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["Template"][];
                    };
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        /**
         * @deprecated
         * @description Create a new template
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateBuildRequest"];
                };
            };
            responses: {
                /** @description The build was accepted */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateLegacy"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/{templateID}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List all builds for a template */
        get: {
            parameters: {
                query?: {
                    /** @description Maximum number of items to return per page */
                    limit?: components["parameters"]["paginationLimit"];
                    /** @description Cursor to start the list from */
                    nextToken?: components["parameters"]["paginationNextToken"];
                };
                header?: never;
                path: {
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the template with its builds */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateWithBuilds"];
                    };
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        /**
         * @deprecated
         * @description Rebuild an template
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateBuildRequest"];
                };
            };
            responses: {
                /** @description The build was accepted */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateLegacy"];
                    };
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        /** @description Delete a template */
        delete: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description The template was deleted successfully */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        options?: never;
        head?: never;
        /**
         * @deprecated
         * @description Update template
         */
        patch: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateUpdateRequest"];
                };
            };
            responses: {
                /** @description The template was updated successfully */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        trace?: never;
    };
    "/templates/{templateID}/builds/{buildID}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * @deprecated
         * @description Start the build
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    buildID: components["parameters"]["buildID"];
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description The build has started */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/{templateID}/builds/{buildID}/logs": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get template build logs */
        get: {
            parameters: {
                query?: {
                    /** @description Starting timestamp of the logs that should be returned in milliseconds */
                    cursor?: number;
                    direction?: components["schemas"]["LogsDirection"];
                    level?: components["schemas"]["LogLevel"];
                    /** @description Maximum number of logs that should be returned */
                    limit?: number;
                    /** @description Source of the logs that should be returned from */
                    source?: components["schemas"]["LogsSource"];
                };
                header?: never;
                path: {
                    buildID: components["parameters"]["buildID"];
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the template build logs */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateBuildLogsResponse"];
                    };
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/{templateID}/builds/{buildID}/status": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get template build info */
        get: {
            parameters: {
                query?: {
                    level?: components["schemas"]["LogLevel"];
                    /** @description Maximum number of logs that should be returned */
                    limit?: number;
                    /** @description Index of the starting build log that should be returned with the template */
                    logsOffset?: number;
                };
                header?: never;
                path: {
                    buildID: components["parameters"]["buildID"];
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned the template */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateBuildInfo"];
                    };
                };
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/{templateID}/files/{hash}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Get an upload link for a tar file containing build layer files */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    hash: string;
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description The upload link where to upload the tar file */
                201: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateBuildFileUpload"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/aliases/{alias}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description Check if template with given alias exists */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    alias: string;
                };
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully queried template by alias */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateAliasResponse"];
                    };
                };
                400: components["responses"]["400"];
                403: components["responses"]["403"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/templates/tags": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Assign tag(s) to a template build */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["AssignTemplateTagsRequest"];
                };
            };
            responses: {
                /** @description Tag assigned successfully */
                201: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["AssignedTemplateTags"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        /** @description Delete multiple tags from templates */
        delete: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["DeleteTemplateTagsRequest"];
                };
            };
            responses: {
                /** @description Tags deleted successfully */
                204: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                404: components["responses"]["404"];
                500: components["responses"]["500"];
            };
        };
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v2/sandboxes": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** @description List all sandboxes */
        get: {
            parameters: {
                query?: {
                    /** @description Maximum number of items to return per page */
                    limit?: components["parameters"]["paginationLimit"];
                    /** @description Metadata query used to filter the sandboxes (e.g. "user=abc&app=prod"). Each key and values must be URL encoded. */
                    metadata?: string;
                    /** @description Cursor to start the list from */
                    nextToken?: components["parameters"]["paginationNextToken"];
                    /** @description Filter sandboxes by one or more states */
                    state?: components["schemas"]["SandboxState"][];
                };
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successfully returned all running sandboxes */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ListedSandbox"][];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v2/templates": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * @deprecated
         * @description Create a new template
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateBuildRequestV2"];
                };
            };
            responses: {
                /** @description The build was requested successfully */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateLegacy"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v2/templates/{templateID}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        /** @description Update template */
        patch: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateUpdateRequest"];
                };
            };
            responses: {
                /** @description The template was updated successfully */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateUpdateResponse"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        trace?: never;
    };
    "/v2/templates/{templateID}/builds/{buildID}": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Start the build */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path: {
                    buildID: components["parameters"]["buildID"];
                    templateID: components["parameters"]["templateID"];
                };
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateBuildStartV2"];
                };
            };
            responses: {
                /** @description The build has started */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content?: never;
                };
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v3/templates": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /** @description Create a new template */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    "application/json": components["schemas"]["TemplateBuildRequestV3"];
                };
            };
            responses: {
                /** @description The build was requested successfully */
                202: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["TemplateRequestResponseV3"];
                    };
                };
                400: components["responses"]["400"];
                401: components["responses"]["401"];
                500: components["responses"]["500"];
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
}
interface components {
    schemas: {
        AdminSandboxKillResult: {
            /** @description Number of sandboxes that failed to kill */
            failedCount: number;
            /** @description Number of sandboxes successfully killed */
            killedCount: number;
        };
        AssignedTemplateTags: {
            /**
             * Format: uuid
             * @description Identifier of the build associated with these tags
             */
            buildID: string;
            /** @description Assigned tags of the template */
            tags: string[];
        };
        AssignTemplateTagsRequest: {
            /** @description Tags to assign to the template */
            tags: string[];
            /** @description Target template in "name:tag" format */
            target: string;
        };
        AWSRegistry: {
            /** @description AWS Access Key ID for ECR authentication */
            awsAccessKeyId: string;
            /** @description AWS Region where the ECR registry is located */
            awsRegion: string;
            /** @description AWS Secret Access Key for ECR authentication */
            awsSecretAccessKey: string;
            /**
             * @description Type of registry authentication (enum property replaced by openapi-typescript)
             * @enum {string}
             */
            type: "aws";
        };
        BuildLogEntry: {
            level: components["schemas"]["LogLevel"];
            /** @description Log message content */
            message: string;
            /** @description Step in the build process related to the log entry */
            step?: string;
            /**
             * Format: date-time
             * @description Timestamp of the log entry
             */
            timestamp: string;
        };
        BuildStatusReason: {
            /**
             * @description Log entries related to the status reason
             * @default []
             */
            logEntries?: components["schemas"]["BuildLogEntry"][];
            /** @description Message with the status reason, currently reporting only for error status */
            message: string;
            /** @description Step that failed */
            step?: string;
        };
        ConnectSandbox: {
            /**
             * Format: int32
             * @description Timeout in seconds from the current time after which the sandbox should expire
             */
            timeout: number;
        };
        /**
         * Format: int32
         * @description CPU cores for the sandbox
         */
        CPUCount: number;
        CreatedAccessToken: {
            /**
             * Format: date-time
             * @description Timestamp of access token creation
             */
            createdAt: string;
            /**
             * Format: uuid
             * @description Identifier of the access token
             */
            id: string;
            mask: components["schemas"]["IdentifierMaskingDetails"];
            /** @description Name of the access token */
            name: string;
            /** @description The fully created access token */
            token: string;
        };
        CreatedTeamAPIKey: {
            /**
             * Format: date-time
             * @description Timestamp of API key creation
             */
            createdAt: string;
            createdBy?: components["schemas"]["TeamUser"] | null;
            /**
             * Format: uuid
             * @description Identifier of the API key
             */
            id: string;
            /** @description Raw value of the API key */
            key: string;
            /**
             * Format: date-time
             * @description Last time this API key was used
             */
            lastUsed?: string | null;
            mask: components["schemas"]["IdentifierMaskingDetails"];
            /** @description Name of the API key */
            name: string;
        };
        DeleteTemplateTagsRequest: {
            /** @description Name of the template */
            name: string;
            /** @description Tags to delete */
            tags: string[];
        };
        DiskMetrics: {
            /** @description Device name */
            device: string;
            /** @description Filesystem type (e.g., ext4, xfs) */
            filesystemType: string;
            /** @description Mount point of the disk */
            mountPoint: string;
            /**
             * Format: uint64
             * @description Total space in bytes
             */
            totalBytes: number;
            /**
             * Format: uint64
             * @description Used space in bytes
             */
            usedBytes: number;
        };
        /**
         * Format: int32
         * @description Disk size for the sandbox in MiB
         */
        DiskSizeMB: number;
        /** @description Version of the envd running in the sandbox */
        EnvdVersion: string;
        EnvVars: {
            [key: string]: string;
        };
        Error: {
            /**
             * Format: int32
             * @description Error code
             */
            code: number;
            /** @description Error */
            message: string;
        };
        FromImageRegistry: components["schemas"]["AWSRegistry"] | components["schemas"]["GCPRegistry"] | components["schemas"]["GeneralRegistry"];
        GCPRegistry: {
            /** @description Service Account JSON for GCP authentication */
            serviceAccountJson: string;
            /**
             * @description Type of registry authentication (enum property replaced by openapi-typescript)
             * @enum {string}
             */
            type: "gcp";
        };
        GeneralRegistry: {
            /** @description Password to use for the registry */
            password: string;
            /**
             * @description Type of registry authentication (enum property replaced by openapi-typescript)
             * @enum {string}
             */
            type: "registry";
            /** @description Username to use for the registry */
            username: string;
        };
        IdentifierMaskingDetails: {
            /** @description Prefix used in masked version of the token or key */
            maskedValuePrefix: string;
            /** @description Suffix used in masked version of the token or key */
            maskedValueSuffix: string;
            /** @description Prefix that identifies the token or key type */
            prefix: string;
            /** @description Length of the token or key */
            valueLength: number;
        };
        ListedSandbox: {
            /** @description Alias of the template */
            alias?: string;
            /**
             * @deprecated
             * @description Identifier of the client
             */
            clientID: string;
            cpuCount: components["schemas"]["CPUCount"];
            diskSizeMB: components["schemas"]["DiskSizeMB"];
            /**
             * Format: date-time
             * @description Time when the sandbox will expire
             */
            endAt: string;
            envdVersion: components["schemas"]["EnvdVersion"];
            memoryMB: components["schemas"]["MemoryMB"];
            metadata?: components["schemas"]["SandboxMetadata"];
            /** @description Identifier of the sandbox */
            sandboxID: string;
            /**
             * Format: date-time
             * @description Time when the sandbox was started
             */
            startedAt: string;
            state: components["schemas"]["SandboxState"];
            /** @description Identifier of the template from which is the sandbox created */
            templateID: string;
        };
        /**
         * @description State of the sandbox
         * @enum {string}
         */
        LogLevel: "debug" | "info" | "warn" | "error";
        /**
         * @description Direction of the logs that should be returned
         * @enum {string}
         */
        LogsDirection: "forward" | "backward";
        /**
         * @description Source of the logs that should be returned
         * @enum {string}
         */
        LogsSource: "temporary" | "persistent";
        MachineInfo: {
            /** @description CPU architecture of the node */
            cpuArchitecture: string;
            /** @description CPU family of the node */
            cpuFamily: string;
            /** @description CPU model of the node */
            cpuModel: string;
            /** @description CPU model name of the node */
            cpuModelName: string;
        };
        /** @description Team metric with timestamp */
        MaxTeamMetric: {
            /**
             * Format: date-time
             * @deprecated
             * @description Timestamp of the metric entry
             */
            timestamp: string;
            /**
             * Format: int64
             * @description Timestamp of the metric entry in Unix time (seconds since epoch)
             */
            timestampUnix: number;
            /** @description The maximum value of the requested metric in the given interval */
            value: number;
        };
        /** @description MCP configuration for the sandbox */
        Mcp: {
            [key: string]: unknown;
        } | null;
        /**
         * Format: int32
         * @description Memory for the sandbox in MiB
         */
        MemoryMB: number;
        NewAccessToken: {
            /** @description Name of the access token */
            name: string;
        };
        NewSandbox: {
            /** @description Allow sandbox to access the internet. When set to false, it behaves the same as specifying denyOut to 0.0.0.0/0 in the network config. */
            allow_internet_access?: boolean;
            /**
             * @description Automatically pauses the sandbox after the timeout
             * @default false
             */
            autoPause?: boolean;
            envVars?: components["schemas"]["EnvVars"];
            mcp?: components["schemas"]["Mcp"];
            metadata?: components["schemas"]["SandboxMetadata"];
            network?: components["schemas"]["SandboxNetworkConfig"];
            /** @description Secure all system communication with sandbox */
            secure?: boolean;
            /** @description Identifier of the required template */
            templateID: string;
            /**
             * Format: int32
             * @description Time to live for the sandbox in seconds.
             * @default 15
             */
            timeout?: number;
        };
        NewTeamAPIKey: {
            /** @description Name of the API key */
            name: string;
        };
        Node: {
            /** @description Identifier of the cluster */
            clusterID: string;
            /** @description Commit of the orchestrator */
            commit: string;
            /**
             * Format: uint64
             * @description Number of sandbox create fails
             */
            createFails: number;
            /**
             * Format: uint64
             * @description Number of sandbox create successes
             */
            createSuccesses: number;
            /** @description Identifier of the node */
            id: string;
            machineInfo: components["schemas"]["MachineInfo"];
            metrics: components["schemas"]["NodeMetrics"];
            /**
             * @deprecated
             * @description Identifier of the nomad node
             */
            nodeID: string;
            /**
             * Format: uint32
             * @description Number of sandboxes running on the node
             */
            sandboxCount: number;
            /**
             * Format: int
             * @description Number of starting Sandboxes
             */
            sandboxStartingCount: number;
            /** @description Service instance identifier of the node */
            serviceInstanceID: string;
            status: components["schemas"]["NodeStatus"];
            /** @description Version of the orchestrator */
            version: string;
        };
        NodeDetail: {
            /** @description List of cached builds id on the node */
            cachedBuilds: string[];
            /** @description Identifier of the cluster */
            clusterID: string;
            /** @description Commit of the orchestrator */
            commit: string;
            /**
             * Format: uint64
             * @description Number of sandbox create fails
             */
            createFails: number;
            /**
             * Format: uint64
             * @description Number of sandbox create successes
             */
            createSuccesses: number;
            /** @description Identifier of the node */
            id: string;
            machineInfo: components["schemas"]["MachineInfo"];
            metrics: components["schemas"]["NodeMetrics"];
            /**
             * @deprecated
             * @description Identifier of the nomad node
             */
            nodeID: string;
            /** @description List of sandboxes running on the node */
            sandboxes: components["schemas"]["ListedSandbox"][];
            /** @description Service instance identifier of the node */
            serviceInstanceID: string;
            status: components["schemas"]["NodeStatus"];
            /** @description Version of the orchestrator */
            version: string;
        };
        /** @description Node metrics */
        NodeMetrics: {
            /**
             * Format: uint32
             * @description Number of allocated CPU cores
             */
            allocatedCPU: number;
            /**
             * Format: uint64
             * @description Amount of allocated memory in bytes
             */
            allocatedMemoryBytes: number;
            /**
             * Format: uint32
             * @description Total number of CPU cores on the node
             */
            cpuCount: number;
            /**
             * Format: uint32
             * @description Node CPU usage percentage
             */
            cpuPercent: number;
            /** @description Detailed metrics for each disk/mount point */
            disks: components["schemas"]["DiskMetrics"][];
            /**
             * Format: uint64
             * @description Total node memory in bytes
             */
            memoryTotalBytes: number;
            /**
             * Format: uint64
             * @description Node memory used in bytes
             */
            memoryUsedBytes: number;
        };
        /**
         * @description Status of the node
         * @enum {string}
         */
        NodeStatus: "ready" | "draining" | "connecting" | "unhealthy";
        NodeStatusChange: {
            /**
             * Format: uuid
             * @description Identifier of the cluster
             */
            clusterID?: string;
            status: components["schemas"]["NodeStatus"];
        };
        ResumedSandbox: {
            /**
             * @deprecated
             * @description Automatically pauses the sandbox after the timeout
             */
            autoPause?: boolean;
            /**
             * Format: int32
             * @description Time to live for the sandbox in seconds.
             * @default 15
             */
            timeout?: number;
        };
        Sandbox: {
            /** @description Alias of the template */
            alias?: string;
            /**
             * @deprecated
             * @description Identifier of the client
             */
            clientID: string;
            /** @description Base domain where the sandbox traffic is accessible */
            domain?: string | null;
            /** @description Access token used for envd communication */
            envdAccessToken?: string;
            envdVersion: components["schemas"]["EnvdVersion"];
            /** @description Identifier of the sandbox */
            sandboxID: string;
            /** @description Identifier of the template from which is the sandbox created */
            templateID: string;
            /** @description Token required for accessing sandbox via proxy. */
            trafficAccessToken?: string | null;
        };
        SandboxDetail: {
            /** @description Alias of the template */
            alias?: string;
            /**
             * @deprecated
             * @description Identifier of the client
             */
            clientID: string;
            cpuCount: components["schemas"]["CPUCount"];
            diskSizeMB: components["schemas"]["DiskSizeMB"];
            /** @description Base domain where the sandbox traffic is accessible */
            domain?: string | null;
            /**
             * Format: date-time
             * @description Time when the sandbox will expire
             */
            endAt: string;
            /** @description Access token used for envd communication */
            envdAccessToken?: string;
            envdVersion: components["schemas"]["EnvdVersion"];
            memoryMB: components["schemas"]["MemoryMB"];
            metadata?: components["schemas"]["SandboxMetadata"];
            /** @description Identifier of the sandbox */
            sandboxID: string;
            /**
             * Format: date-time
             * @description Time when the sandbox was started
             */
            startedAt: string;
            state: components["schemas"]["SandboxState"];
            /** @description Identifier of the template from which is the sandbox created */
            templateID: string;
        };
        SandboxesWithMetrics: {
            sandboxes: {
                [key: string]: components["schemas"]["SandboxMetric"];
            };
        };
        /** @description Log entry with timestamp and line */
        SandboxLog: {
            /** @description Log line content */
            line: string;
            /**
             * Format: date-time
             * @description Timestamp of the log entry
             */
            timestamp: string;
        };
        SandboxLogEntry: {
            fields: {
                [key: string]: string;
            };
            level: components["schemas"]["LogLevel"];
            /** @description Log message content */
            message: string;
            /**
             * Format: date-time
             * @description Timestamp of the log entry
             */
            timestamp: string;
        };
        SandboxLogs: {
            /** @description Structured logs of the sandbox */
            logEntries: components["schemas"]["SandboxLogEntry"][];
            /** @description Logs of the sandbox */
            logs: components["schemas"]["SandboxLog"][];
        };
        SandboxMetadata: {
            [key: string]: string;
        };
        /** @description Metric entry with timestamp and line */
        SandboxMetric: {
            /**
             * Format: int32
             * @description Number of CPU cores
             */
            cpuCount: number;
            /**
             * Format: float
             * @description CPU usage percentage
             */
            cpuUsedPct: number;
            /**
             * Format: int64
             * @description Total disk space in bytes
             */
            diskTotal: number;
            /**
             * Format: int64
             * @description Disk used in bytes
             */
            diskUsed: number;
            /**
             * Format: int64
             * @description Total memory in bytes
             */
            memTotal: number;
            /**
             * Format: int64
             * @description Memory used in bytes
             */
            memUsed: number;
            /**
             * Format: date-time
             * @deprecated
             * @description Timestamp of the metric entry
             */
            timestamp: string;
            /**
             * Format: int64
             * @description Timestamp of the metric entry in Unix time (seconds since epoch)
             */
            timestampUnix: number;
        };
        SandboxNetworkConfig: {
            /** @description List of allowed CIDR blocks or IP addresses for egress traffic. Allowed addresses always take precedence over blocked addresses. */
            allowOut?: string[];
            /**
             * @description Specify if the sandbox URLs should be accessible only with authentication.
             * @default true
             */
            allowPublicTraffic?: boolean;
            /** @description List of denied CIDR blocks or IP addresses for egress traffic */
            denyOut?: string[];
            /** @description Specify host mask which will be used for all sandbox requests */
            maskRequestHost?: string;
        };
        /**
         * @description State of the sandbox
         * @enum {string}
         */
        SandboxState: "running" | "paused";
        Team: {
            /** @description API key for the team */
            apiKey: string;
            /** @description Whether the team is the default team */
            isDefault: boolean;
            /** @description Name of the team */
            name: string;
            /** @description Identifier of the team */
            teamID: string;
        };
        TeamAPIKey: {
            /**
             * Format: date-time
             * @description Timestamp of API key creation
             */
            createdAt: string;
            createdBy?: components["schemas"]["TeamUser"] | null;
            /**
             * Format: uuid
             * @description Identifier of the API key
             */
            id: string;
            /**
             * Format: date-time
             * @description Last time this API key was used
             */
            lastUsed?: string | null;
            mask: components["schemas"]["IdentifierMaskingDetails"];
            /** @description Name of the API key */
            name: string;
        };
        /** @description Team metric with timestamp */
        TeamMetric: {
            /**
             * Format: int32
             * @description The number of concurrent sandboxes for the team
             */
            concurrentSandboxes: number;
            /**
             * Format: float
             * @description Number of sandboxes started per second
             */
            sandboxStartRate: number;
            /**
             * Format: date-time
             * @deprecated
             * @description Timestamp of the metric entry
             */
            timestamp: string;
            /**
             * Format: int64
             * @description Timestamp of the metric entry in Unix time (seconds since epoch)
             */
            timestampUnix: number;
        };
        TeamUser: {
            /** @description Email of the user */
            email: string;
            /**
             * Format: uuid
             * @description Identifier of the user
             */
            id: string;
        };
        Template: {
            /**
             * @deprecated
             * @description Aliases of the template
             */
            aliases: string[];
            /**
             * Format: int32
             * @description Number of times the template was built
             */
            buildCount: number;
            /** @description Identifier of the last successful build for given template */
            buildID: string;
            buildStatus: components["schemas"]["TemplateBuildStatus"];
            cpuCount: components["schemas"]["CPUCount"];
            /**
             * Format: date-time
             * @description Time when the template was created
             */
            createdAt: string;
            createdBy: components["schemas"]["TeamUser"] | null;
            diskSizeMB: components["schemas"]["DiskSizeMB"];
            envdVersion: components["schemas"]["EnvdVersion"];
            /**
             * Format: date-time
             * @description Time when the template was last used
             */
            lastSpawnedAt: string | null;
            memoryMB: components["schemas"]["MemoryMB"];
            /** @description Names of the template (namespace/alias format when namespaced) */
            names: string[];
            /** @description Whether the template is public or only accessible by the team */
            public: boolean;
            /**
             * Format: int64
             * @description Number of times the template was used
             */
            spawnCount: number;
            /** @description Identifier of the template */
            templateID: string;
            /**
             * Format: date-time
             * @description Time when the template was last updated
             */
            updatedAt: string;
        };
        TemplateAliasResponse: {
            /** @description Whether the template is public or only accessible by the team */
            public: boolean;
            /** @description Identifier of the template */
            templateID: string;
        };
        TemplateBuild: {
            /**
             * Format: uuid
             * @description Identifier of the build
             */
            buildID: string;
            cpuCount: components["schemas"]["CPUCount"];
            /**
             * Format: date-time
             * @description Time when the build was created
             */
            createdAt: string;
            diskSizeMB?: components["schemas"]["DiskSizeMB"];
            envdVersion?: components["schemas"]["EnvdVersion"];
            /**
             * Format: date-time
             * @description Time when the build was finished
             */
            finishedAt?: string;
            memoryMB: components["schemas"]["MemoryMB"];
            status: components["schemas"]["TemplateBuildStatus"];
            /**
             * Format: date-time
             * @description Time when the build was last updated
             */
            updatedAt: string;
        };
        TemplateBuildFileUpload: {
            /** @description Whether the file is already present in the cache */
            present: boolean;
            /** @description Url where the file should be uploaded to */
            url?: string;
        };
        TemplateBuildInfo: {
            /** @description Identifier of the build */
            buildID: string;
            /**
             * @description Build logs structured
             * @default []
             */
            logEntries: components["schemas"]["BuildLogEntry"][];
            /**
             * @description Build logs
             * @default []
             */
            logs: string[];
            reason?: components["schemas"]["BuildStatusReason"];
            status: components["schemas"]["TemplateBuildStatus"];
            /** @description Identifier of the template */
            templateID: string;
        };
        TemplateBuildLogsResponse: {
            /**
             * @description Build logs structured
             * @default []
             */
            logs: components["schemas"]["BuildLogEntry"][];
        };
        TemplateBuildRequest: {
            /** @description Alias of the template */
            alias?: string;
            cpuCount?: components["schemas"]["CPUCount"];
            /** @description Dockerfile for the template */
            dockerfile: string;
            memoryMB?: components["schemas"]["MemoryMB"];
            /** @description Ready check command to execute in the template after the build */
            readyCmd?: string;
            /** @description Start command to execute in the template after the build */
            startCmd?: string;
            /** @description Identifier of the team */
            teamID?: string;
        };
        TemplateBuildRequestV2: {
            /** @description Alias of the template */
            alias: string;
            cpuCount?: components["schemas"]["CPUCount"];
            memoryMB?: components["schemas"]["MemoryMB"];
            /**
             * @deprecated
             * @description Identifier of the team
             */
            teamID?: string;
        };
        TemplateBuildRequestV3: {
            /**
             * @deprecated
             * @description Alias of the template. Deprecated, use name instead.
             */
            alias?: string;
            cpuCount?: components["schemas"]["CPUCount"];
            memoryMB?: components["schemas"]["MemoryMB"];
            /** @description Name of the template. Can include a tag with colon separator (e.g. "my-template" or "my-template:v1"). If tag is included, it will be treated as if the tag was provided in the tags array. */
            name?: string;
            /** @description Tags to assign to the template build */
            tags?: string[];
            /**
             * @deprecated
             * @description Identifier of the team
             */
            teamID?: string;
        };
        TemplateBuildStartV2: {
            /**
             * @description Whether the whole build should be forced to run regardless of the cache
             * @default false
             */
            force?: boolean;
            /** @description Image to use as a base for the template build */
            fromImage?: string;
            fromImageRegistry?: components["schemas"]["FromImageRegistry"];
            /** @description Template to use as a base for the template build */
            fromTemplate?: string;
            /** @description Ready check command to execute in the template after the build */
            readyCmd?: string;
            /** @description Start command to execute in the template after the build */
            startCmd?: string;
            /**
             * @description List of steps to execute in the template build
             * @default []
             */
            steps?: components["schemas"]["TemplateStep"][];
        };
        /**
         * @description Status of the template build
         * @enum {string}
         */
        TemplateBuildStatus: "building" | "waiting" | "ready" | "error";
        TemplateLegacy: {
            /** @description Aliases of the template */
            aliases: string[];
            /**
             * Format: int32
             * @description Number of times the template was built
             */
            buildCount: number;
            /** @description Identifier of the last successful build for given template */
            buildID: string;
            cpuCount: components["schemas"]["CPUCount"];
            /**
             * Format: date-time
             * @description Time when the template was created
             */
            createdAt: string;
            createdBy: components["schemas"]["TeamUser"] | null;
            diskSizeMB: components["schemas"]["DiskSizeMB"];
            envdVersion: components["schemas"]["EnvdVersion"];
            /**
             * Format: date-time
             * @description Time when the template was last used
             */
            lastSpawnedAt: string | null;
            memoryMB: components["schemas"]["MemoryMB"];
            /** @description Whether the template is public or only accessible by the team */
            public: boolean;
            /**
             * Format: int64
             * @description Number of times the template was used
             */
            spawnCount: number;
            /** @description Identifier of the template */
            templateID: string;
            /**
             * Format: date-time
             * @description Time when the template was last updated
             */
            updatedAt: string;
        };
        TemplateRequestResponseV3: {
            /**
             * @deprecated
             * @description Aliases of the template
             */
            aliases: string[];
            /** @description Identifier of the last successful build for given template */
            buildID: string;
            /** @description Names of the template */
            names: string[];
            /** @description Whether the template is public or only accessible by the team */
            public: boolean;
            /** @description Tags assigned to the template build */
            tags: string[];
            /** @description Identifier of the template */
            templateID: string;
        };
        /** @description Step in the template build process */
        TemplateStep: {
            /**
             * @description Arguments for the step
             * @default []
             */
            args?: string[];
            /** @description Hash of the files used in the step */
            filesHash?: string;
            /**
             * @description Whether the step should be forced to run regardless of the cache
             * @default false
             */
            force?: boolean;
            /** @description Type of the step */
            type: string;
        };
        TemplateUpdateRequest: {
            /** @description Whether the template is public or only accessible by the team */
            public?: boolean;
        };
        TemplateUpdateResponse: {
            /** @description Names of the template (namespace/alias format when namespaced) */
            names: string[];
        };
        TemplateWithBuilds: {
            /**
             * @deprecated
             * @description Aliases of the template
             */
            aliases: string[];
            /** @description List of builds for the template */
            builds: components["schemas"]["TemplateBuild"][];
            /**
             * Format: date-time
             * @description Time when the template was created
             */
            createdAt: string;
            /**
             * Format: date-time
             * @description Time when the template was last used
             */
            lastSpawnedAt: string | null;
            /** @description Names of the template (namespace/alias format when namespaced) */
            names: string[];
            /** @description Whether the template is public or only accessible by the team */
            public: boolean;
            /**
             * Format: int64
             * @description Number of times the template was used
             */
            spawnCount: number;
            /** @description Identifier of the template */
            templateID: string;
            /**
             * Format: date-time
             * @description Time when the template was last updated
             */
            updatedAt: string;
        };
        UpdateTeamAPIKey: {
            /** @description New name for the API key */
            name: string;
        };
    };
    responses: {
        /** @description Bad request */
        400: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
        /** @description Authentication error */
        401: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
        /** @description Forbidden */
        403: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
        /** @description Not found */
        404: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
        /** @description Conflict */
        409: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
        /** @description Server error */
        500: {
            headers: {
                [name: string]: unknown;
            };
            content: {
                "application/json": components["schemas"]["Error"];
            };
        };
    };
    parameters: {
        accessTokenID: string;
        apiKeyID: string;
        buildID: string;
        nodeID: string;
        /** @description Maximum number of items to return per page */
        paginationLimit: number;
        /** @description Cursor to start the list from */
        paginationNextToken: string;
        sandboxID: string;
        tag: string;
        teamID: string;
        templateID: string;
    };
    requestBodies: never;
    headers: never;
    pathItems: never;
}

/**
 * Logger interface compatible with {@link console} used for logging Sandbox messages.
 */
interface Logger {
    /**
     * Debug level logging method.
     */
    debug?: (...args: any[]) => void;
    /**
     * Info level logging method.
     */
    info?: (...args: any[]) => void;
    /**
     * Warn level logging method.
     */
    warn?: (...args: any[]) => void;
    /**
     * Error level logging method.
     */
    error?: (...args: any[]) => void;
}

/**
 * Connection options for requests to the API.
 */
interface ConnectionOpts {
    /**
     * E2B API key to use for authentication.
     *
     * @default E2B_API_KEY // environment variable
     */
    apiKey?: string;
    /**
     * E2B access token to use for authentication.
     *
     * @default E2B_ACCESS_TOKEN // environment variable
     */
    accessToken?: string;
    /**
     * Domain to use for the API.
     *
     * @default E2B_DOMAIN // environment variable or `e2b.app`
     */
    domain?: string;
    /**
     * API Url to use for the API.
     * @internal
     * @default E2B_API_URL // environment variable or `https://api.${domain}`
     */
    apiUrl?: string;
    /**
     * Sandbox Url to use for the API.
     * @internal
     * @default E2B_SANDBOX_URL // environment variable or `https://${port}-${sandboxID}.${domain}`
     */
    sandboxUrl?: string;
    /**
     * If true the SDK starts in the debug mode and connects to the local envd API server.
     * @internal
     * @default E2B_DEBUG // environment variable or `false`
     */
    debug?: boolean;
    /**
     * Timeout for requests to the API in **milliseconds**.
     *
     * @default 60_000 // 60 seconds
     */
    requestTimeoutMs?: number;
    /**
     * Logger to use for logging messages. It can accept any object that implements `Logger` interfacefor example, {@link console}.
     */
    logger?: Logger;
    /**
     * Additional headers to send with the request.
     */
    headers?: Record<string, string>;
}
/**
 * Configuration for connecting to the API.
 */
declare class ConnectionConfig {
    static envdPort: number;
    readonly debug: boolean;
    readonly domain: string;
    readonly apiUrl: string;
    readonly sandboxUrl?: string;
    readonly logger?: Logger;
    readonly requestTimeoutMs: number;
    readonly apiKey?: string;
    readonly accessToken?: string;
    readonly headers?: Record<string, string>;
    constructor(opts?: ConnectionOpts);
    private static get domain();
    private static get apiUrl();
    private static get sandboxUrl();
    private static get debug();
    private static get apiKey();
    private static get accessToken();
    getSignal(requestTimeoutMs?: number): AbortSignal | undefined;
    getSandboxUrl(sandboxId: string, opts: {
        sandboxDomain: string;
        envdPort: number;
    }): string;
    getHost(sandboxId: string, port: number, sandboxDomain: string): string;
}
type Username = string;

/**
 * Client for interacting with the E2B API.
 */
declare class ApiClient {
    readonly api: ReturnType<typeof createClient<paths>>;
    constructor(config: ConnectionConfig, opts?: {
        requireAccessToken?: boolean;
        requireApiKey?: boolean;
    });
}

/**
 * Base class for all sandbox errors.
 *
 * Thrown when general sandbox errors occur.
 */
declare class SandboxError extends Error {
    constructor(message?: string, stackTrace?: string);
}
/**
 * Thrown when a timeout error occurs.
 *
 * The [unavailable] error type is caused by sandbox timeout.
 *
 * The [canceled] error type is caused by exceeding request timeout.
 *
 * The [deadline_exceeded] error type is caused by exceeding the timeout for command execution, watch, etc.
 *
 * The [unknown] error type is sometimes caused by the sandbox timeout when the request is not processed correctly.
 */
declare class TimeoutError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when an invalid argument is provided.
 */
declare class InvalidArgumentError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when there is not enough disk space.
 */
declare class NotEnoughSpaceError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when a resource is not found.
 */
declare class NotFoundError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when authentication fails.
 */
declare class AuthenticationError extends Error {
    constructor(message: string);
}
/**
 * Thrown when git authentication fails.
 */
declare class GitAuthError extends AuthenticationError {
    constructor(message: string);
}
/**
 * Thrown when git upstream tracking is missing.
 */
declare class GitUpstreamError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when the template uses old envd version. It isn't compatible with the new SDK.
 */
declare class TemplateError extends SandboxError {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when the API rate limit is exceeded.
 */
declare class RateLimitError extends SandboxError {
    constructor(message: string);
}
/**
 * Thrown when the build fails.
 */
declare class BuildError extends Error {
    constructor(message: string, stackTrace?: string);
}
/**
 * Thrown when the file upload fails.
 */
declare class FileUploadError extends BuildError {
    constructor(message: string, stackTrace?: string);
}

/**
 * Get the URL signature for the specified path, operation and user.
 *
 * @param path Path to the file in the sandbox.
 *
 * @param operation File system operation. Can be either `read` or `write`.
 *
 * @param user Sandbox user.
 *
 * @param expirationInSeconds Optional signature expiration time in seconds.
 */
interface SignatureOpts {
    path: string;
    operation: 'read' | 'write';
    user: string | undefined;
    expirationInSeconds?: number;
    envdAccessToken?: string;
}
declare function getSignature({ path, operation, user, expirationInSeconds, envdAccessToken, }: SignatureOpts): Promise<{
    signature: string;
    expiration: number | null;
}>;

/**
 * @generated from message process.PTY
 */
type PTY = Message<'process.PTY'> & {
    /**
     * @generated from field: process.PTY.Size size = 1;
     */
    size?: PTY_Size;
};
/**
 * @generated from message process.PTY.Size
 */
type PTY_Size = Message<'process.PTY.Size'> & {
    /**
     * @generated from field: uint32 cols = 1;
     */
    cols: number;
    /**
     * @generated from field: uint32 rows = 2;
     */
    rows: number;
};
/**
 * @generated from message process.ProcessConfig
 */
type ProcessConfig = Message<'process.ProcessConfig'> & {
    /**
     * @generated from field: string cmd = 1;
     */
    cmd: string;
    /**
     * @generated from field: repeated string args = 2;
     */
    args: string[];
    /**
     * @generated from field: map<string, string> envs = 3;
     */
    envs: {
        [key: string]: string;
    };
    /**
     * @generated from field: optional string cwd = 4;
     */
    cwd?: string;
};
/**
 * @generated from message process.ListRequest
 */
type ListRequest = Message<'process.ListRequest'> & {};
/**
 * Describes the message process.ListRequest.
 * Use `create(ListRequestSchema)` to create a new message.
 */
declare const ListRequestSchema: GenMessage<ListRequest>;
/**
 * @generated from message process.ProcessInfo
 */
type ProcessInfo$1 = Message<'process.ProcessInfo'> & {
    /**
     * @generated from field: process.ProcessConfig config = 1;
     */
    config?: ProcessConfig;
    /**
     * @generated from field: uint32 pid = 2;
     */
    pid: number;
    /**
     * @generated from field: optional string tag = 3;
     */
    tag?: string;
};
/**
 * @generated from message process.ListResponse
 */
type ListResponse = Message<'process.ListResponse'> & {
    /**
     * @generated from field: repeated process.ProcessInfo processes = 1;
     */
    processes: ProcessInfo$1[];
};
/**
 * Describes the message process.ListResponse.
 * Use `create(ListResponseSchema)` to create a new message.
 */
declare const ListResponseSchema: GenMessage<ListResponse>;
/**
 * @generated from message process.StartRequest
 */
type StartRequest = Message<'process.StartRequest'> & {
    /**
     * @generated from field: process.ProcessConfig process = 1;
     */
    process?: ProcessConfig;
    /**
     * @generated from field: optional process.PTY pty = 2;
     */
    pty?: PTY;
    /**
     * @generated from field: optional string tag = 3;
     */
    tag?: string;
    /**
     * @generated from field: optional bool stdin = 4;
     */
    stdin?: boolean;
};
/**
 * Describes the message process.StartRequest.
 * Use `create(StartRequestSchema)` to create a new message.
 */
declare const StartRequestSchema: GenMessage<StartRequest>;
/**
 * @generated from message process.UpdateRequest
 */
type UpdateRequest = Message<'process.UpdateRequest'> & {
    /**
     * @generated from field: process.ProcessSelector process = 1;
     */
    process?: ProcessSelector;
    /**
     * @generated from field: optional process.PTY pty = 2;
     */
    pty?: PTY;
};
/**
 * Describes the message process.UpdateRequest.
 * Use `create(UpdateRequestSchema)` to create a new message.
 */
declare const UpdateRequestSchema: GenMessage<UpdateRequest>;
/**
 * @generated from message process.UpdateResponse
 */
type UpdateResponse = Message<'process.UpdateResponse'> & {};
/**
 * Describes the message process.UpdateResponse.
 * Use `create(UpdateResponseSchema)` to create a new message.
 */
declare const UpdateResponseSchema: GenMessage<UpdateResponse>;
/**
 * @generated from message process.ProcessEvent
 */
type ProcessEvent = Message<'process.ProcessEvent'> & {
    /**
     * @generated from oneof process.ProcessEvent.event
     */
    event: {
        /**
         * @generated from field: process.ProcessEvent.StartEvent start = 1;
         */
        value: ProcessEvent_StartEvent;
        case: 'start';
    } | {
        /**
         * @generated from field: process.ProcessEvent.DataEvent data = 2;
         */
        value: ProcessEvent_DataEvent;
        case: 'data';
    } | {
        /**
         * @generated from field: process.ProcessEvent.EndEvent end = 3;
         */
        value: ProcessEvent_EndEvent;
        case: 'end';
    } | {
        /**
         * @generated from field: process.ProcessEvent.KeepAlive keepalive = 4;
         */
        value: ProcessEvent_KeepAlive;
        case: 'keepalive';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * @generated from message process.ProcessEvent.StartEvent
 */
type ProcessEvent_StartEvent = Message<'process.ProcessEvent.StartEvent'> & {
    /**
     * @generated from field: uint32 pid = 1;
     */
    pid: number;
};
/**
 * @generated from message process.ProcessEvent.DataEvent
 */
type ProcessEvent_DataEvent = Message<'process.ProcessEvent.DataEvent'> & {
    /**
     * @generated from oneof process.ProcessEvent.DataEvent.output
     */
    output: {
        /**
         * @generated from field: bytes stdout = 1;
         */
        value: Uint8Array;
        case: 'stdout';
    } | {
        /**
         * @generated from field: bytes stderr = 2;
         */
        value: Uint8Array;
        case: 'stderr';
    } | {
        /**
         * @generated from field: bytes pty = 3;
         */
        value: Uint8Array;
        case: 'pty';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * @generated from message process.ProcessEvent.EndEvent
 */
type ProcessEvent_EndEvent = Message<'process.ProcessEvent.EndEvent'> & {
    /**
     * @generated from field: sint32 exit_code = 1;
     */
    exitCode: number;
    /**
     * @generated from field: bool exited = 2;
     */
    exited: boolean;
    /**
     * @generated from field: string status = 3;
     */
    status: string;
    /**
     * @generated from field: optional string error = 4;
     */
    error?: string;
};
/**
 * @generated from message process.ProcessEvent.KeepAlive
 */
type ProcessEvent_KeepAlive = Message<'process.ProcessEvent.KeepAlive'> & {};
/**
 * @generated from message process.StartResponse
 */
type StartResponse = Message<'process.StartResponse'> & {
    /**
     * @generated from field: process.ProcessEvent event = 1;
     */
    event?: ProcessEvent;
};
/**
 * Describes the message process.StartResponse.
 * Use `create(StartResponseSchema)` to create a new message.
 */
declare const StartResponseSchema: GenMessage<StartResponse>;
/**
 * @generated from message process.ConnectResponse
 */
type ConnectResponse = Message<'process.ConnectResponse'> & {
    /**
     * @generated from field: process.ProcessEvent event = 1;
     */
    event?: ProcessEvent;
};
/**
 * Describes the message process.ConnectResponse.
 * Use `create(ConnectResponseSchema)` to create a new message.
 */
declare const ConnectResponseSchema: GenMessage<ConnectResponse>;
/**
 * @generated from message process.SendInputRequest
 */
type SendInputRequest = Message<'process.SendInputRequest'> & {
    /**
     * @generated from field: process.ProcessSelector process = 1;
     */
    process?: ProcessSelector;
    /**
     * @generated from field: process.ProcessInput input = 2;
     */
    input?: ProcessInput;
};
/**
 * Describes the message process.SendInputRequest.
 * Use `create(SendInputRequestSchema)` to create a new message.
 */
declare const SendInputRequestSchema: GenMessage<SendInputRequest>;
/**
 * @generated from message process.SendInputResponse
 */
type SendInputResponse = Message<'process.SendInputResponse'> & {};
/**
 * Describes the message process.SendInputResponse.
 * Use `create(SendInputResponseSchema)` to create a new message.
 */
declare const SendInputResponseSchema: GenMessage<SendInputResponse>;
/**
 * @generated from message process.ProcessInput
 */
type ProcessInput = Message<'process.ProcessInput'> & {
    /**
     * @generated from oneof process.ProcessInput.input
     */
    input: {
        /**
         * @generated from field: bytes stdin = 1;
         */
        value: Uint8Array;
        case: 'stdin';
    } | {
        /**
         * @generated from field: bytes pty = 2;
         */
        value: Uint8Array;
        case: 'pty';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * @generated from message process.StreamInputRequest
 */
type StreamInputRequest = Message<'process.StreamInputRequest'> & {
    /**
     * @generated from oneof process.StreamInputRequest.event
     */
    event: {
        /**
         * @generated from field: process.StreamInputRequest.StartEvent start = 1;
         */
        value: StreamInputRequest_StartEvent;
        case: 'start';
    } | {
        /**
         * @generated from field: process.StreamInputRequest.DataEvent data = 2;
         */
        value: StreamInputRequest_DataEvent;
        case: 'data';
    } | {
        /**
         * @generated from field: process.StreamInputRequest.KeepAlive keepalive = 3;
         */
        value: StreamInputRequest_KeepAlive;
        case: 'keepalive';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * Describes the message process.StreamInputRequest.
 * Use `create(StreamInputRequestSchema)` to create a new message.
 */
declare const StreamInputRequestSchema: GenMessage<StreamInputRequest>;
/**
 * @generated from message process.StreamInputRequest.StartEvent
 */
type StreamInputRequest_StartEvent = Message<'process.StreamInputRequest.StartEvent'> & {
    /**
     * @generated from field: process.ProcessSelector process = 1;
     */
    process?: ProcessSelector;
};
/**
 * @generated from message process.StreamInputRequest.DataEvent
 */
type StreamInputRequest_DataEvent = Message<'process.StreamInputRequest.DataEvent'> & {
    /**
     * @generated from field: process.ProcessInput input = 2;
     */
    input?: ProcessInput;
};
/**
 * @generated from message process.StreamInputRequest.KeepAlive
 */
type StreamInputRequest_KeepAlive = Message<'process.StreamInputRequest.KeepAlive'> & {};
/**
 * @generated from message process.StreamInputResponse
 */
type StreamInputResponse = Message<'process.StreamInputResponse'> & {};
/**
 * Describes the message process.StreamInputResponse.
 * Use `create(StreamInputResponseSchema)` to create a new message.
 */
declare const StreamInputResponseSchema: GenMessage<StreamInputResponse>;
/**
 * @generated from message process.SendSignalRequest
 */
type SendSignalRequest = Message<'process.SendSignalRequest'> & {
    /**
     * @generated from field: process.ProcessSelector process = 1;
     */
    process?: ProcessSelector;
    /**
     * @generated from field: process.Signal signal = 2;
     */
    signal: Signal;
};
/**
 * Describes the message process.SendSignalRequest.
 * Use `create(SendSignalRequestSchema)` to create a new message.
 */
declare const SendSignalRequestSchema: GenMessage<SendSignalRequest>;
/**
 * @generated from message process.SendSignalResponse
 */
type SendSignalResponse = Message<'process.SendSignalResponse'> & {};
/**
 * Describes the message process.SendSignalResponse.
 * Use `create(SendSignalResponseSchema)` to create a new message.
 */
declare const SendSignalResponseSchema: GenMessage<SendSignalResponse>;
/**
 * @generated from message process.ConnectRequest
 */
type ConnectRequest = Message<'process.ConnectRequest'> & {
    /**
     * @generated from field: process.ProcessSelector process = 1;
     */
    process?: ProcessSelector;
};
/**
 * Describes the message process.ConnectRequest.
 * Use `create(ConnectRequestSchema)` to create a new message.
 */
declare const ConnectRequestSchema: GenMessage<ConnectRequest>;
/**
 * @generated from message process.ProcessSelector
 */
type ProcessSelector = Message<'process.ProcessSelector'> & {
    /**
     * @generated from oneof process.ProcessSelector.selector
     */
    selector: {
        /**
         * @generated from field: uint32 pid = 1;
         */
        value: number;
        case: 'pid';
    } | {
        /**
         * @generated from field: string tag = 2;
         */
        value: string;
        case: 'tag';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * @generated from enum process.Signal
 */
declare enum Signal {
    /**
     * @generated from enum value: SIGNAL_UNSPECIFIED = 0;
     */
    UNSPECIFIED = 0,
    /**
     * @generated from enum value: SIGNAL_SIGTERM = 15;
     */
    SIGTERM = 15,
    /**
     * @generated from enum value: SIGNAL_SIGKILL = 9;
     */
    SIGKILL = 9
}
/**
 * @generated from service process.Process
 */
declare const Process: GenService<{
    /**
     * @generated from rpc process.Process.List
     */
    list: {
        methodKind: 'unary';
        input: typeof ListRequestSchema;
        output: typeof ListResponseSchema;
    };
    /**
     * @generated from rpc process.Process.Connect
     */
    connect: {
        methodKind: 'server_streaming';
        input: typeof ConnectRequestSchema;
        output: typeof ConnectResponseSchema;
    };
    /**
     * @generated from rpc process.Process.Start
     */
    start: {
        methodKind: 'server_streaming';
        input: typeof StartRequestSchema;
        output: typeof StartResponseSchema;
    };
    /**
     * @generated from rpc process.Process.Update
     */
    update: {
        methodKind: 'unary';
        input: typeof UpdateRequestSchema;
        output: typeof UpdateResponseSchema;
    };
    /**
     * Client input stream ensures ordering of messages
     *
     * @generated from rpc process.Process.StreamInput
     */
    streamInput: {
        methodKind: 'client_streaming';
        input: typeof StreamInputRequestSchema;
        output: typeof StreamInputResponseSchema;
    };
    /**
     * @generated from rpc process.Process.SendInput
     */
    sendInput: {
        methodKind: 'unary';
        input: typeof SendInputRequestSchema;
        output: typeof SendInputResponseSchema;
    };
    /**
     * @generated from rpc process.Process.SendSignal
     */
    sendSignal: {
        methodKind: 'unary';
        input: typeof SendSignalRequestSchema;
        output: typeof SendSignalResponseSchema;
    };
}>;

/**
 * @generated from message filesystem.FilesystemEvent
 */
type FilesystemEvent$1 = Message<'filesystem.FilesystemEvent'> & {
    /**
     * @generated from field: string name = 1;
     */
    name: string;
    /**
     * @generated from field: filesystem.EventType type = 2;
     */
    type: EventType;
};
/**
 * @generated from message filesystem.WatchDirResponse
 */
type WatchDirResponse = Message<'filesystem.WatchDirResponse'> & {
    /**
     * @generated from oneof filesystem.WatchDirResponse.event
     */
    event: {
        /**
         * @generated from field: filesystem.WatchDirResponse.StartEvent start = 1;
         */
        value: WatchDirResponse_StartEvent;
        case: 'start';
    } | {
        /**
         * @generated from field: filesystem.FilesystemEvent filesystem = 2;
         */
        value: FilesystemEvent$1;
        case: 'filesystem';
    } | {
        /**
         * @generated from field: filesystem.WatchDirResponse.KeepAlive keepalive = 3;
         */
        value: WatchDirResponse_KeepAlive;
        case: 'keepalive';
    } | {
        case: undefined;
        value?: undefined;
    };
};
/**
 * @generated from message filesystem.WatchDirResponse.StartEvent
 */
type WatchDirResponse_StartEvent = Message<'filesystem.WatchDirResponse.StartEvent'> & {};
/**
 * @generated from message filesystem.WatchDirResponse.KeepAlive
 */
type WatchDirResponse_KeepAlive = Message<'filesystem.WatchDirResponse.KeepAlive'> & {};
/**
 * @generated from enum filesystem.EventType
 */
declare enum EventType {
    /**
     * @generated from enum value: EVENT_TYPE_UNSPECIFIED = 0;
     */
    UNSPECIFIED = 0,
    /**
     * @generated from enum value: EVENT_TYPE_CREATE = 1;
     */
    CREATE = 1,
    /**
     * @generated from enum value: EVENT_TYPE_WRITE = 2;
     */
    WRITE = 2,
    /**
     * @generated from enum value: EVENT_TYPE_REMOVE = 3;
     */
    REMOVE = 3,
    /**
     * @generated from enum value: EVENT_TYPE_RENAME = 4;
     */
    RENAME = 4,
    /**
     * @generated from enum value: EVENT_TYPE_CHMOD = 5;
     */
    CHMOD = 5
}

declare class EnvdApiClient {
    readonly api: ReturnType<typeof createClient<paths>>;
    readonly version: string;
    constructor(config: Pick<ConnectionConfig, 'apiUrl' | 'logger' | 'accessToken'> & {
        fetch?: (request: Request) => ReturnType<typeof fetch>;
        headers?: Record<string, string>;
    }, metadata: {
        version: string;
    });
}

/**
 * Sandbox filesystem event types.
 */
declare enum FilesystemEventType {
    /**
     * Filesystem object permissions were changed.
     */
    CHMOD = "chmod",
    /**
     * Filesystem object was created.
     */
    CREATE = "create",
    /**
     * Filesystem object was removed.
     */
    REMOVE = "remove",
    /**
     * Filesystem object was renamed.
     */
    RENAME = "rename",
    /**
     * Filesystem object was written to.
     */
    WRITE = "write"
}
/**
 * Information about a filesystem event.
 */
interface FilesystemEvent {
    /**
     * Relative path to the filesystem object.
     */
    name: string;
    /**
     * Filesystem operation event type.
     */
    type: FilesystemEventType;
}
/**
 * Handle for watching a directory in the sandbox filesystem.
 *
 * Use {@link WatchHandle.stop} to stop watching the directory.
 */
declare class WatchHandle {
    private readonly handleStop;
    private readonly events;
    private readonly onEvent?;
    private readonly onExit?;
    constructor(handleStop: () => void, events: AsyncIterable<WatchDirResponse>, onEvent?: ((event: FilesystemEvent) => void | Promise<void>) | undefined, onExit?: ((err?: Error) => void | Promise<void>) | undefined);
    /**
     * Stop watching the directory.
     */
    stop(): Promise<void>;
    private iterateEvents;
    private handleEvents;
}

/**
 * Sandbox filesystem object information.
 */
interface WriteInfo {
    /**
     * Name of the filesystem object.
     */
    name: string;
    /**
     * Type of the filesystem object.
     */
    type?: FileType;
    /**
     * Path to the filesystem object.
     */
    path: string;
}
interface EntryInfo extends WriteInfo {
    /**
     * Size of the filesystem object in bytes.
     */
    size: number;
    /**
     * File mode and permission bits.
     */
    mode: number;
    /**
     * String representation of file permissions (e.g. 'rwxr-xr-x').
     */
    permissions: string;
    /**
     * Owner of the filesystem object.
     */
    owner: string;
    /**
     * Group owner of the filesystem object.
     */
    group: string;
    /**
     * Last modification time of the filesystem object.
     */
    modifiedTime?: Date;
    /**
     * If the filesystem object is a symlink, this is the target of the symlink.
     */
    symlinkTarget?: string;
}
/**
 * Sandbox filesystem object type.
 */
declare enum FileType {
    /**
     * Filesystem object is a file.
     */
    FILE = "file",
    /**
     * Filesystem object is a directory.
     */
    DIR = "dir"
}
type WriteEntry = {
    path: string;
    data: string | ArrayBuffer | Blob | ReadableStream;
};
/**
 * Options for the sandbox filesystem operations.
 */
interface FilesystemRequestOpts extends Partial<Pick<ConnectionOpts, 'requestTimeoutMs'>> {
    /**
     * User to use for the operation in the sandbox.
     * This affects the resolution of relative paths and ownership of the created filesystem objects.
     */
    user?: Username;
}
interface FilesystemListOpts extends FilesystemRequestOpts {
    /**
     * Depth of the directory to list.
     */
    depth?: number;
}
/**
 * Options for watching a directory.
 */
interface WatchOpts extends FilesystemRequestOpts {
    /**
     * Timeout for the watch operation in **milliseconds**.
     * You can pass `0` to disable the timeout.
     *
     * @default 60_000 // 60 seconds
     */
    timeoutMs?: number;
    /**
     * Callback to call when the watch operation stops.
     */
    onExit?: (err?: Error) => void | Promise<void>;
    /**
     * Watch the directory recursively
     */
    recursive?: boolean;
}
/**
 * Module for interacting with the sandbox filesystem.
 */
declare class Filesystem {
    private readonly envdApi;
    private readonly connectionConfig;
    private readonly rpc;
    private readonly defaultWatchTimeout;
    private readonly defaultWatchRecursive;
    constructor(transport: Transport, envdApi: EnvdApiClient, connectionConfig: ConnectionConfig);
    /**
     * Read file content as a `string`.
     *
     * You can pass `text`, `bytes`, `blob`, or `stream` to `opts.format` to change the return type.
     *
     * @param path path to the file.
     * @param opts connection options.
     * @param [opts.format] format of the file content`text` by default.
     *
     * @returns file content as string
     */
    read(path: string, opts?: FilesystemRequestOpts & {
        format?: 'text';
    }): Promise<string>;
    /**
     * Read file content as a `Uint8Array`.
     *
     * You can pass `text`, `bytes`, `blob`, or `stream` to `opts.format` to change the return type.
     *
     * @param path path to the file.
     * @param opts connection options.
     * @param [opts.format] format of the file content`bytes`.
     *
     * @returns file content as `Uint8Array`
     */
    read(path: string, opts?: FilesystemRequestOpts & {
        format: 'bytes';
    }): Promise<Uint8Array>;
    /**
     * Read file content as a `Blob`.
     *
     * You can pass `text`, `bytes`, `blob`, or `stream` to `opts.format` to change the return type.
     *
     * @param path path to the file.
     * @param opts connection options.
     * @param [opts.format] format of the file content`blob`.
     *
     * @returns file content as `Blob`
     */
    read(path: string, opts?: FilesystemRequestOpts & {
        format: 'blob';
    }): Promise<Blob>;
    /**
     * Read file content as a `ReadableStream`.
     *
     * You can pass `text`, `bytes`, `blob`, or `stream` to `opts.format` to change the return type.
     *
     * @param path path to the file.
     * @param opts connection options.
     * @param [opts.format] format of the file content`stream`.
     *
     * @returns file content as `ReadableStream`
     */
    read(path: string, opts?: FilesystemRequestOpts & {
        format: 'stream';
    }): Promise<ReadableStream<Uint8Array>>;
    /**
     * Write content to a file.
     *
     *
     * Writing to a file that doesn't exist creates the file.
     *
     * Writing to a file that already exists overwrites the file.
     *
     * Writing to a file at path that doesn't exist creates the necessary directories.
     *
     * @param path path to file.
     * @param data data to write to the file. Data can be a string, `ArrayBuffer`, `Blob`, or `ReadableStream`.
     * @param opts connection options.
     *
     * @returns information about the written file
     */
    write(path: string, data: string | ArrayBuffer | Blob | ReadableStream, opts?: FilesystemRequestOpts): Promise<WriteInfo>;
    write(files: WriteEntry[], opts?: FilesystemRequestOpts): Promise<WriteInfo[]>;
    /**
     * Write multiple files.
     *
     *
     * Writing to a file that doesn't exist creates the file.
     *
     * Writing to a file that already exists overwrites the file.
     *
     * Writing to a file at path that doesn't exist creates the necessary directories.
     *
     * @param files list of files to write as `WriteEntry` objects, each containing `path` and `data`.
     * @param opts connection options.
     *
     * @returns information about the written files
     */
    writeFiles(files: WriteEntry[], opts?: FilesystemRequestOpts): Promise<WriteInfo[]>;
    /**
     * List entries in a directory.
     *
     * @param path path to the directory.
     * @param opts connection options.
     *
     * @returns list of entries in the sandbox filesystem directory.
     */
    list(path: string, opts?: FilesystemListOpts): Promise<EntryInfo[]>;
    /**
     * Create a new directory and all directories along the way if needed on the specified path.
     *
     * @param path path to a new directory. For example '/dirA/dirB' when creating 'dirB'.
     * @param opts connection options.
     *
     * @returns `true` if the directory was created, `false` if it already exists.
     */
    makeDir(path: string, opts?: FilesystemRequestOpts): Promise<boolean>;
    /**
     * Rename a file or directory.
     *
     * @param oldPath path to the file or directory to rename.
     * @param newPath new path for the file or directory.
     * @param opts connection options.
     *
     * @returns information about renamed file or directory.
     */
    rename(oldPath: string, newPath: string, opts?: FilesystemRequestOpts): Promise<EntryInfo>;
    /**
     * Remove a file or directory.
     *
     * @param path path to a file or directory.
     * @param opts connection options.
     */
    remove(path: string, opts?: FilesystemRequestOpts): Promise<void>;
    /**
     * Check if a file or a directory exists.
     *
     * @param path path to a file or a directory
     * @param opts connection options.
     *
     * @returns `true` if the file or directory exists, `false` otherwise
     */
    exists(path: string, opts?: FilesystemRequestOpts): Promise<boolean>;
    /**
     * Get information about a file or directory.
     *
     * @param path path to a file or directory.
     * @param opts connection options.
     *
     * @returns information about the file or directory like name, type, and path.
     */
    getInfo(path: string, opts?: FilesystemRequestOpts): Promise<EntryInfo>;
    /**
     * Start watching a directory for filesystem events.
     *
     * @param path path to directory to watch.
     * @param onEvent callback to call when an event in the directory occurs.
     * @param opts connection options.
     *
     * @returns `WatchHandle` object for stopping watching directory.
     */
    watchDir(path: string, onEvent: (event: FilesystemEvent) => void | Promise<void>, opts?: WatchOpts & {
        onExit?: (err?: Error) => void | Promise<void>;
    }): Promise<WatchHandle>;
}

declare const __brand: unique symbol;
type Brand<B> = {
    [__brand]: B;
};
type Branded<T, B> = T & Brand<B>;
type Stdout = Branded<string, 'stdout'>;
type Stderr = Branded<string, 'stderr'>;
type PtyOutput = Branded<Uint8Array, 'pty'>;
/**
 * Command execution result.
 */
interface CommandResult {
    /**
     * Command execution exit code.
     * `0` if the command finished successfully.
     */
    exitCode: number;
    /**
     * Error message from command execution if it failed.
     */
    error?: string;
    /**
     * Command stdout output.
     */
    stdout: string;
    /**
     * Command stderr output.
     */
    stderr: string;
}
/**
 * Error thrown when a command exits with a non-zero exit code.
 */
declare class CommandExitError extends SandboxError implements CommandResult {
    private readonly result;
    constructor(result: CommandResult);
    /**
     * Command execution exit code.
     * `0` if the command finished successfully.
     */
    get exitCode(): number;
    /**
     * Error message from command execution.
     */
    get error(): string | undefined;
    /**
     * Command execution stdout output.
     */
    get stdout(): string;
    /**
     * Command execution stderr output.
     */
    get stderr(): string;
}
/**
 * Command execution handle.
 *
 * It provides methods for waiting for the command to finish, retrieving stdout/stderr, and killing the command.
 *
 * @property {number} pid process ID of the command.
 */
declare class CommandHandle implements Omit<CommandResult, 'exitCode' | 'error'>, Partial<Pick<CommandResult, 'exitCode' | 'error'>> {
    readonly pid: number;
    private readonly handleDisconnect;
    private readonly handleKill;
    private readonly events;
    private readonly onStdout?;
    private readonly onStderr?;
    private readonly onPty?;
    private _stdout;
    private _stderr;
    private result?;
    private iterationError?;
    private readonly _wait;
    /**
     * @hidden
     * @internal
     * @access protected
     */
    constructor(pid: number, handleDisconnect: () => void, handleKill: () => Promise<boolean>, events: AsyncIterable<ConnectResponse | StartResponse>, onStdout?: ((stdout: string) => void | Promise<void>) | undefined, onStderr?: ((stderr: string) => void | Promise<void>) | undefined, onPty?: ((pty: Uint8Array) => void | Promise<void>) | undefined);
    /**
     * Command execution exit code.
     * `0` if the command finished successfully.
     *
     * It is `undefined` if the command is still running.
     */
    get exitCode(): number | undefined;
    /**
     * Error message from command execution.
     */
    get error(): string | undefined;
    /**
     * Command execution stderr output.
     */
    get stderr(): string;
    /**
     * Command execution stdout output.
     */
    get stdout(): string;
    /**
     * Wait for the command to finish and return the result.
     * If the command exits with a non-zero exit code, it throws a `CommandExitError`.
     *
     * @returns `CommandResult` result of command execution.
     */
    wait(): Promise<CommandResult>;
    /**
     * Disconnect from the command.
     *
     * The command is not killed, but SDK stops receiving events from the command.
     * You can reconnect to the command using {@link Commands.connect}.
     */
    disconnect(): Promise<void>;
    /**
     * Kill the command.
     * It uses `SIGKILL` signal to kill the command.
     *
     * @returns `true` if the command was killed successfully, `false` if the command was not found.
     */
    kill(): Promise<boolean>;
    private iterateEvents;
    private handleEvents;
}

/* eslint-disable */
/**
 * This file was automatically generated by json-schema-to-typescript.
 * DO NOT MODIFY IT BY HAND. Instead, modify the source JSONSchema file,
 * and run json-schema-to-typescript to regenerate this file.
 */

interface McpServer$1 {
  airtable?: AirtableMCPServer
  aks?: AzureKubernetesServiceAKS
  apiGateway?: ApiGateway
  apify?: ApifyMCPServer
  arxiv?: ArXivMCPServer
  astGrep?: AstGrep
  astraDb?: AstraDB
  astroDocs?: AstroDocs
  atlan?: AtlanMCPServer
  atlasDocs?: AtlasDocs
  atlassian?: Atlassian
  audienseInsights?: AudienseInsights
  awsCdk?: AWSCDK
  awsCore?: AWSCoreMCPServer
  awsDiagram?: AWSDiagram
  awsDocumentation?: AWSDocumentation
  awsKbRetrievalServer?: AWSKBRetrievalArchived
  awsTerraform?: AWSTerraform
  azure?: Azure
  beagleSecurity?: BeagleSecurityMCPServer
  bitrefill?: Bitrefill
  box?: Box
  brave?: BraveSearch
  browserbase?: Browserbase
  buildkite?: Buildkite
  camunda?: CamundaBPMProcessEngineMCPServer
  cdataConnectcloud?: CDataConnectCloud
  charmhealth?: CharmHealthMCPServer
  chroma?: Chroma
  circleci?: CircleCI
  clickhouse?: OfficialClickHouseMCPServer
  close?: Close
  cloudRun?: CloudRunMCP
  cloudflareDocs?: CloudflareDocs
  cockroachdb?: CockroachDB
  codeInterpreter?: PythonInterpreter
  context7?: Context7
  couchbase?: Couchbase
  cylera?: TheOfficialMCPServerForCylera
  cyreslabAiShodan?: Shodan
  dappier?: Dappier
  dappierRemote?: DappierRemoteMCPServer
  dart?: DartAI
  databaseServer?: MCPDatabaseServer
  databutton?: Databutton
  deepwiki?: DeepWiki
  descope?: Descope
  desktopCommander?: DesktopCommander
  devhubCms?: DevHubCMS
  discord?: Discord
  dockerhub?: DockerHub
  dodoPayments?: DodoPayments
  dreamfactory?: DreamFactoryMCPServer
  duckduckgo?: DuckDuckGo
  dynatrace?: DynatraceMCPServer
  e2b?: E2B
  edubase?: EduBase
  effect?: EffectMCP
  elasticsearch?: Elasticsearch
  elevenlabs?: ElevenlabsMCP
  everart?: EverArtArchived
  exa?: Exa
  explorium?: ExploriumB2BData
  fetch?: FetchReference
  fibery?: Fibery
  filesystem?: FilesystemReference
  findADomain?: FindADomain
  firecrawl?: Firecrawl
  firewalla?: FirewallaMCPServer
  flexprice?: FlexPrice
  git?: GitReference
  github?: GitHubArchived
  githubChat?: GitHubChat
  githubOfficial?: GitHubOfficial
  gitlab?: GitLabArchived
  gitmcp?: GitMCP
  glif?: GlifApp
  gmail?: GmailMCPServer
  googleMaps?: GoogleMapsArchived
  googleMapsComprehensive?: GoogleMapsComprehensiveMCP
  grafana?: Grafana
  gyazo?: Gyazo
  hackernews?: HackernewsMcp
  hackle?: Hackle
  handwritingOcr?: HandwritingOCR
  hdx?: HumanitarianDataExchangeMCPServer
  heroku?: Heroku
  hostinger?: HostingerAPIMCPServer
  hoverfly?: HoverflyMCPServer
  hubspot?: HubSpot
  huggingFace?: HuggingFace
  hummingbot?: HummingbotMCPTradingAgent
  husqvarnaAutomower?: HusqvarnaAutomower
  hyperbrowser?: Hyperbrowser
  hyperspell?: Hyperspell
  iaptic?: Iaptic
  inspektorGadget?: InspektorGadget
  javadocs?: Javadocs
  jetbrains?: JetBrains
  kafkaSchemaReg?: KafkaSchemaRegistryMCP
  kagisearch?: KagiSearch
  keboola?: KeboolaMCPServer
  kong?: KongKonnect
  kubectl?: KubectlMCPServer
  kubernetes?: Kubernetes
  lara?: LaraTranslate
  line?: LINE
  linkedin?: LinkedInMCPServer
  llmtxt?: LLMText
  maestro?: MaestroMCPServer
  manifold?: Manifold
  mapbox?: MapboxMCPServer
  mapboxDevkit?: MapboxDeveloperMCPServer
  markdownify?: Markdownify
  markitdown?: Markitdown
  mavenTools?: MavenToolsMCPServer
  memory?: MemoryReference
  mercadoLibre?: MercadoLibre
  mercadoPago?: MercadoPago
  metabase?: MetabaseMCP
  minecraftWiki?: MinecraftWiki
  mongodb?: MongoDB
  multiversxMx?: MultiversX
  nasdaqDataLink?: NasdaqDataLink
  needle?: Needle
  neo4jCloudAuraApi?: Neo4JCloudAuraApi
  neo4jCypher?: Neo4JCypher
  neo4jDataModeling?: Neo4JDataModeling
  neo4jMemory?: Neo4JMemory
  neon?: Neon
  nodeCodeSandbox?: NodeJsSandbox
  notion?: Notion
  novita?: Novita
  npmSentinel?: NPMSentinel
  obsidian?: Obsidian
  oktaMcpFctr?: OktaMCPServer
  omi?: OmiMcp
  onlyofficeDocspace?: ONLYOFFICEDocSpace
  openapi?: OpenAPIToolkitForMCP
  openapiSchema?: OpenAPISchema
  openbnbAirbnb?: AirbnbSearch
  openmesh?: OpenMesh
  openweather?: Openweather
  openzeppelinCairo?: OpenZeppelinCairoContracts
  openzeppelinSolidity?: OpenZeppelinSolidityContracts
  openzeppelinStellar?: OpenZeppelinStellarContracts
  openzeppelinStylus?: OpenZeppelinStylusContracts
  opik?: Opik
  opine?: OpineMCPServer
  oracle?: OracleDatabaseMCPServer
  ospMarketingTools?: OSPMarketingTools
  oxylabs?: Oxylabs
  paperSearch?: PaperSearch
  perplexityAsk?: Perplexity
  pia?: ProgramIntegrityAlliance
  pinecone?: PineconeAssistant
  playwright?: ExecuteAutomationPlaywrightMCP
  pluggedinMcpProxy?: PluggedInMCPProxy
  polarSignals?: PolarSignals
  pomodash?: PomoDash
  postgres?: PostgreSQLReadonlyArchived
  postman?: PostmanMCPServer
  prefEditor?: PrefEditor
  prometheus?: Prometheus
  puppeteer?: PuppeteerArchived
  pythonRefactoring?: PythonRefactoringAssistant
  quantconnect?: QuantConnectMCPServer
  ramparts?: RampartsMCPSecurityScanner
  razorpay?: Razorpay
  reddit?: McpReddit
  redis?: Redis
  redisCloud?: RedisCloud
  ref?: RefUpToDateDocs
  remote?: RemoteMCP
  render?: Render
  resend?: SendEmails
  risken?: RISKEN
  root?: RootIoVulnerabilityRemediationMCP
  ros2?: WiseVisionROS2MCPServer
  rube?: Rube
  rustMcpFilesystem?: BlazingFastAsynchronousMCPServerForSeamlessFilesystemOperations
  schemacrawlerAi?: SchemaCrawlerAI
  schoginiMcpImageBorder?: SchoginiMCPImageBorder
  scrapegraph?: ScrapeGraph
  scrapezy?: Scrapezy
  securenoteLink?: SecurenoteLinkMcpServer
  semgrep?: Semgrep
  sentry?: SentryArchived
  sequa?: SequaAI
  sequentialthinking?: SequentialThinkingReference
  shortIo?: ShortIo
  simplechecklist?: SimpleCheckListMCPServer
  singlestore?: Singlestore
  slack?: SlackArchived
  smartbear?: SmartBearMCPServer
  sonarqube?: SonarQube
  sqlite?: SQLiteArchived
  stackgen?: StackGen
  stackhawk?: StackHawk
  stripe?: Stripe
  supadata?: Supadata
  suzieq?: SuzieqMCP
  taskOrchestrator?: TaskOrchestrator
  tavily?: Tavily
  teamwork?: Teamwork
  telnyx?: Telnyx
  tembo?: Tembo
  terraform?: HashicorpTerraform
  textToGraphql?: TextToGraphQL
  tigris?: TigrisData
  time?: TimeReference
  triplewhale?: Triplewhale
  unrealEngine?: UnrealEngineMCPServer
  veyrax?: VeyraX
  vizro?: Vizro
  vulnNist?: VulnNistMcpServer
  wayfound?: WayfoundMCP
  webflow?: Webflow
  wikipedia?: Wikipedia
  wolframAlpha?: WolframAlpha
  youtubeTranscript?: YouTubeTranscripts
  zerodhaKite?: ZerodhaKiteConnect
}
/**
 * Provides AI assistants with direct access to Airtable bases, allowing them to read schemas, query records, and interact with your Airtable data. Supports listing bases, retrieving table structures, and searching through records to help automate workflows and answer questions about your organized data.
 */
interface AirtableMCPServer {
  airtableApiKey: string
  nodeenv: string
}
/**
 * Azure Kubernetes Service (AKS) official MCP server.
 */
interface AzureKubernetesServiceAKS {
  /**
   * Access level for the MCP server, One of [ readonly, readwrite, admin ]
   */
  accessLevel: string
  /**
   * Comma-separated list of additional tools, One of [ helm, cilium ]
   */
  additionalTools?: string
  /**
   * Comma-separated list of namespaces to allow access to. If not specified, all namespaces are allowed.
   */
  allowNamespaces?: string
  /**
   * Path to the Azure configuration directory (e.g. /home/azureuser/.azure). Used for Azure CLI authentication, you should be logged in (e.g. run `az login`) on the host before starting the MCP server.
   */
  azureDir: string
  /**
   * Username or UID of the container user (format <name|uid>[:<group|gid>] e.g. 10000), ensuring correct permissions to access the Azure and kubeconfig files. Leave empty to use default user in the container.
   */
  containerUser?: string
  /**
   * Path to the kubeconfig file for the AKS cluster (e.g. /home/azureuser/.kube/config). Used to connect to the AKS cluster.
   */
  kubeconfig: string
}
/**
 * A universal MCP (Model Context Protocol) server to integrate any API with Claude Desktop using only Docker configurations.
 */
interface ApiGateway {
  api1HeaderAuthorization: string
  api1Name: string
  api1SwaggerUrl: string
}
/**
 * Apify is the world's largest marketplace of tools for web scraping, data extraction, and web automation. You can extract structured data from social media, e-commerce, search engines, maps, travel sites, or any other website.
 */
interface ApifyMCPServer {
  apifyToken: string
  /**
   * Comma-separated list of tools to enable. Can be either a tool category, a specific tool, or an Apify Actor. For example: "actors,docs,apify/rag-web-browser". For more details visit https://mcp.apify.com.
   */
  tools: string
}
/**
 * The ArXiv MCP Server provides a comprehensive bridge between AI assistants and arXiv's research repository through the Model Context Protocol (MCP).   Features:  Search arXiv papers with advanced filtering  Download and store papers locally as markdown  Read and analyze paper content  Deep research analysis prompts  Local paper management and storage  Enhanced tool descriptions optimized for local AI models  Docker MCP Gateway compatible with detailed context  Perfect for researchers, academics, and AI assistants conducting literature reviews and research analysis.  **Recent Update**: Enhanced tool descriptions specifically designed to resolve local AI model confusion and improve Docker MCP Gateway compatibility.
 */
interface ArXivMCPServer {
  /**
   * Directory path where downloaded papers will be stored
   */
  storagePath: string
}
/**
 * ast-grep is a fast and polyglot tool for code structural search, lint, rewriting at large scale.
 */
interface AstGrep {
  path: string
}
/**
 * An MCP server for Astra DB workloads.
 */
interface AstraDB {
  astraDbApplicationToken: string
  endpoint: string
}
/**
 * Access the latest Astro web framework documentation, guides, and API references.
 */
interface AstroDocs {}
/**
 * MCP server for interacting with Atlan services including asset search, updates, and lineage traversal for comprehensive data governance and discovery.
 */
interface AtlanMCPServer {
  apiKey: string
  baseUrl: string
}
/**
 * Provide LLMs hosted, clean markdown documentation of libraries and frameworks.
 */
interface AtlasDocs {
  apiUrl: string
}
/**
 * Tools for Atlassian products (Confluence and Jira). This integration supports both Atlassian Cloud and Jira Server/Data Center deployments.
 */
interface Atlassian {
  confluenceApiToken?: string
  confluencePersonalToken?: string
  confluenceUrl: string
  confluenceUsername?: string
  jiraApiToken?: string
  jiraPersonalToken?: string
  jiraUrl: string
  jiraUsername?: string
}
/**
 * Audiense Insights MCP Server is a server based on the Model Context Protocol (MCP) that allows Claude and other MCP-compatible clients to interact with your Audiense Insights account.
 */
interface AudienseInsights {
  audienseClientSecret?: string
  clientId: string
  twitterBearerToken?: string
}
/**
 * AWS Cloud Development Kit (CDK) best practices, infrastructure as code patterns, and security compliance with CDK Nag.
 */
interface AWSCDK {}
/**
 * Starting point for using the awslabs MCP servers.
 */
interface AWSCoreMCPServer {}
/**
 * Seamlessly create diagrams using the Python diagrams package DSL. This server allows you to generate AWS diagrams, sequence diagrams, flow diagrams, and class diagrams using Python code.
 */
interface AWSDiagram {}
/**
 * Tools to access AWS documentation, search for content, and get recommendations.
 */
interface AWSDocumentation {}
/**
 * An MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.
 */
interface AWSKBRetrievalArchived {
  accessKeyId: string
  awsSecretAccessKey?: string
}
/**
 * Terraform on AWS best practices, infrastructure as code patterns, and security compliance with Checkov.
 */
interface AWSTerraform {}
/**
 * The Azure MCP Server, bringing the power of Azure to your agents.
 */
interface Azure {}
/**
 * Connects with the Beagle Security backend using a user token to manage applications, run automated security tests, track vulnerabilities across environments, and gain intelligence from Application and API vulnerability data.
 */
interface BeagleSecurityMCPServer {
  beagleSecurityApiToken: string
}
/**
 * A Model Context Protocol Server connector for Bitrefill public API, to enable AI agents to search and shop on Bitrefill.
 */
interface Bitrefill {
  apiId: string
  apiSecret?: string
}
/**
 * An MCP server capable of interacting with the Box API.
 */
interface Box {
  clientId: string
  clientSecret?: string
}
/**
 * Search the Web for pages, images, news, videos, and more using the Brave Search API.
 */
interface BraveSearch {
  apiKey: string
}
/**
 * Allow LLMs to control a browser with Browserbase and Stagehand for AI-powered web automation, intelligent data extraction, and screenshot capture.
 */
interface Browserbase {
  apiKey: string
  geminiApiKey: string
  projectId: string
}
/**
 * Buildkite MCP lets agents interact with Buildkite Builds, Jobs, Logs, Packages and Test Suites.
 */
interface Buildkite {
  apiToken: string
}
/**
 * Tools to interact with the Camunda 7 Community Edition Engine using the Model Context Protocol (MCP). Whether you're automating workflows, querying process instances, or integrating with external systems, Camunda MCP Server is your agentic solution for seamless interaction with Camunda.
 */
interface CamundaBPMProcessEngineMCPServer {
  camundahost: string
}
/**
 * This fully functional MCP Server allows you to connect to any data source in Connect Cloud from Claude Desktop.
 */
interface CDataConnectCloud {
  cdataPat?: string
  username: string
}
/**
 * An MCP server for CharmHealth EHR that allows LLMs and MCP clients to interact with patient records, encounters, and practice information.
 */
interface CharmHealthMCPServer {
  charmhealthApiKey: string
  charmhealthBaseUrl: string
  charmhealthClientId: string
  charmhealthClientSecret: string
  charmhealthRedirectUri: string
  charmhealthRefreshToken: string
  charmhealthTokenUrl: string
}
/**
 * A Model Context Protocol (MCP) server implementation that provides database capabilities for Chroma.
 */
interface Chroma {
  apiKey: string
}
/**
 * A specialized server implementation for the Model Context Protocol (MCP) designed to integrate with CircleCI's development workflow. This project serves as a bridge between CircleCI's infrastructure and the Model Context Protocol, enabling enhanced AI-powered development experiences.
 */
interface CircleCI {
  token: string
  url: string
}
/**
 * Official ClickHouse MCP Server.
 */
interface OfficialClickHouseMCPServer {
  connectTimeout: string
  host: string
  password: string
  port: string
  secure: string
  sendReceiveTimeout: string
  user: string
  verify: string
}
/**
 * Streamline sales processes with integrated calling, email, SMS, and automated workflows for small and scaling businesses.
 */
interface Close {
  apiKey: string
}
/**
 * MCP server to deploy apps to Cloud Run.
 */
interface CloudRunMCP {
  /**
   * path to application-default credentials (eg $HOME/.config/gcloud/application_default_credentials.json )
   */
  credentialsPath: string
}
/**
 * Access the latest documentation on Cloudflare products such as Workers, Pages, R2, D1, KV.
 */
interface CloudflareDocs {}
/**
 * Enable AI agents to manage, monitor, and query CockroachDB using natural language. Perform complex database operations, cluster management, and query execution seamlessly through AI-driven workflows. Integrate effortlessly with MCP clients for scalable and high-performance data operations.
 */
interface CockroachDB {
  caPath: string
  crdbPwd: string
  database: string
  host: string
  port: number
  sslCertfile: string
  sslKeyfile: string
  sslMode: string
  username: string
}
/**
 * A Python-based execution tool that mimics a Jupyter notebook environment. It accepts code snippets, executes them, and maintains state across sessions  preserving variables, imports, and past results. Ideal for iterative development, debugging, or code execution.
 */
interface PythonInterpreter {}
/**
 * Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors.
 */
interface Context7 {}
/**
 * Couchbase is a distributed document database with a powerful search engine and in-built operational and analytical capabilities.
 */
interface Couchbase {
  /**
   * Bucket in the Couchbase cluster to use for the MCP server.
   */
  cbBucketName: string
  /**
   * Connection string for the Couchbase cluster.
   */
  cbConnectionString: string
  /**
   * Setting to "true" (default) enables read-only query mode while running SQL++ queries.
   */
  cbMcpReadOnlyQueryMode: string
  cbPassword: string
  /**
   * Username for the Couchbase cluster with access to the bucket.
   */
  cbUsername: string
}
/**
 * Brings context about device inventory, threats, risks and utilization powered by the Cylera Partner API into an LLM.
 */
interface TheOfficialMCPServerForCylera {
  cyleraBaseUrl: string
  cyleraPassword: string
  cyleraUsername: string
}
/**
 * A Model Context Protocol server that provides access to Shodan API functionality.
 */
interface Shodan {
  shodanApiKey: string
}
/**
 * Enable fast, free real-time web search and access premium data from trusted media brandsnews, financial markets, sports, entertainment, weather, and more. Build powerful AI agents with Dappier.
 */
interface Dappier {
  apiKey: string
}
/**
 * Enable fast, free real-time web search and access premium data from trusted media brandsnews, financial markets, sports, entertainment, weather, and more. Build powerful AI agents with Dappier.
 */
interface DappierRemoteMCPServer {
  dappierRemoteApiKey: string
}
/**
 * Dart AI Model Context Protocol (MCP) server.
 */
interface DartAI {
  host: string
  token: string
}
/**
 * Comprehensive database server supporting PostgreSQL, MySQL, and SQLite with natural language SQL query capabilities. Enables AI agents to interact with databases through both direct SQL and natural language queries.
 */
interface MCPDatabaseServer {
  /**
   * Connection string for your database. Examples: SQLite: sqlite+aiosqlite:///data/mydb.db, PostgreSQL: postgresql+asyncpg://user:password@localhost:5432/mydb, MySQL: mysql+aiomysql://user:password@localhost:3306/mydb
   */
  databaseUrl: string
}
/**
 * Databutton MCP Server.
 */
interface Databutton {}
/**
 * Tools for fetching and asking questions about GitHub repositories.
 */
interface DeepWiki {}
/**
 * The Descope Model Context Protocol (MCP) server provides an interface to interact with Descope's Management APIs, enabling the search and retrieval of project-related information.
 */
interface Descope {
  managementKey?: string
  projectId: string
}
/**
 * Search, update, manage files and run terminal commands with AI.
 */
interface DesktopCommander {
  /**
   * List of directories that Desktop Commander can access
   */
  paths: string[]
}
/**
 * DevHub CMS LLM integration through the Model Context Protocol.
 */
interface DevHubCMS {
  devhubApiKey?: string
  devhubApiSecret?: string
  url: string
}
/**
 * Interact with the Discord platform.
 */
interface Discord {
  discordToken: string
}
/**
 * Docker Hub official MCP server.
 */
interface DockerHub {
  hubPatToken: string
  username: string
}
/**
 * Tools for cross-border payments, taxes, and compliance.
 */
interface DodoPayments {
  dodoPaymentsApiKey: string
}
/**
 * DreamFactory is a REST API generation platform with support for hundreds of data sources, including Microsoft SQL Server, MySQL, PostgreSQL, and MongoDB. The DreamFactory MCP Server makes it easy for users to securely interact with their data sources via an MCP client.
 */
interface DreamFactoryMCPServer {
  dreamfactoryapikey: string
  dreamfactoryurl: string
}
/**
 * A Model Context Protocol (MCP) server that provides web search capabilities through DuckDuckGo, with additional features for content fetching and parsing.
 */
interface DuckDuckGo {}
/**
 * This MCP Server allows interaction with the Dynatrace observability platform, brining real-time observability data directly into your development workflow.
 */
interface DynatraceMCPServer {
  oauthClientId: string
  oauthClientSecret: string
  url: string
}
/**
 * Giving Claude ability to run code with E2B via MCP (Model Context Protocol).
 */
interface E2B {
  apiKey: string
}
/**
 * The EduBase MCP server enables Claude and other LLMs to interact with EduBase's comprehensive e-learning platform through the Model Context Protocol (MCP).
 */
interface EduBase {
  apiKey?: string
  app: string
  url: string
}
/**
 * Tools and resources for writing Effect code in Typescript.
 */
interface EffectMCP {}
/**
 * Interact with your Elasticsearch indices through natural language conversations.
 */
interface Elasticsearch {
  esApiKey?: string
  url: string
}
/**
 * Official ElevenLabs Model Context Protocol (MCP) server that enables interaction with powerful Text to Speech and audio processing APIs.
 */
interface ElevenlabsMCP {
  apiKey?: string
  data: string
}
/**
 * Image generation server using EverArt's API.
 */
interface EverArtArchived {
  apiKey: string
}
/**
 * Exa MCP for web search and web crawling!.
 */
interface Exa {
  apiKey: string
}
/**
 * Discover companies, contacts, and business insightspowered by dozens of trusted external data sources.
 */
interface ExploriumB2BData {
  apiAccessToken: string
}
/**
 * Fetches a URL from the internet and extracts its contents as markdown.
 */
interface FetchReference {}
/**
 * Interact with your Fibery workspace.
 */
interface Fibery {
  apiToken: string
  host: string
}
/**
 * Local filesystem access with configurable allowed paths.
 */
interface FilesystemReference {
  paths: string[]
}
/**
 * Tools for finding domain names.
 */
interface FindADomain {}
/**
 *  Official Firecrawl MCP Server - Adds powerful web scraping and search to Cursor, Claude and any other LLM clients.
 */
interface Firecrawl {
  apiKey: string
  creditCriticalThreshold: number
  creditWarningThreshold: number
  retryBackoffFactor: number
  retryDelay: number
  retryMax: number
  retryMaxDelay: number
  url: string
}
/**
 * Real-time network monitoring, security analysis, and firewall management through 28 specialized tools. Access security alerts, network flows, device status, and firewall rules directly from your Firewalla device.
 */
interface FirewallaMCPServer {
  /**
   * Your Firewalla Box Global ID
   */
  boxId: string
  firewallaMspToken: string
  /**
   * Your Firewalla MSP domain (e.g., yourdomain.firewalla.net)
   */
  mspId: string
}
/**
 * Official flexprice MCP Server.
 */
interface FlexPrice {
  apiKey: string
  baseUrl: string
}
/**
 * Git repository interaction and automation.
 */
interface GitReference {
  paths: string[]
}
/**
 * Tools for interacting with the GitHub API, enabling file operations, repository management, search functionality, and more.
 */
interface GitHubArchived {
  personalAccessToken: string
}
/**
 * A Model Context Protocol (MCP) for analyzing and querying GitHub repositories using the GitHub Chat API.
 */
interface GitHubChat {
  githubApiKey: string
}
/**
 * Official GitHub MCP Server, by GitHub. Provides seamless integration with GitHub APIs, enabling advanced automation and interaction capabilities for developers and tools.
 */
interface GitHubOfficial {
  githubPersonalAccessToken: string
}
/**
 * MCP Server for the GitLab API, enabling project management, file operations, and more.
 */
interface GitLabArchived {
  personalAccessToken: string
  /**
   * api url - optional for self-hosted instances
   */
  url: string
}
/**
 * Tools for interacting with Git repositories.
 */
interface GitMCP {}
/**
 * Easily run glif.app AI workflows inside your LLM: image generators, memes, selfies, and more. Glif supports all major multimedia AI models inside one app.
 */
interface GlifApp {
  apiToken: string
  ids: string
  ignoredSaved: boolean
}
/**
 * A Model Context Protocol server for Gmail operations using IMAP/SMTP with app password authentication. Supports listing messages, searching emails, and sending messages. To create your app password, visit your Google Account settings under Security > App Passwords. Or visit the link https://myaccount.google.com/apppasswords.
 */
interface GmailMCPServer {
  /**
   * Your Gmail email address
   */
  emailAddress: string
  emailPassword?: string
}
/**
 * Tools for interacting with the Google Maps API.
 */
interface GoogleMapsArchived {
  googleMapsApiKey: string
}
/**
 * Complete Google Maps integration with 8 tools including geocoding, places search, directions, elevation data, and more using Google's latest APIs.
 */
interface GoogleMapsComprehensiveMCP {
  googleMapsApiKey: string
}
/**
 * MCP server for Grafana.
 */
interface Grafana {
  apiKey: string
  url: string
}
/**
 * Official Model Context Protocol server for Gyazo.
 */
interface Gyazo {
  accessToken: string
}
/**
 * A Model Context Protocol (MCP) server that provides access to Hacker News stories, comments, and user data, with support for search and content retrieval.
 */
interface HackernewsMcp {}
/**
 * Model Context Protocol server for Hackle.
 */
interface Hackle {
  apiKey: string
}
/**
 * Model Context Protocol (MCP) Server for Handwriting OCR.
 */
interface HandwritingOCR {
  apiToken: string
}
/**
 * HDX MCP Server provides access to humanitarian data through the Humanitarian Data Exchange (HDX) API - https://data.humdata.org/hapi. This server offers 33 specialized tools for retrieving humanitarian information including affected populations (refugees, IDPs, returnees), baseline demographics, food security indicators, conflict data, funding information, and operational presence across hundreds of countries and territories. See repository for instructions on getting a free HDX_APP_INDENTIFIER for access.
 */
interface HumanitarianDataExchangeMCPServer {
  appIdentifier: string
}
/**
 * Heroku Platform MCP Server using the Heroku CLI.
 */
interface Heroku {
  apiKey: string
}
/**
 * Interact with Hostinger services over the Hostinger API.
 */
interface HostingerAPIMCPServer {
  apitoken: string
}
/**
 * A Model Context Protocol (MCP) server that exposes Hoverfly as a programmable tool for AI assistants like Cursor, Claude, GitHub Copilot, and others supporting MCP. It enables dynamic mocking of third-party APIs to unblock development, automate testing, and simulate unavailable services during integration.
 */
interface HoverflyMCPServer {
  data: string
}
/**
 * Unite marketing, sales, and customer service with AI-powered automation, lead management, and comprehensive analytics.
 */
interface HubSpot {
  apiKey: string
}
/**
 * Tools for interacting with Hugging Face models, datasets, research papers, and more.
 */
interface HuggingFace {}
/**
 * Hummingbot MCP is an open-source toolset that lets you control and monitor your Hummingbot trading bots through AI-powered commands and automation.
 */
interface HummingbotMCPTradingAgent {
  apiUrl: string
  hummingbotApiPassword?: string
  hummingbotApiUsername?: string
}
/**
 * MCP Server for huqsvarna automower.
 */
interface HusqvarnaAutomower {
  clientId: string
  husqvarnaClientSecret: string
}
/**
 * A MCP server implementation for hyperbrowser.
 */
interface Hyperbrowser {
  apiKey: string
}
/**
 * Hyperspell MCP Server.
 */
interface Hyperspell {
  collection: string
  token: string
  useResources: boolean
}
/**
 * Model Context Protocol server for interacting with iaptic.
 */
interface Iaptic {
  apiKey?: string
  appName: string
}
/**
 * AI interface to troubleshoot and observe Kubernetes/Container workloads.
 */
interface InspektorGadget {
  /**
   * Comma-separated list of gadget images (trace_dns, trace_tcp, etc) to use, allowing control over which gadgets are available as MCP tools
   */
  gadgetImages?: string
  /**
   * Path to the kubeconfig file for accessing Kubernetes clusters
   */
  kubeconfig: string
}
/**
 * Access to Java, Kotlin, and Scala library documentation.
 */
interface Javadocs {}
/**
 * A model context protocol server to work with JetBrains IDEs: IntelliJ, PyCharm, WebStorm, etc. Also, works with Android Studio.
 */
interface JetBrains {
  port: number
}
/**
 * Comprehensive MCP server for Kafka Schema Registry operations. Features multi-registry support, schema contexts, migration tools, OAuth authentication, and 57+ tools for complete schema management. Supports SLIM_MODE for optimal performance.
 */
interface KafkaSchemaRegistryMCP {
  /**
   * Schema Registry URL
   */
  registryUrl: string
  schemaRegistryPassword?: string
  schemaRegistryUser?: string
  /**
   * Enable SLIM_MODE for better performance
   */
  slimMode?: string
  /**
   * Enable read-only mode
   */
  viewonly?: string
}
/**
 * The Official Model Context Protocol (MCP) server for Kagi search & other tools.
 */
interface KagiSearch {
  engine: string
  kagiApiKey: string
}
/**
 * Keboola MCP Server is an open-source bridge between your Keboola project and modern AI tools.
 */
interface KeboolaMCPServer {
  kbcStorageToken: string
  kbcWorkspaceSchema: string
}
/**
 * A Model Context Protocol (MCP) server for interacting with Kong Konnect APIs, allowing AI assistants to query and analyze Kong Gateway configurations, traffic, and analytics.
 */
interface KongKonnect {
  konnectAccessToken: string
  region: string
}
/**
 * MCP Server that enables AI assistants to interact with Kubernetes clusters via kubectl operations.
 */
interface KubectlMCPServer {
  kubeconfig: string
}
/**
 * Connect to a Kubernetes cluster and manage it.
 */
interface Kubernetes {
  /**
   * the path to the host .kube/config
   */
  configPath: string
}
/**
 * Connect to Lara Translate API, enabling powerful translation capabilities with support for language detection and context-aware translations.
 */
interface LaraTranslate {
  accessKeySecret?: string
  keyId: string
}
/**
 * MCP server that integrates the LINE Messaging API to connect an AI Agent to the LINE Official Account.
 */
interface LINE {
  channelAccessToken?: string
  userId: string
}
/**
 * This MCP server allows Claude and other AI assistants to access your LinkedIn. Scrape LinkedIn profiles and companies, get your recommended jobs, and perform job searches. Set your li_at LinkedIn cookie to use this server.
 */
interface LinkedInMCPServer {
  linkedinCookie: string
  /**
   * Custom user agent string (optional, helps avoid detection and cookie login issues)
   */
  userAgent: string
}
/**
 * Discovers and retrieves llms.txt from websites.
 */
interface LLMText {}
/**
 * A Model Context Protocol (MCP) server exposing Bitcoin blockchain data through the Maestro API platform. Provides tools to explore blocks, transactions, addresses, inscriptions, runes, and other metaprotocol data.
 */
interface MaestroMCPServer {
  apiKeyApiKey: string
}
/**
 * Tools for accessing the Manifold Markets online prediction market platform.
 */
interface Manifold {}
/**
 * Transform any AI agent into a geospatially-aware system with Mapbox APIs. Provides geocoding, POI search, routing, travel time matrices, isochrones, and static map generation.
 */
interface MapboxMCPServer {
  accessToken: string
}
/**
 * Direct access to Mapbox developer APIs for AI assistants. Enables style management, token management, GeoJSON preview, and other developer tools for building Mapbox applications.
 */
interface MapboxDeveloperMCPServer {
  mapboxAccessToken: string
}
/**
 * A Model Context Protocol server for converting almost anything to Markdown.
 */
interface Markdownify {
  paths: string[]
}
/**
 * A lightweight MCP server for calling MarkItDown.
 */
interface Markitdown {
  paths: string[]
}
/**
 * JVM dependency intelligence for any build tool using Maven Central Repository. Includes Context7 integration for upgrade documentation and guidance.
 */
interface MavenToolsMCPServer {}
/**
 * Knowledge graph-based persistent memory system.
 */
interface MemoryReference {}
/**
 * Provides access to Mercado Libre E-Commerce API.
 */
interface MercadoLibre {
  mercadoLibreApiKey: string
}
/**
 * Provides access to Mercado Pago Marketplace API.
 */
interface MercadoPago {
  mercadoPagoApiKey: string
}
/**
 * A comprehensive MCP server for Metabase with 70+ tools.
 */
interface MetabaseMCP {
  apiKey: string
  metabaseurl: string
  metabaseusername: string
  password: string
}
/**
 * A MCP Server for browsing the official Minecraft Wiki!.
 */
interface MinecraftWiki {}
/**
 * A Model Context Protocol server to connect to MongoDB databases and MongoDB Atlas Clusters.
 */
interface MongoDB {
  mdbMcpConnectionString: string
}
/**
 * MCP Server for MultiversX.
 */
interface MultiversX {
  network: string
  wallet: string
}
/**
 * MCP server to interact with the data feeds provided by the Nasdaq Data Link. Developed by the community and maintained by Stefano Amorelli.
 */
interface NasdaqDataLink {
  nasdaqDataLinkApiKey: string
}
/**
 * Production-ready RAG service to search and retrieve data from your documents.
 */
interface Needle {
  needleApiKey: string
}
/**
 * Manage Neo4j Aura database instances through the Neo4j Aura API.
 */
interface Neo4JCloudAuraApi {
  clientId: string
  neo4jAuraClientSecret?: string
  serverAllowOrigins?: string
  serverAllowedHosts?: string
  serverHost?: string
  serverPath?: string
  serverPort?: string
  transport?: string
}
/**
 * Interact with Neo4j using Cypher graph queries.
 */
interface Neo4JCypher {
  database?: string
  namespace?: string
  neo4jPassword?: string
  readOnly?: boolean
  readTimeout?: string
  responseTokenLimit?: string
  serverAllowOrigins?: string
  serverAllowedHosts?: string
  serverHost?: string
  serverPath?: string
  serverPort?: string
  transport?: string
  url: string
  username: string
}
/**
 * MCP server that assists in creating, validating and visualizing graph data models.
 */
interface Neo4JDataModeling {
  serverAllowOrigins: string
  serverAllowedHosts: string
  serverHost: string
  serverPath: string
  serverPort: string
  transport: string
}
/**
 * Provide persistent memory capabilities through Neo4j graph database integration.
 */
interface Neo4JMemory {
  database?: string
  neo4jPassword?: string
  serverAllowOrigins?: string
  serverAllowedHosts?: string
  serverHost?: string
  serverPath?: string
  serverPort?: string
  transport?: string
  url: string
  username: string
}
/**
 * MCP server for interacting with Neon Management API and databases.
 */
interface Neon {
  apiKey: string
}
/**
 * A Node.jsbased Model Context Protocol server that spins up disposable Docker containers to execute arbitrary JavaScript.
 */
interface NodeJsSandbox {}
/**
 * Official Notion MCP Server.
 */
interface Notion {
  internalIntegrationToken: string
}
/**
 * Seamless interaction with Novita AI platform resources.
 */
interface Novita {}
/**
 * MCP server that enables intelligent NPM package analysis powered by AI.
 */
interface NPMSentinel {}
/**
 * MCP server that interacts with Obsidian via the Obsidian rest API community plugin.
 */
interface Obsidian {
  apiKey: string
}
/**
 * Secure Okta identity and access management via Model Context Protocol (MCP). Access Okta users, groups, applications, logs, and policies through AI assistants with enterprise-grade security.
 */
interface OktaMCPServer {
  /**
   * Okta organization URL (e.g., https://dev-123456.okta.com)
   */
  clientOrgurl: string
  /**
   * Maximum concurrent requests to Okta API
   */
  concurrentLimit?: string
  /**
   * Logging level for server output
   */
  logLevel?: string
  oktaApiToken?: string
}
/**
 * A Model Context Protocol server for Omi interaction and automation. This server provides tools to read, search, and manipulate Memories and Conversations.
 */
interface OmiMcp {
  apiKey: string
}
/**
 * ONLYOFFICE DocSpace is a room-based collaborative platform which allows organizing a clear file structure depending on users' needs or project goals.
 */
interface ONLYOFFICEDocSpace {
  baseUrl: string
  docspaceApiKey: string
  docspaceAuthToken: string
  docspacePassword: string
  docspaceUsername: string
  dynamic: boolean
  origin: string
  toolsets: string
  userAgent: string
}
/**
 * Fetch, validate, and generate code or curl from any OpenAPI or Swagger spec - all from a single URL.
 */
interface OpenAPIToolkitForMCP {
  mode: string
}
/**
 * OpenAPI Schema Model Context Protocol Server.
 */
interface OpenAPISchema {
  SchemaPath: string
}
/**
 * MCP Server for searching Airbnb and get listing details.
 */
interface AirbnbSearch {}
/**
 * Discover and connect to a curated marketplace of MCP servers for extending AI agent capabilities.
 */
interface OpenMesh {}
/**
 * A simple MCP service that provides current weather and 5-day forecast using the free OpenWeatherMap API.
 */
interface Openweather {
  owmApiKey: string
}
/**
 * Access to OpenZeppelin Cairo Contracts.
 */
interface OpenZeppelinCairoContracts {}
/**
 * Access to OpenZeppelin Solidity Contracts.
 */
interface OpenZeppelinSolidityContracts {}
/**
 * Access to OpenZeppelin Stellar Contracts.
 */
interface OpenZeppelinStellarContracts {}
/**
 * Access to OpenZeppelin Stylus Contracts.
 */
interface OpenZeppelinStylusContracts {}
/**
 * Model Context Protocol (MCP) implementation for Opik enabling seamless IDE integration and unified access to prompts, projects, traces, and metrics.
 */
interface Opik {
  apiBaseUrl: string
  apiKey: string
  workspaceName: string
}
/**
 * A Model Context Protocol (MCP) server for querying deals and evaluations from the Opine CRM API.
 */
interface OpineMCPServer {
  opineApiKey: string
}
/**
 * Connect to Oracle databases via MCP, providing secure read-only access with support for schema exploration, query execution, and metadata inspection.
 */
interface OracleDatabaseMCPServer {
  oracleConnectionString: string
  oracleUser: string
  password: string
}
/**
 * A Model Context Protocol (MCP) server that empowers LLMs to use some of Open Srategy Partners' core writing and product marketing techniques.
 */
interface OSPMarketingTools {}
/**
 * A Model Context Protocol (MCP) server that enables AI assistants like Claude to seamlessly access web data through Oxylabs' powerful web scraping technology.
 */
interface Oxylabs {
  password?: string
  username: string
}
/**
 * A MCP for searching and downloading academic papers from multiple sources like arXiv, PubMed, bioRxiv, etc.
 */
interface PaperSearch {}
/**
 * Connector for Perplexity API, to enable real-time, web-wide research.
 */
interface Perplexity {
  perplexityApiKey: string
}
/**
 * An MCP server to help make U.S. Government open datasets AI-friendly.
 */
interface ProgramIntegrityAlliance {
  apiKey: string
}
/**
 * Pinecone Assistant MCP server.
 */
interface PineconeAssistant {
  apiKey: string
  assistantHost: string
}
/**
 * Playwright Model Context Protocol Server - Tool to automate Browsers and APIs in Claude Desktop, Cline, Cursor IDE and More .
 */
interface ExecuteAutomationPlaywrightMCP {
  data: string
}
/**
 * A unified MCP proxy that aggregates multiple MCP servers into one interface, enabling seamless tool discovery and management across all your AI interactions. Manage all your MCP servers from a single connection point with RAG capabilities and real-time notifications.
 */
interface PluggedInMCPProxy {
  /**
   * Base URL for the Plugged.in API (optional, defaults to https://plugged.in for cloud or http://localhost:12005 for self-hosted)
   */
  pluggedinApiBaseUrl: string
  pluggedinApiKey: string
}
/**
 * MCP server for Polar Signals Cloud continuous profiling platform, enabling AI assistants to analyze CPU performance, memory usage, and identify optimization opportunities in production systems.
 */
interface PolarSignals {
  polarSignalsApiKey: string
}
/**
 * Connect your AI assistant to PomoDash for seamless task and project management.
 */
interface PomoDash {
  apiKey: string
}
/**
 * Connect with read-only access to PostgreSQL databases. This server enables LLMs to inspect database schemas and execute read-only queries.
 */
interface PostgreSQLReadonlyArchived {
  url: string
}
/**
 * Postman's MCP server connects AI agents, assistants, and chatbots directly to your APIs on Postman. Use natural language to prompt AI to automate work across your Postman collections, environments, workspaces, and more.
 */
interface PostmanMCPServer {
  apiKey: string
}
/**
 * Pref Editor is a tool for viewing and editing Android app preferences during development.
 */
interface PrefEditor {}
/**
 * A Model Context Protocol (MCP) server that enables AI assistants to query and analyze Prometheus metrics through standardized interfaces. Connect to your Prometheus instance to retrieve metrics, perform queries, and gain insights into your system's performance and health.
 */
interface Prometheus {
  /**
   * The URL of your Prometheus server
   */
  prometheusUrl: string
}
/**
 * Browser automation and web scraping using Puppeteer.
 */
interface PuppeteerArchived {}
/**
 * Educational Python refactoring assistant that provides guided suggestions for AI assistants.  Features:  Step-by-step refactoring instructions without modifying code  Comprehensive code analysis using professional tools (Rope, Radon, Vulture, Jedi, LibCST, Pyrefly)  Educational approach teaching refactoring patterns through guided practice  Support for both guide-only and apply-changes modes  Identifies long functions, high complexity, dead code, and type issues  Provides precise line numbers and specific refactoring instructions  Compatible with all AI assistants (Claude, GPT, Cursor, Continue, etc.)  Perfect for developers learning refactoring patterns while maintaining full control over code changes. Acts as a refactoring mentor rather than an automated code modifier.
 */
interface PythonRefactoringAssistant {}
/**
 * The QuantConnect MCP Server is a bridge for AIs (such as Claude and OpenAI o3 Pro) to interact with our cloud platform. When equipped with our MCP, the AI can perform tasks on your behalf through our API such as updating projects, writing strategies, backtesting, and deploying strategies to production live-trading.
 */
interface QuantConnectMCPServer {
  agentname: string
  quantconnectapitoken: string
  quantconnectuserid: string
}
/**
 * A comprehensive security scanner for MCP servers with YARA rules and static analysis capabilities.
 */
interface RampartsMCPSecurityScanner {}
/**
 * Razorpay's Official MCP Server.
 */
interface Razorpay {
  keyId: string
  keySecret?: string
}
/**
 * A comprehensive Model Context Protocol (MCP) server for Reddit integration. This server enables AI agents to interact with Reddit programmatically through a standardized interface.
 */
interface McpReddit {
  redditClientId: string
  redditClientSecret: string
  redditPassword: string
  username: string
}
/**
 * Access to Redis database operations.
 */
interface Redis {
  caCerts: string
  caPath: string
  certReqs: string
  clusterMode: boolean
  host: string
  port: number
  pwd: string
  ssl: boolean
  sslCertfile: string
  sslKeyfile: string
  username: string
}
/**
 * MCP Server for Redis Cloud's API, allowing you to manage your Redis Cloud resources using natural language.
 */
interface RedisCloud {
  apiKey: string
  secretKey?: string
}
/**
 * Ref powerful search tool connets your coding tools with documentation context. It includes an up-to-date index of public documentation and it can ingest your private documentation (eg. GitHub repos, PDFs) as well.
 */
interface RefUpToDateDocs {
  apiKey: string
}
/**
 * Tools for finding remote MCP servers.
 */
interface RemoteMCP {}
/**
 * Interact with your Render resources via LLMs.
 */
interface Render {
  apiKey: string
}
/**
 * Send emails directly from Cursor with this email sending MCP server.
 */
interface SendEmails {
  apiKey?: string
  /**
   * comma separated list of reply to email addresses
   */
  replyTo: string
  /**
   * sender email address
   */
  sender: string
}
/**
 * RISKEN's official MCP Server.
 */
interface RISKEN {
  accessToken: string
  url: string
}
/**
 * MCP server that provides container image vulnerability scanning and remediation capabilities through Root.io.
 */
interface RootIoVulnerabilityRemediationMCP {
  apiAccessToken: string
}
/**
 * Python server implementing Model Context Protocol (MCP) for ROS2.
 */
interface WiseVisionROS2MCPServer {}
/**
 * Access to Rube's catalog of remote MCP servers.
 */
interface Rube {
  apiKey: string
}
/**
 * The Rust MCP Filesystem is a high-performance, asynchronous, and lightweight Model Context Protocol (MCP) server built in Rust for secure and efficient filesystem operations. Designed with security in mind, it operates in read-only mode by default and restricts clients from updating allowed directories via MCP Roots unless explicitly enabled, ensuring robust protection against unauthorized access. Leveraging asynchronous I/O, it delivers blazingly fast performance with a minimal resource footprint. Optimized for token efficiency, the Rust MCP Filesystem enables large language models (LLMs) to precisely target searches and edits within specific sections of large files and restrict operations by file size range, making it ideal for efficient file exploration, automation, and system integration.
 */
interface BlazingFastAsynchronousMCPServerForSeamlessFilesystemOperations {
  /**
   * Enable read/write mode. If false, the app operates in read-only mode.
   */
  allowWrite: boolean
  /**
   * List of directories that rust-mcp-filesystem can access.
   */
  allowedDirectories: string[]
  /**
   * Enable dynamic directory access control via MCP client-side Roots.
   */
  enableRoots: boolean
}
/**
 * The SchemaCrawler AI MCP Server enables natural language interaction with your database schema using an MCP client in "Agent" mode. It allows users to explore tables, columns, foreign keys, triggers, stored procedures and more simply by asking questions like "Explain the code for the interest calculation stored procedure". You can also ask it to help with SQL, since it knows your schema. This is ideal for developers, DBAs, and data analysts who want to streamline schema comprehension and query development without diving into dense documentation.
 */
interface SchemaCrawlerAI {
  /**
   * --info-level How much database metadata to retrieve
   */
  generalInfoLevel: string
  generalLogLevel?: string
  schcrwlrDatabasePassword?: string
  schcrwlrDatabaseUser?: string
  /**
   * --database Database to connect to (optional)
   */
  serverConnectionDatabase?: string
  /**
   * --host Database host (optional)
   */
  serverConnectionHost?: string
  /**
   * --port Database port (optional)
   */
  serverConnectionPort?: number
  /**
   * --server SchemaCrawler database plugin
   */
  serverConnectionServer: string
  /**
   * --url JDBC URL for database connection
   */
  urlConnectionJdbcUrl: string
  /**
   * Host volume to map within the Docker container
   */
  volumeHostShare: string
}
/**
 * This adds a border to an image and returns base64 encoded image.
 */
interface SchoginiMCPImageBorder {}
/**
 * ScapeGraph MCP Server.
 */
interface ScrapeGraph {
  sgaiApiKey: string
}
/**
 * A Model Context Protocol server for Scrapezy that enables AI models to extract structured data from websites.
 */
interface Scrapezy {
  apiKey: string
}
/**
 * SecureNote.link MCP Server - allowing AI agents to securely share sensitive information through end-to-end encrypted notes.
 */
interface SecurenoteLinkMcpServer {}
/**
 * MCP server for using Semgrep to scan code for security vulnerabilities.
 */
interface Semgrep {}
/**
 * A Model Context Protocol server for retrieving and analyzing issues from Sentry.io. This server provides tools to inspect error reports, stacktraces, and other debugging information from your Sentry account.
 */
interface SentryArchived {
  authToken: string
}
/**
 * Stop stitching context for Copilot and Cursor. With Sequa MCP, your AI tools know your entire codebase and docs out of the box.
 */
interface SequaAI {
  apiKey: string
  mcpServerUrl: string
}
/**
 * Dynamic and reflective problem-solving through thought sequences.
 */
interface SequentialThinkingReference {}
/**
 * Access to Short.io's link shortener and analytics tools.
 */
interface ShortIo {
  shortIoApiKey: string
}
/**
 * Advanced SimpleCheckList with MCP server and SQLite database for comprehensive task management.  Features:  Complete project and task management system  Hierarchical organization (Projects  Groups  Task Lists  Tasks  Subtasks)  SQLite database for data persistence  RESTful API with comprehensive endpoints  MCP protocol compliance for AI assistant integration  Docker-optimized deployment with stability improvements  **v1.0.1 Update**: Enhanced Docker stability with improved container lifecycle management. Default mode optimized for containerized deployment with reliable startup and shutdown processes.  Perfect for AI assistants managing complex project workflows and task hierarchies.
 */
interface SimpleCheckListMCPServer {}
/**
 * MCP server for interacting with SingleStore Management API and services.
 */
interface Singlestore {
  mcpApiKey: string
}
/**
 * Interact with Slack Workspaces over the Slack API.
 */
interface SlackArchived {
  botToken?: string
  channelIds?: string
  teamId: string
}
/**
 * MCP server for AI access to SmartBear tools, including BugSnag, Reflect, API Hub, PactFlow.
 */
interface SmartBearMCPServer {
  apiHubApiKey: string
  bugsnagApiKey: string
  bugsnagAuthToken: string
  bugsnagEndpoint: string
  pactBrokerBaseUrl: string
  pactBrokerPassword: string
  pactBrokerToken: string
  pactBrokerUsername: string
  reflectApiToken: string
}
/**
 * Interact with SonarQube Cloud, Server and Community build over the web API. Analyze code to identify quality and security issues.
 */
interface SonarQube {
  /**
   * Organization key for SonarQube Cloud, not required for SonarQube Server or Community Build
   */
  org: string
  token: string
  /**
   * URL of the SonarQube instance, to provide only for SonarQube Server or Community Build
   */
  url: string
}
/**
 * Database interaction and business intelligence capabilities.
 */
interface SQLiteArchived {}
/**
 * AI-powered DevOps assistant for managing cloud infrastructure and applications.
 */
interface StackGen {
  token?: string
  /**
   * URL of your StackGen instance
   */
  url: string
}
/**
 * A Model Context Protocol (MCP) server for integrating with StackHawk's security scanning platform. Provides security analytics, YAML configuration management, sensitive data/threat surface analysis, and anti-hallucination tools for LLMs.
 */
interface StackHawk {
  apiKey: string
}
/**
 * Interact with Stripe services over the Stripe API.
 */
interface Stripe {
  secretKey: string
}
/**
 * Official Supadata MCP Server - Adds powerful video & web scraping to Cursor, Claude and any other LLM clients.
 */
interface Supadata {
  apiKey: string
}
/**
 * MCP Server to interact with a SuzieQ network observability instance via its REST API.
 */
interface SuzieqMCP {
  apiEndpoint: string
  apiKey: string
}
/**
 * Model Context Protocol (MCP) server for comprehensive task and feature management, providing AI assistants with a structured, context-efficient way to interact with project data.
 */
interface TaskOrchestrator {}
/**
 * The Tavily MCP server provides seamless interaction with the tavily-search and tavily-extract tools, real-time web search capabilities through the tavily-search tool and Intelligent data extraction from web pages via the tavily-extract tool.
 */
interface Tavily {
  apiKey: string
}
/**
 * Tools for Teamwork.com products.
 */
interface Teamwork {
  twMcpBearerToken: string
}
/**
 * Enables interaction with powerful telephony, messaging, and AI assistant APIs.
 */
interface Telnyx {
  apiKey: string
}
/**
 * MCP server for Tembo Cloud's platform API.
 */
interface Tembo {
  apiKey: string
}
/**
 * The Terraform MCP Server provides seamless integration with Terraform ecosystem, enabling advanced automation and interaction capabilities for Infrastructure as Code (IaC) development.
 */
interface HashicorpTerraform {}
/**
 * Transform natural language queries into GraphQL queries using an AI agent. Provides schema management, query validation, execution, and history tracking.
 */
interface TextToGraphQL {
  graphqlApiKey: string
  /**
   * Authentication method for GraphQL API
   */
  graphqlAuthType: string
  graphqlEndpoint: string
  /**
   * OpenAI model to use
   */
  modelName: string
  /**
   * Model temperature for responses
   */
  modelTemperature: number
  openaiApiKey: string
}
/**
 * Tigris is a globally distributed S3-compatible object storage service that provides low latency anywhere in the world, enabling developers to store and access any amount of data for a wide range of use cases.
 */
interface TigrisData {
  awsAccessKeyId: string
  awsEndpointUrlS3: string
  awsSecretAccessKey?: string
}
/**
 * Time and timezone conversion capabilities.
 */
interface TimeReference {}
/**
 * Triplewhale MCP Server.
 */
interface Triplewhale {
  apiKey: string
}
/**
 * A comprehensive Model Context Protocol (MCP) server that enables AI assistants to control Unreal Engine via Remote Control API. Built with TypeScript and designed for game development automation.
 */
interface UnrealEngineMCPServer {
  /**
   * Logging level
   */
  logLevel?: string
  /**
   * Unreal Engine host address. Use: host.docker.internal for local UE on Windows/Mac Docker, 127.0.0.1 for Linux without Docker, or actual IP address (e.g., 192.168.1.100) for remote UE
   */
  ueHost: string
  /**
   * Remote Control HTTP port
   */
  ueRcHttpPort: string
  /**
   * Remote Control WebSocket port
   */
  ueRcWsPort: string
}
/**
 * VeyraX MCP is the only connection you need to access all your tools in any MCP-compatible environment.
 */
interface VeyraX {
  apiKey: string
}
/**
 * provides tools and templates to create a functioning Vizro chart or dashboard step by step.
 */
interface Vizro {}
/**
 * This MCP server exposes tools to query the NVD/CVE REST API and return formatted text results suitable for LLM consumption via the MCP protocol. It includes automatic query chunking for large date ranges and parallel processing for improved performance.
 */
interface VulnNistMcpServer {}
/**
 * Wayfounds MCP server allows business users to govern, supervise, and improve AI Agents.
 */
interface WayfoundMCP {
  mcpApiKey: string
}
/**
 * Model Context Protocol (MCP) server for the Webflow Data API.
 */
interface Webflow {
  token: string
}
/**
 * A Model Context Protocol (MCP) server that retrieves information from Wikipedia to provide context to LLMs.
 */
interface Wikipedia {}
/**
 * Connect your chat repl to wolfram alpha computational intelligence.
 */
interface WolframAlpha {
  wolframApiKey: string
}
/**
 * Retrieves transcripts for given YouTube video URLs.
 */
interface YouTubeTranscripts {}
/**
 * MCP server for Zerodha Kite Connect API - India's leading stock broker trading platform. Execute trades, manage portfolios, and access real-time market data for NSE, BSE, and other Indian exchanges.
 */
interface ZerodhaKiteConnect {
  /**
   * Access token obtained after OAuth authentication (optional - can be generated at runtime)
   */
  kiteAccessToken?: string
  /**
   * Your Kite Connect API key from the developer console
   */
  kiteApiKey: string
  kiteApiSecret?: string
  /**
   * OAuth redirect URL configured in your Kite Connect app
   */
  kiteRedirectUrl?: string
}

/**
 * Extended MCP server configuration that includes base servers
 * and allows dynamic GitHub-based MCP servers with custom run and install commands.
 */
type McpServer = McpServer$1 | GitHubMcpServer;
type GitHubMcpServer = {
    [key: `github/${string}`]: {
        /**
         * Command to run the MCP server. Must start a stdio-compatible server.
         */
        runCmd: string;
        /**
         * Command to install dependencies for the MCP server. Working directory is the root of the github repository.
         */
        installCmd?: string;
        /**
         * Environment variables to set in the MCP process.
         */
        envs?: Record<string, string>;
    };
};
type SandboxNetworkOpts = {
    /**
     * Allow outbound traffic from the sandbox to the specified addresses.
     * If `allowOut` is not specified, all outbound traffic is allowed.
     *
     * Examples:
     * - To allow traffic to a specific addresses: `["1.1.1.1", "8.8.8.0/24"]`
     */
    allowOut?: string[];
    /**
     * Deny outbound traffic from the sandbox to the specified addresses.
     *
     * Examples:
     * - To deny traffic to a specific addresses: `["1.1.1.1", "8.8.8.0/24"]`
     */
    denyOut?: string[];
    /**
     * Specify if the sandbox URLs should be accessible only with authentication.
     * @default true
     */
    allowPublicTraffic?: boolean;
    /** Specify host mask which will be used for all sandbox requests in the header.
     * You can use the ${PORT} variable that will be replaced with the actual port number of the service.
     *
     * @default ${PORT}-sandboxid.e2b.app
     */
    maskRequestHost?: string;
};
/**
 * Options for request to the Sandbox API.
 */
interface SandboxApiOpts extends Partial<Pick<ConnectionOpts, 'apiKey' | 'headers' | 'debug' | 'domain' | 'requestTimeoutMs'>> {
}
/**
 * Options for creating a new Sandbox.
 */
interface SandboxOpts extends ConnectionOpts {
    /**
     * Custom metadata for the sandbox.
     *
     * @default {}
     */
    metadata?: Record<string, string>;
    /**
     * Custom environment variables for the sandbox.
     *
     * Used when executing commands and code in the sandbox.
     * Can be overridden with the `envs` argument when executing commands or code.
     *
     * @default {}
     */
    envs?: Record<string, string>;
    /**
     * Timeout for the sandbox in **milliseconds**.
     * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
     *
     * @default 300_000 // 5 minutes
     */
    timeoutMs?: number;
    /**
     * Secure all traffic coming to the sandbox controller with auth token
     *
     * @default true
     */
    secure?: boolean;
    /**
     * Allow sandbox to access the internet. If set to `False`, it works the same as setting network `denyOut` to `[0.0.0.0/0]`.
     *
     * @default true
     */
    allowInternetAccess?: boolean;
    /**
     * MCP server to enable in the sandbox
     * @default undefined
     */
    mcp?: McpServer;
    /**
     * Sandbox network configuration
     */
    network?: SandboxNetworkOpts;
    /**
     * Sandbox URL. Used for local development
     */
    sandboxUrl?: string;
}
type SandboxBetaCreateOpts = SandboxOpts & {
    /**
     * Automatically pause the sandbox after the timeout expires.
     * @default false
     */
    autoPause?: boolean;
};
/**
 * Options for connecting to a Sandbox.
 */
type SandboxConnectOpts = ConnectionOpts & {
    /**
     * Timeout for the sandbox in **milliseconds**.
     * For running sandboxes, the timeout will update only if the new timeout is longer than the existing one.
     * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
     *
     * @default 300_000 // 5 minutes
     */
    timeoutMs?: number;
};
/**
 * State of the sandbox.
 */
type SandboxState = 'running' | 'paused';
interface SandboxListOpts extends SandboxApiOpts {
    /**
     * Filter the list of sandboxes, e.g. by metadata `metadata:{"key": "value"}`, if there are multiple filters they are combined with AND.
     *
     */
    query?: {
        metadata?: Record<string, string>;
        /**
         * Filter the list of sandboxes by state.
         * @default ['running', 'paused']
         */
        state?: Array<SandboxState>;
    };
    /**
     * Number of sandboxes to return per page.
     *
     * @default 100
     */
    limit?: number;
    /**
     * Token to the next page.
     */
    nextToken?: string;
}
interface SandboxMetricsOpts extends SandboxApiOpts {
    /**
     * Start time for the metrics, defaults to the start of the sandbox
     */
    start?: Date;
    /**
     * End time for the metrics, defaults to the current time
     */
    end?: Date;
}
/**
 * Information about a sandbox.
 */
interface SandboxInfo {
    /**
     * Sandbox ID.
     */
    sandboxId: string;
    /**
     * Template ID.
     */
    templateId: string;
    /**
     * Template name.
     */
    name?: string;
    /**
     * Saved sandbox metadata.
     */
    metadata: Record<string, string>;
    /**
     * Sandbox start time.
     */
    startedAt: Date;
    /**
     * Sandbox expiration date.
     */
    endAt: Date;
    /**
     * Sandbox state.
     *
     * @string can be `running` or `paused`
     */
    state: SandboxState;
    /**
     * Sandbox CPU count.
     */
    cpuCount: number;
    /**
     * Sandbox Memory size in MiB.
     */
    memoryMB: number;
    /**
     * Envd version.
     */
    envdVersion: string;
}
/**
 * Sandbox resource usage metrics.
 */
interface SandboxMetrics {
    /**
     * Timestamp of the metrics.
     */
    timestamp: Date;
    /**
     * CPU usage in percentage.
     */
    cpuUsedPct: number;
    /**
     * Number of CPU cores.
     */
    cpuCount: number;
    /**
     * Memory usage in bytes.
     */
    memUsed: number;
    /**
     * Total memory available in bytes.
     */
    memTotal: number;
    /**
     * Used disk space in bytes.
     */
    diskUsed: number;
    /**
     * Total disk space available in bytes.
     */
    diskTotal: number;
}
declare class SandboxApi {
    protected constructor();
    /**
     * Kill the sandbox specified by sandbox ID.
     *
     * @param sandboxId sandbox ID.
     * @param opts connection options.
     *
     * @returns `true` if the sandbox was found and killed, `false` otherwise.
     */
    static kill(sandboxId: string, opts?: SandboxApiOpts): Promise<boolean>;
    /**
     * Get sandbox information like sandbox ID, template, metadata, started at/end at date.
     *
     * @param sandboxId sandbox ID.
     * @param opts connection options.
     *
     * @returns sandbox information.
     */
    static getInfo(sandboxId: string, opts?: SandboxApiOpts): Promise<SandboxInfo>;
    /**
     * Get the metrics of the sandbox.
     *
     * @param sandboxId sandbox ID.
     * @param opts sandbox metrics options.
     *
     * @returns  List of sandbox metrics containing CPU, memory and disk usage information.
     */
    static getMetrics(sandboxId: string, opts?: SandboxMetricsOpts): Promise<SandboxMetrics[]>;
    /**
     * Set the timeout of the specified sandbox.
     * After the timeout expires the sandbox will be automatically killed.
     *
     * This method can extend or reduce the sandbox timeout set when creating the sandbox or from the last call to {@link Sandbox.setTimeout}.
     *
     * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
     *
     * @param sandboxId sandbox ID.
     * @param timeoutMs timeout in **milliseconds**.
     * @param opts connection options.
     */
    static setTimeout(sandboxId: string, timeoutMs: number, opts?: SandboxApiOpts): Promise<void>;
    static getFullInfo(sandboxId: string, opts?: SandboxApiOpts): Promise<{
        metadata: {
            [key: string]: string;
        };
        envdVersion: string;
        envdAccessToken: string | undefined;
        startedAt: Date;
        endAt: Date;
        state: "running" | "paused";
        cpuCount: number;
        memoryMB: number;
        sandboxDomain: string | undefined;
        name?: string | undefined;
        sandboxId: string;
        templateId: string;
    }>;
    /**
     * Pause the sandbox specified by sandbox ID.
     *
     * @param sandboxId sandbox ID.
     * @param opts connection options.
     *
     * @returns `true` if the sandbox got paused, `false` if the sandbox was already paused.
     */
    static betaPause(sandboxId: string, opts?: SandboxApiOpts): Promise<boolean>;
    protected static createSandbox(template: string, timeoutMs: number, opts?: SandboxBetaCreateOpts): Promise<{
        sandboxId: string;
        sandboxDomain: string | undefined;
        envdVersion: string;
        envdAccessToken: string | undefined;
        trafficAccessToken: string | undefined;
    }>;
    protected static connectSandbox(sandboxId: string, opts?: SandboxConnectOpts): Promise<{
        sandboxId: string;
        sandboxDomain: string | undefined;
        envdVersion: string;
        envdAccessToken: string | undefined;
        trafficAccessToken: string | undefined;
    }>;
}
/**
 * Paginator for listing sandboxes.
 *
 * @example
 * ```ts
 * const paginator = Sandbox.list()
 *
 * while (paginator.hasNext) {
 *   const sandboxes = await paginator.nextItems()
 *   console.log(sandboxes)
 * }
 * ```
 */
declare class SandboxPaginator {
    private _hasNext;
    private _nextToken?;
    private readonly config;
    private client;
    private query;
    private readonly limit?;
    constructor(opts?: SandboxListOpts);
    /**
     * Returns True if there are more items to fetch.
     */
    get hasNext(): boolean;
    /**
     * Returns the next token to use for pagination.
     */
    get nextToken(): string | undefined;
    /**
     * Get the next page of sandboxes.
     *
     * @throws Error if there are no more items to fetch. Call this method only if `hasNext` is `true`.
     *
     * @returns List of sandboxes
     */
    nextItems(): Promise<SandboxInfo[]>;
}

/**
 * CIDR range that represents all traffic.
 */
declare const ALL_TRAFFIC = "0.0.0.0/0";

interface PtyCreateOpts extends Pick<ConnectionOpts, 'requestTimeoutMs'> {
    /**
     * Number of columns for the PTY.
     */
    cols: number;
    /**
     * Number of rows for the PTY.
     */
    rows: number;
    /**
     * Callback to handle PTY data.
     */
    onData: (data: Uint8Array) => void | Promise<void>;
    /**
     * Timeout for the PTY in **milliseconds**.
     *
     * @default 60_000 // 60 seconds
     */
    timeoutMs?: number;
    /**
     * User to use for the PTY.
     *
     * @default `default Sandbox user (as specified in the template)`
     */
    user?: Username;
    /**
     * Environment variables for the PTY.
     *
     * @default {}
     */
    envs?: Record<string, string>;
    /**
     * Working directory for the PTY.
     *
     * @default // home directory of the user used to start the PTY
     */
    cwd?: string;
}
/**
 * Options for connecting to a command.
 */
type PtyConnectOpts = Pick<PtyCreateOpts, 'onData' | 'timeoutMs'> & Pick<ConnectionOpts, 'requestTimeoutMs'>;
/**
 * Module for interacting with PTYs (pseudo-terminals) in the sandbox.
 */
declare class Pty {
    private readonly transport;
    private readonly connectionConfig;
    private readonly rpc;
    private readonly envdVersion;
    private readonly defaultPtyConnectionTimeout;
    constructor(transport: Transport, connectionConfig: ConnectionConfig, metadata: {
        version: string;
    });
    /**
     * Create a new PTY (pseudo-terminal).
     *
     * @param opts options for creating the PTY.
     *
     * @returns handle to interact with the PTY.
     */
    create(opts: PtyCreateOpts): Promise<CommandHandle>;
    /**
     * Connect to a running PTY.
     *
     * @param pid process ID of the PTY to connect to. You can get the list of running PTYs using {@link Commands.list}.
     * @param opts connection options.
     *
     * @returns handle to interact with the PTY.
     */
    connect(pid: number, opts?: PtyConnectOpts): Promise<CommandHandle>;
    /**
     * Send input to a PTY.
     *
     * @param pid process ID of the PTY.
     * @param data input data to send to the PTY.
     * @param opts connection options.
     */
    sendInput(pid: number, data: Uint8Array, opts?: Pick<ConnectionOpts, 'requestTimeoutMs'>): Promise<void>;
    /**
     * Resize PTY.
     * Call this when the terminal window is resized and the number of columns and rows has changed.
     *
     * @param pid process ID of the PTY.
     * @param size new size of the PTY.
     * @param opts connection options.
     */
    resize(pid: number, size: {
        cols: number;
        rows: number;
    }, opts?: Pick<ConnectionOpts, 'requestTimeoutMs'>): Promise<void>;
    /**
     * Kill a running PTY specified by process ID.
     * It uses `SIGKILL` signal to kill the PTY.
     *
     * @param pid process ID of the PTY.
     * @param opts connection options.
     *
     * @returns `true` if the PTY was killed, `false` if the PTY was not found.
     */
    kill(pid: number, opts?: Pick<ConnectionOpts, 'requestTimeoutMs'>): Promise<boolean>;
}

/**
 * Options for sending a command request.
 */
interface CommandRequestOpts extends Partial<Pick<ConnectionOpts, 'requestTimeoutMs'>> {
}
/**
 * Options for starting a new command.
 */
interface CommandStartOpts extends CommandRequestOpts {
    /**
     * If true, starts command in the background and the method returns immediately.
     * You can use {@link CommandHandle.wait} to wait for the command to finish.
     */
    background?: boolean;
    /**
     * Working directory for the command.
     *
     * @default // home directory of the user used to start the command
     */
    cwd?: string;
    /**
     * User to run the command as.
     *
     * @default `default Sandbox user (as specified in the template)`
     */
    user?: Username;
    /**
     * Environment variables used for the command.
     *
     * This overrides the default environment variables from `Sandbox` constructor.
     *
     * @default `{}`
     */
    envs?: Record<string, string>;
    /**
     * Callback for command stdout output.
     */
    onStdout?: (data: string) => void | Promise<void>;
    /**
     * Callback for command stderr output.
     */
    onStderr?: (data: string) => void | Promise<void>;
    /**
     * If true, command stdin is kept open and you can send data to it using {@link Commands.sendStdin} or {@link CommandHandle.sendStdin}.
     * @default false
     */
    stdin?: boolean;
    /**
     * Timeout for the command in **milliseconds**.
     *
     * @default 60_000 // 60 seconds
     */
    timeoutMs?: number;
}
/**
 * Options for connecting to a command.
 */
type CommandConnectOpts = Pick<CommandStartOpts, 'onStderr' | 'onStdout' | 'timeoutMs'> & CommandRequestOpts;
/**
 * Information about a command, PTY session or start command running in the sandbox as process.
 */
interface ProcessInfo {
    /**
     * Process ID.
     */
    pid: number;
    /**
     * Custom tag used for identifying special commands like start command in the custom template.
     */
    tag?: string;
    /**
     * Command that was executed.
     */
    cmd: string;
    /**
     * Command arguments.
     */
    args: string[];
    /**
     * Environment variables used for the command.
     */
    envs: Record<string, string>;
    /**
     * Executed command working directory.
     */
    cwd?: string;
}
/**
 * Module for starting and interacting with commands in the sandbox.
 */
declare class Commands {
    private readonly connectionConfig;
    protected readonly rpc: Client<typeof Process>;
    private readonly defaultProcessConnectionTimeout;
    private readonly envdVersion;
    constructor(transport: Transport, connectionConfig: ConnectionConfig, metadata: {
        version: string;
    });
    /**
     * List all running commands and PTY sessions.
     *
     * @param opts connection options.
     *
     * @returns list of running commands and PTY sessions.
     */
    list(opts?: CommandRequestOpts): Promise<ProcessInfo[]>;
    /**
     * Send data to command stdin.
     *
     * @param pid process ID of the command. You can get the list of running commands using {@link Commands.list}.
     * @param data data to send to the command.
     * @param opts connection options.
     */
    sendStdin(pid: number, data: string, opts?: CommandRequestOpts): Promise<void>;
    /**
     * Kill a running command specified by its process ID.
     * It uses `SIGKILL` signal to kill the command.
     *
     * @param pid process ID of the command. You can get the list of running commands using {@link Commands.list}.
     * @param opts connection options.
     *
     * @returns `true` if the command was killed, `false` if the command was not found.
     */
    kill(pid: number, opts?: CommandRequestOpts): Promise<boolean>;
    /**
     * Connect to a running command.
     * You can use {@link CommandHandle.wait} to wait for the command to finish and get execution results.
     *
     * @param pid process ID of the command to connect to. You can get the list of running commands using {@link Commands.list}.
     * @param opts connection options.
     *
     * @returns `CommandHandle` handle to interact with the running command.
     */
    connect(pid: number, opts?: CommandConnectOpts): Promise<CommandHandle>;
    /**
     * Start a new command and wait until it finishes executing.
     *
     * @param cmd command to execute.
     * @param opts options for starting the command.
     *
     * @returns `CommandResult` result of the command execution.
     */
    run(cmd: string, opts?: CommandStartOpts & {
        background?: false;
    }): Promise<CommandResult>;
    /**
     * Start a new command in the background.
     * You can use {@link CommandHandle.wait} to wait for the command to finish and get its result.
     *
     * @param cmd command to execute.
     * @param opts options for starting the command
     *
     * @returns `CommandHandle` handle to interact with the running command.
     */
    run(cmd: string, opts: CommandStartOpts & {
        background: true;
    }): Promise<CommandHandle>;
    /**
     * Start a new command.
     *
     * @param cmd command to execute.
     * @param opts options for starting the command.
     *   - `opts.background: true` - runs in background, returns `CommandHandle`
     *   - `opts.background: false | undefined` - waits for completion, returns `CommandResult`
     *
     * @returns Either a `CommandHandle` or a `CommandResult` (depending on `opts.background`).
     */
    run(cmd: string, opts?: CommandStartOpts & {
        background?: boolean;
    }): Promise<CommandHandle | CommandResult>;
    private start;
}

/**
 * Parsed git status entry for a file.
 */
interface GitFileStatus {
    /**
     * Path relative to the repository root.
     */
    name: string;
    /**
     * Normalized status string (for example, `"modified"` or `"added"`).
     */
    status: GitStatusLabel;
    /**
     * Index status character from porcelain output.
     */
    indexStatus: string;
    /**
     * Working tree status character from porcelain output.
     */
    workingTreeStatus: string;
    /**
     * Whether the change is staged.
     */
    staged: boolean;
    /**
     * Original path when the file was renamed.
     */
    renamedFrom?: string;
}
/**
 * Supported normalized git status labels.
 */
type GitStatusLabel = 'conflict' | 'renamed' | 'copied' | 'deleted' | 'added' | 'modified' | 'typechange' | 'untracked' | 'unknown';
/**
 * Scope for git config operations.
 */
type GitConfigScope = 'global' | 'local' | 'system';
/**
 * Parsed git repository status.
 */
interface GitStatus {
    /**
     * Current branch name, if available.
     */
    currentBranch?: string;
    /**
     * Upstream branch name, if available.
     */
    upstream?: string;
    /**
     * Number of commits the branch is ahead of upstream.
     */
    ahead: number;
    /**
     * Number of commits the branch is behind upstream.
     */
    behind: number;
    /**
     * Whether HEAD is detached.
     */
    detached: boolean;
    /**
     * List of file status entries.
     */
    fileStatus: GitFileStatus[];
    /**
     * Whether the repository has no tracked or untracked file changes.
     */
    isClean: boolean;
    /**
     * Whether the repository has any tracked or untracked file changes.
     */
    hasChanges: boolean;
    /**
     * Whether there are staged changes.
     */
    hasStaged: boolean;
    /**
     * Whether there are untracked files.
     */
    hasUntracked: boolean;
    /**
     * Whether there are merge conflicts.
     */
    hasConflicts: boolean;
    /**
     * Total number of changed files.
     */
    totalCount: number;
    /**
     * Number of files with staged changes.
     */
    stagedCount: number;
    /**
     * Number of files with unstaged changes.
     */
    unstagedCount: number;
    /**
     * Number of untracked files.
     */
    untrackedCount: number;
    /**
     * Number of files with merge conflicts.
     */
    conflictCount: number;
}
/**
 * Parsed git branch list.
 */
interface GitBranches {
    /**
     * List of branch names.
     */
    branches: string[];
    /**
     * Current branch name, if available.
     */
    currentBranch?: string;
}

/**
 * Options for git operations in the sandbox.
 */
interface GitRequestOpts extends Partial<Pick<CommandStartOpts, 'envs' | 'user' | 'cwd' | 'timeoutMs' | 'requestTimeoutMs'>> {
}
/**
 * Options for cloning a repository.
 */
interface GitCloneOpts extends GitRequestOpts {
    /**
     * Destination path for the clone.
     */
    path?: string;
    /**
     * Branch to check out.
     */
    branch?: string;
    /**
     * If set, perform a shallow clone with this depth.
     */
    depth?: number;
    /**
     * Username for HTTP(S) authentication.
     */
    username?: string;
    /**
     * Password or token for HTTP(S) authentication.
     */
    password?: string;
    /**
     * Store credentials in the cloned repository when `true`.
     *
     * @default false
     */
    dangerouslyStoreCredentials?: boolean;
}
/**
 * Options for initializing a repository.
 */
interface GitInitOpts extends GitRequestOpts {
    /**
     * Create a bare repository when `true`.
     */
    bare?: boolean;
    /**
     * Initial branch name (for example, `"main"`).
     */
    initialBranch?: string;
}
/**
 * Options for adding a git remote.
 */
interface GitRemoteAddOpts extends GitRequestOpts {
    /**
     * Fetch the remote after adding it when `true`.
     */
    fetch?: boolean;
    /**
     * Overwrite the remote URL if the remote already exists when `true`.
     */
    overwrite?: boolean;
}
/**
 * Options for creating a commit.
 */
interface GitCommitOpts extends GitRequestOpts {
    /**
     * Commit author name.
     */
    authorName?: string;
    /**
     * Commit author email.
     */
    authorEmail?: string;
    /**
     * Allow empty commits when `true`.
     */
    allowEmpty?: boolean;
}
/**
 * Options for staging files.
 */
interface GitAddOpts extends GitRequestOpts {
    /**
     * Files to add; when omitted, adds the current directory.
     */
    files?: string[];
    /**
     * When `true` and `files` is omitted, stage all changes.
     */
    all?: boolean;
}
/**
 * Supported reset modes.
 */
type GitResetMode = 'soft' | 'mixed' | 'hard' | 'merge' | 'keep';
/**
 * Options for resetting a repository.
 */
interface GitResetOpts extends GitRequestOpts {
    /**
     * Reset mode to use.
     */
    mode?: GitResetMode;
    /**
     * Commit, branch, or ref to reset to (defaults to HEAD).
     */
    target?: string;
    /**
     * Paths to reset.
     */
    paths?: string[];
}
/**
 * Options for restoring files or unstaging changes.
 */
interface GitRestoreOpts extends GitRequestOpts {
    /**
     * Paths to restore (use `['.']` for all).
     */
    paths: string[];
    /**
     * Restore the index (unstage).
     */
    staged?: boolean;
    /**
     * Restore working tree files.
     */
    worktree?: boolean;
    /**
     * Restore from the given source (commit, branch, or ref).
     */
    source?: string;
}
/**
 * Options for deleting a branch.
 */
interface GitDeleteBranchOpts extends GitRequestOpts {
    /**
     * Force deletion with `-D` when `true`.
     */
    force?: boolean;
}
/**
 * Options for pushing commits.
 */
interface GitPushOpts extends GitRequestOpts {
    /**
     * Remote name (for example, `"origin"`).
     */
    remote?: string;
    /**
     * Branch name to push.
     */
    branch?: string;
    /**
     * Set upstream tracking when `true`.
     */
    setUpstream?: boolean;
    /**
     * Username for HTTP(S) authentication.
     */
    username?: string;
    /**
     * Password or token for HTTP(S) authentication.
     */
    password?: string;
}
/**
 * Options for pulling commits.
 */
interface GitPullOpts extends GitRequestOpts {
    /**
     * Remote name (for example, `"origin"`).
     */
    remote?: string;
    /**
     * Branch name to pull.
     */
    branch?: string;
    /**
     * Username for HTTP(S) authentication.
     */
    username?: string;
    /**
     * Password or token for HTTP(S) authentication.
     */
    password?: string;
}
/**
 * Supported scopes for git config operations.
 */
/**
 * Options for git config operations.
 */
interface GitConfigOpts extends GitRequestOpts {
    /**
     * Scope for the git config command.
     *
     * @default "global"
     */
    scope?: GitConfigScope;
    /**
     * Repository path required when `scope` is `"local"`.
     */
    path?: string;
}
/**
 * Options for dangerously authenticating git globally via the credential helper.
 */
interface GitDangerouslyAuthenticateOpts extends GitRequestOpts {
    /**
     * Username for HTTP(S) authentication.
     */
    username: string;
    /**
     * Password or token for HTTP(S) authentication.
     */
    password: string;
    /**
     * Host to authenticate for.
     *
     * @default "github.com"
     */
    host?: string;
    /**
     * Protocol to authenticate for.
     *
     * @default "https"
     */
    protocol?: string;
}
/**
 * Module for running git operations in the sandbox.
 */
declare class Git {
    private readonly commands;
    constructor(commands: Commands);
    /**
     * Clone a git repository into the sandbox.
     *
     * @param url Git repository URL.
     * @param opts Clone options.
     * @returns Command result from the command runner.
     */
    clone(url: string, opts?: GitCloneOpts): Promise<CommandResult>;
    /**
     * Initialize a new git repository.
     *
     * @param path Destination path for the repository.
     * @param opts Init options.
     * @returns Command result from the command runner.
     */
    init(path: string, opts?: GitInitOpts): Promise<CommandResult>;
    /**
     * Add (or update) a remote for a repository.
     *
     * @param path Repository path.
     * @param name Remote name (for example, `"origin"`).
     * @param url Remote URL.
     * @param opts Remote add options.
     * @returns Command result from the command runner.
     */
    remoteAdd(path: string, name: string, url: string, opts?: GitRemoteAddOpts): Promise<CommandResult>;
    /**
     * Get the URL for a git remote.
     *
     * Returns `undefined` when the remote does not exist.
     *
     * @param path Repository path.
     * @param name Remote name (for example, `"origin"`).
     * @param opts Command execution options.
     * @returns Remote URL if present.
     */
    remoteGet(path: string, name: string, opts?: GitRequestOpts): Promise<string | undefined>;
    /**
     * Get repository status information.
     *
     * @param path Repository path.
     * @param opts Command execution options.
     * @returns Parsed git status.
     */
    status(path: string, opts?: GitRequestOpts): Promise<GitStatus>;
    /**
     * List branches in a repository.
     *
     * @param path Repository path.
     * @param opts Command execution options.
     * @returns Parsed branch list.
     */
    branches(path: string, opts?: GitRequestOpts): Promise<GitBranches>;
    /**
     * Create and check out a new branch.
     *
     * @param path Repository path.
     * @param branch Branch name to create.
     * @param opts Command execution options.
     * @returns Command result from the command runner.
     */
    createBranch(path: string, branch: string, opts?: GitRequestOpts): Promise<CommandResult>;
    /**
     * Check out an existing branch.
     *
     * @param path Repository path.
     * @param branch Branch name to check out.
     * @param opts Command execution options.
     * @returns Command result from the command runner.
     */
    checkoutBranch(path: string, branch: string, opts?: GitRequestOpts): Promise<CommandResult>;
    /**
     * Delete a branch.
     *
     * @param path Repository path.
     * @param branch Branch name to delete.
     * @param opts Delete options.
     * @returns Command result from the command runner.
     */
    deleteBranch(path: string, branch: string, opts?: GitDeleteBranchOpts): Promise<CommandResult>;
    /**
     * Stage files for commit.
     *
     * @param path Repository path.
     * @param opts Add options.
     * @returns Command result from the command runner.
     */
    add(path: string, opts?: GitAddOpts): Promise<CommandResult>;
    /**
     * Create a commit in the repository.
     *
     * @param path Repository path.
     * @param message Commit message.
     * @param opts Commit options.
     * @returns Command result from the command runner.
     */
    commit(path: string, message: string, opts?: GitCommitOpts): Promise<CommandResult>;
    /**
     * Reset the current HEAD to a specified state.
     *
     * @param path Repository path.
     * @param opts Reset options.
     * @returns Command result from the command runner.
     */
    reset(path: string, opts?: GitResetOpts): Promise<CommandResult>;
    /**
     * Restore working tree files or unstage changes.
     *
     * @param path Repository path.
     * @param opts Restore options.
     * @returns Command result from the command runner.
     */
    restore(path: string, opts: GitRestoreOpts): Promise<CommandResult>;
    /**
     * Push commits to a remote.
     *
     * @param path Repository path.
     * @param opts Push options.
     * @returns Command result from the command runner.
     */
    push(path: string, opts?: GitPushOpts): Promise<CommandResult>;
    /**
     * Pull changes from a remote.
     *
     * @param path Repository path.
     * @param opts Pull options.
     * @returns Command result from the command runner.
     */
    pull(path: string, opts?: GitPullOpts): Promise<CommandResult>;
    /**
     * Set a git config value.
     *
     * Use `scope: "local"` together with `path` to configure a specific repository.
     *
     * @param key Git config key (for example, `"pull.rebase"`).
     * @param value Git config value.
     * @param opts Config options.
     * @returns Command result from the command runner.
     */
    setConfig(key: string, value: string, opts?: GitConfigOpts): Promise<CommandResult>;
    /**
     * Get a git config value.
     *
     * Returns `undefined` when the key is not set in the requested scope.
     *
     * @param key Git config key (for example, `"pull.rebase"`).
     * @param opts Config options.
     * @returns The config value if present.
     */
    getConfig(key: string, opts?: GitConfigOpts): Promise<string | undefined>;
    /**
     * Dangerously authenticate git globally via the credential helper.
     *
     * This persists credentials in the credential store.
     * Prefer short-lived credentials when possible.
     *
     * @param opts Authentication options.
     * @returns Command result from the command runner.
     */
    dangerouslyAuthenticate(opts: GitDangerouslyAuthenticateOpts): Promise<CommandResult>;
    /**
     * Configure git user name and email.
     *
     * @param name Git user name.
     * @param email Git user email.
     * @param opts Config options.
     * @returns Command result from the command runner.
     */
    configureUser(name: string, email: string, opts?: GitConfigOpts): Promise<CommandResult>;
    /**
     * Build and execute a git command inside the sandbox.
     *
     * @param args Git arguments to pass to the git binary.
     * @param repoPath Repository path used with `git -C`, if provided.
     * @param opts Command execution options.
     * @returns Command result from the command runner.
     */
    private runGit;
    /**
     * Execute a raw shell command while applying default git environment variables.
     *
     Note: We can liekly just modify runGit later to allow appending commands to the git but for now it's separate.
     */
    private runShell;
    private getRemoteUrl;
    private resolveRemoteName;
    private withRemoteCredentials;
    private hasUpstream;
}

/**
 * Options for sandbox upload/download URL generation.
 */
interface SandboxUrlOpts {
    /**
     * Use signature expiration for the URL.
     * Optional parameter to set the expiration time for the signature in seconds.
     */
    useSignatureExpiration?: number;
    /**
     * User that will be used to access the file.
     */
    user?: Username;
}
/**
 * E2B cloud sandbox is a secure and isolated cloud environment.
 *
 * The sandbox allows you to:
 * - Access Linux OS
 * - Create, list, and delete files and directories
 * - Run commands
 * - Run git operations
 * - Run isolated code
 * - Access the internet
 *
 * Check docs [here](https://e2b.dev/docs).
 *
 * Use {@link Sandbox.create} to create a new sandbox.
 *
 * @example
 * ```ts
 * import { Sandbox } from 'e2b'
 *
 * const sandbox = await Sandbox.create()
 * ```
 */
declare class Sandbox extends SandboxApi {
    protected static readonly defaultTemplate: string;
    protected static readonly defaultMcpTemplate: string;
    protected static readonly defaultSandboxTimeoutMs = 300000;
    /**
     * Module for interacting with the sandbox filesystem
     */
    readonly files: Filesystem;
    /**
     * Module for running commands in the sandbox
     */
    readonly commands: Commands;
    /**
     * Module for interacting with the sandbox pseudo-terminals
     */
    readonly pty: Pty;
    /**
     * Module for running git operations in the sandbox
     */
    readonly git: Git;
    /**
     * Unique identifier of the sandbox.
     */
    readonly sandboxId: string;
    /**
     * Domain where the sandbox is hosted.
     */
    readonly sandboxDomain: string;
    /**
     * Traffic access token for accessing sandbox services with restricted public traffic.
     */
    readonly trafficAccessToken?: string;
    protected readonly envdPort = 49983;
    protected readonly mcpPort = 50005;
    protected readonly connectionConfig: ConnectionConfig;
    protected readonly envdAccessToken?: string;
    private readonly envdApiUrl;
    private readonly envdApi;
    private mcpToken?;
    /**
     * Use {@link Sandbox.create} to create a new Sandbox instead.
     *
     * @hidden
     * @hide
     * @internal
     * @access protected
     */
    constructor(opts: SandboxConnectOpts & {
        sandboxId: string;
        sandboxDomain?: string;
        envdVersion: string;
        envdAccessToken?: string;
        trafficAccessToken?: string;
    });
    /**
     * List all sandboxes.
     *
     * @param opts connection options.
     *
     * @returns paginator for listing sandboxes.
     */
    static list(opts?: SandboxListOpts): SandboxPaginator;
    /**
     * Create a new sandbox from the default `base` sandbox template.
     *
     * @param opts connection options.
     *
     * @returns sandbox instance for the new sandbox.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create()
     * ```
     * @constructs {@link Sandbox}
     */
    static create<S extends typeof Sandbox>(this: S, opts?: SandboxOpts): Promise<InstanceType<S>>;
    /**
     * Create a new sandbox from the specified sandbox template.
     *
     * @param template sandbox template name or ID.
     * @param opts connection options.
     *
     * @returns sandbox instance for the new sandbox.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create('<template-name-or-id>')
     * ```
     * @constructs {@link Sandbox}
     */
    static create<S extends typeof Sandbox>(this: S, template: string, opts?: SandboxOpts): Promise<InstanceType<S>>;
    /**
     * @beta This feature is in beta and may change in the future.
     *
     * Create a new sandbox from the default `base` sandbox template.
     *
     * @param opts connection options.
     *
     * @returns sandbox instance for the new sandbox.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.betaCreate()
     * ```
     * @constructs {@link Sandbox}
     */
    static betaCreate<S extends typeof Sandbox>(this: S, opts?: SandboxBetaCreateOpts): Promise<InstanceType<S>>;
    /**
     * @beta This feature is in beta and may change in the future.
     *
     * Create a new sandbox from the specified sandbox template.
     *
     * @param template sandbox template name or ID.
     * @param opts connection options.
     *
     * @returns sandbox instance for the new sandbox.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.betaCreate('<template-name-or-id>')
     * ```
     * @constructs {@link Sandbox}
     */
    static betaCreate<S extends typeof Sandbox>(this: S, template: string, opts?: SandboxBetaCreateOpts): Promise<InstanceType<S>>;
    /**
     * Connect to a sandbox. If the sandbox is paused, it will be automatically resumed.
     * Sandbox must be either running or be paused.
     *
     * With sandbox ID you can connect to the same sandbox from different places or environments (serverless functions, etc).
     *
     * @param sandboxId sandbox ID.
     * @param opts connection options.
     *
     * @returns A running sandbox instance
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create()
     * const sandboxId = sandbox.sandboxId
     *
     * // Connect to the same sandbox.
     * const sameSandbox = await Sandbox.connect(sandboxId)
     * ```
     */
    static connect<S extends typeof Sandbox>(this: S, sandboxId: string, opts?: SandboxConnectOpts): Promise<InstanceType<S>>;
    /**
     * Connect to a sandbox. If the sandbox is paused, it will be automatically resumed.
     * Sandbox must be either running or be paused.
     *
     * With sandbox ID you can connect to the same sandbox from different places or environments (serverless functions, etc).
     *
     * @param opts connection options.
     *
     * @returns A running sandbox instance
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create()
     * await sandbox.betaPause()
     *
     * // Connect to the same sandbox.
     * const sameSandbox = await sandbox.connect()
     * ```
     */
    connect(opts?: SandboxBetaCreateOpts): Promise<this>;
    /**
     * Get the host address for the specified sandbox port.
     * You can then use this address to connect to the sandbox port from outside the sandbox via HTTP or WebSocket.
     *
     * @param port number of the port in the sandbox.
     *
     * @returns host address of the sandbox port.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create()
     * // Start an HTTP server
     * await sandbox.commands.exec('python3 -m http.server 3000')
     * // Get the hostname of the HTTP server
     * const serverURL = sandbox.getHost(3000)
     * ```
     */
    getHost(port: number): string;
    /**
     * Check if the sandbox is running.
     *
     * @returns `true` if the sandbox is running, `false` otherwise.
     *
     * @example
     * ```ts
     * const sandbox = await Sandbox.create()
     * await sandbox.isRunning() // Returns true
     *
     * await sandbox.kill()
     * await sandbox.isRunning() // Returns false
     * ```
     */
    isRunning(opts?: Pick<ConnectionOpts, 'requestTimeoutMs'>): Promise<boolean>;
    /**
     * Set the timeout of the sandbox.
     *
     * This method can extend or reduce the sandbox timeout set when creating the sandbox or from the last call to `.setTimeout`.
     * Maximum time a sandbox can be kept alive is 24 hours (86_400_000 milliseconds) for Pro users and 1 hour (3_600_000 milliseconds) for Hobby users.
     *
     * @param timeoutMs timeout in **milliseconds**.
     * @param opts connection options.
     */
    setTimeout(timeoutMs: number, opts?: Pick<SandboxOpts, 'requestTimeoutMs'>): Promise<void>;
    /**
     * Kill the sandbox.
     *
     * @param opts connection options.
     */
    kill(opts?: Pick<SandboxOpts, 'requestTimeoutMs'>): Promise<void>;
    /**
     * @beta This feature is in beta and may change in the future.
     *
     * Pause a sandbox by its ID.
     *
     * @param opts connection options.
     *
     * @returns sandbox ID that can be used to resume the sandbox.
     */
    betaPause(opts?: ConnectionOpts): Promise<boolean>;
    /**
     *
     * Get the MCP URL for the sandbox.
     *
     * @returns MCP URL for the sandbox.
     */
    getMcpUrl(): string;
    /**
     * Get the MCP token for the sandbox.
     *
     * @returns MCP token for the sandbox, or undefined if MCP is not enabled.
     */
    getMcpToken(): Promise<string | undefined>;
    /**
     * Get the URL to upload a file to the sandbox.
     *
     * You have to send a POST request to this URL with the file as multipart/form-data.
     *
     * @param path path to the file in the sandbox.
     *
     * @param opts download url options.
     *
     * @returns URL for uploading file.
     */
    uploadUrl(path?: string, opts?: SandboxUrlOpts): Promise<string>;
    /**
     * Get the URL to download a file from the sandbox.
     *
     * @param path path to the file in the sandbox.
     *
     * @param opts download url options.
     *
     * @returns URL for downloading file.
     */
    downloadUrl(path: string, opts?: SandboxUrlOpts): Promise<string>;
    /**
     * Get sandbox information like sandbox ID, template, metadata, started at/end at date.
     *
     * @param opts connection options.
     *
     * @returns information about the sandbox
     */
    getInfo(opts?: Pick<SandboxOpts, 'requestTimeoutMs'>): Promise<SandboxInfo>;
    /**
     * Get the metrics of the sandbox.
     *
     * @param opts connection options.
     *
     * @returns  List of sandbox metrics containing CPU, memory and disk usage information.
     */
    getMetrics(opts?: SandboxMetricsOpts): Promise<SandboxMetrics[]>;
    private fileUrl;
}

/**
 * Class for ready check commands.
 */
declare class ReadyCmd {
    private cmd;
    constructor(cmd: string);
    getCmd(): string;
}
/**
 * Wait for a port to be listening.
 * Uses `ss` command to check if a port is open and listening.
 *
 * @param port Port number to wait for
 * @returns ReadyCmd that checks for the port
 *
 * @example
 * ```ts
 * import { Template, waitForPort } from 'e2b'
 *
 * const template = Template()
 *   .fromPythonImage()
 *   .setStartCmd('python -m http.server 8000', waitForPort(8000))
 * ```
 */
declare function waitForPort(port: number): ReadyCmd;
/**
 * Wait for a URL to return a specific HTTP status code.
 * Uses `curl` to make HTTP requests and check the response status.
 *
 * @param url URL to check (e.g., 'http://localhost:3000/health')
 * @param statusCode Expected HTTP status code (default: 200)
 * @returns ReadyCmd that checks the URL
 *
 * @example
 * ```ts
 * import { Template, waitForURL } from 'e2b'
 *
 * const template = Template()
 *   .fromNodeImage()
 *   .setStartCmd('npm start', waitForURL('http://localhost:3000/health'))
 * ```
 */
declare function waitForURL(url: string, statusCode?: number): ReadyCmd;
/**
 * Wait for a process with a specific name to be running.
 * Uses `pgrep` to check if a process exists.
 *
 * @param processName Name of the process to wait for
 * @returns ReadyCmd that checks for the process
 *
 * @example
 * ```ts
 * import { Template, waitForProcess } from 'e2b'
 *
 * const template = Template()
 *   .fromBaseImage()
 *   .setStartCmd('./my-daemon', waitForProcess('my-daemon'))
 * ```
 */
declare function waitForProcess(processName: string): ReadyCmd;
/**
 * Wait for a file to exist.
 * Uses shell test command to check file existence.
 *
 * @param filename Path to the file to wait for
 * @returns ReadyCmd that checks for the file
 *
 * @example
 * ```ts
 * import { Template, waitForFile } from 'e2b'
 *
 * const template = Template()
 *   .fromBaseImage()
 *   .setStartCmd('./init.sh', waitForFile('/tmp/ready'))
 * ```
 */
declare function waitForFile(filename: string): ReadyCmd;
/**
 * Wait for a specified timeout before considering the sandbox ready.
 * Uses `sleep` command to wait for a fixed duration.
 *
 * @param timeout Time to wait in milliseconds (minimum: 1000ms / 1 second)
 * @returns ReadyCmd that waits for the specified duration
 *
 * @example
 * ```ts
 * import { Template, waitForTimeout } from 'e2b'
 *
 * const template = Template()
 *   .fromNodeImage()
 *   .setStartCmd('npm start', waitForTimeout(5000)) // Wait 5 seconds
 * ```
 */
declare function waitForTimeout(timeout: number): ReadyCmd;

/**
 * Log entry severity levels.
 */
type LogEntryLevel = 'debug' | 'info' | 'warn' | 'error';
/**
 * Represents a single log entry from the template build process.
 */
declare class LogEntry {
    readonly timestamp: Date;
    readonly level: LogEntryLevel;
    readonly message: string;
    constructor(timestamp: Date, level: LogEntryLevel, message: string);
    toString(): string;
}
/**
 * Special log entry indicating the start of a build process.
 */
declare class LogEntryStart extends LogEntry {
    constructor(timestamp: Date, message: string);
}
/**
 * Special log entry indicating the end of a build process.
 */
declare class LogEntryEnd extends LogEntry {
    constructor(timestamp: Date, message: string);
}
/**
 * Create a default build logger with animated timer display.
 *
 * @param options Logger configuration options
 * @param options.minLevel Minimum log level to display (default: 'info')
 * @returns Logger function that accepts LogEntry instances
 *
 * @example
 * ```ts
 * import { Template, defaultBuildLogger } from 'e2b'
 *
 * const template = Template().fromPythonImage()
 *
 * await Template.build(template, {
 *   alias: 'my-template',
 *   onBuildLogs: defaultBuildLogger({ minLevel: 'debug' })
 * })
 * ```
 */
declare function defaultBuildLogger(options?: {
    minLevel?: LogEntryLevel;
}): (logEntry: LogEntry) => void;

/**
 * Options for creating a new template.
 */
type TemplateOptions = {
    /**
     * Path to the directory containing files to be copied into the template.
     * @default Current directory from template location
     */
    fileContextPath?: PathLike;
    /**
     * Array of glob patterns to ignore when copying files.
     */
    fileIgnorePatterns?: string[];
};
/**
 * Basic options for building a template.
 */
type BasicBuildOptions = {
    /**
     * Alias name for the template.
     * @deprecated Use the `name` parameter of `Template.build()` instead.
     */
    alias: string;
    /**
     * Tags to assign to the template build.
     */
    tags?: string[];
    /**
     * Number of CPUs allocated to the sandbox.
     * @default 2
     */
    cpuCount?: number;
    /**
     * Amount of memory in MB allocated to the sandbox.
     * @default 1024
     */
    memoryMB?: number;
    /**
     * If true, skips cache and forces a complete rebuild.
     * @default false
     */
    skipCache?: boolean;
    /**
     * Callback function to receive build logs during the build process.
     */
    onBuildLogs?: (logEntry: LogEntry) => void;
};
/**
 * Options for building a template with authentication.
 */
type BuildOptions = ConnectionOpts & BasicBuildOptions;
/**
 * Information about a built template.
 */
type BuildInfo = {
    /**
     * First alias from the build (for backward compatibility).
     * @deprecated Use `name` instead.
     */
    alias: string;
    /**
     * Name of the template.
     */
    name: string;
    /**
     * Tags assigned to this build.
     */
    tags: string[];
    /**
     * Template identifier.
     */
    templateId: string;
    /**
     * Build identifier.
     */
    buildId: string;
};
/**
 * Options for getting build status.
 */
type GetBuildStatusOptions = ConnectionOpts & {
    logsOffset?: number;
};
/**
 * Status of a template build.
 */
type TemplateBuildStatus = 'building' | 'waiting' | 'ready' | 'error';
/**
 * Reason for the current build status (typically for errors).
 */
type BuildStatusReason = {
    /**
     * Message with the status reason.
     */
    message: string;
    /**
     * Step that failed.
     */
    step?: string;
    /**
     * Log entries related to the status reason.
     */
    logEntries: LogEntry[];
};
/**
 * Response from getting build status.
 */
type TemplateBuildStatusResponse = {
    /**
     * Build identifier.
     */
    buildID: string;
    /**
     * Template identifier.
     */
    templateID: string;
    /**
     * Current status of the build.
     */
    status: TemplateBuildStatus;
    /**
     * Build log entries.
     */
    logEntries: LogEntry[];
    /**
     * Build logs (raw strings).
     * @deprecated Use `logEntries` instead.
     */
    logs: string[];
    /**
     * Reason for the current status (typically for errors).
     */
    reason?: BuildStatusReason;
};
/**
 * Information about assigned template tags.
 */
type TemplateTagInfo = {
    /**
     * Build identifier associated with this tag.
     */
    buildId: string;
    /**
     * Assigned tags of the template.
     */
    tags: string[];
};
/**
 * Configuration for a single file/directory copy operation.
 */
type CopyItem = {
    src: PathLike | PathLike[];
    dest: PathLike;
    forceUpload?: true;
    user?: string;
    mode?: number;
    resolveSymlinks?: boolean;
};
/**
 * MCP server names that can be installed.
 */
type McpServerName = keyof McpServer$1;
/**
 * Initial state of a template builder.
 * Use one of these methods to specify the base image or template to start from.
 */
interface TemplateFromImage {
    /**
     * Start from a Debian-based Docker image.
     * @param variant Debian variant (default: 'stable')
     *
     * @example
     * ```ts
     * Template().fromDebianImage('bookworm')
     * ```
     */
    fromDebianImage(variant?: string): TemplateBuilder;
    /**
     * Start from an Ubuntu-based Docker image.
     * @param variant Ubuntu variant (default: 'latest')
     *
     * @example
     * ```ts
     * Template().fromUbuntuImage('24.04')
     * ```
     */
    fromUbuntuImage(variant?: string): TemplateBuilder;
    /**
     * Start from a Python-based Docker image.
     * @param version Python version (default: '3')
     *
     * @example
     * ```ts
     * Template().fromPythonImage('3')
     * ```
     */
    fromPythonImage(version?: string): TemplateBuilder;
    /**
     * Start from a Node.js-based Docker image.
     * @param variant Node.js variant (default: 'lts')
     *
     * @example
     * ```ts
     * Template().fromNodeImage('24')
     * ```
     */
    fromNodeImage(variant?: string): TemplateBuilder;
    /**
     * Start from a Bun-based Docker image.
     * @param variant Bun variant (default: 'latest')
     *
     * @example
     * ```ts
     * Template().fromBunImage('1.3')
     * ```
     */
    fromBunImage(variant?: string): TemplateBuilder;
    /**
     * Start from E2B's default base image (e2bdev/base:latest).
     *
     * @example
     * ```ts
     * Template().fromBaseImage()
     * ```
     */
    fromBaseImage(): TemplateBuilder;
    /**
     * Start from a custom Docker image.
     * @param baseImage Docker image name
     * @param credentials Optional credentials for private registries
     *
     * @example
     * ```ts
     * Template().fromImage('python:3')
     *
     * // With credentials (optional)
     * Template().fromImage('myregistry.com/myimage:latest', {
     *   username: 'user',
     *   password: 'pass'
     * })
     * ```
     */
    fromImage(baseImage: string, credentials?: {
        username: string;
        password: string;
    }): TemplateBuilder;
    /**
     * Start from an existing E2B template.
     * @param template E2B template ID or alias
     *
     * @example
     * ```ts
     * Template().fromTemplate('my-base-template')
     * ```
     */
    fromTemplate(template: string): TemplateBuilder;
    /**
     * Parse a Dockerfile and convert it to Template SDK format.
     * @param dockerfileContentOrPath Dockerfile content or path
     *
     * @example
     * ```ts
     * Template().fromDockerfile('Dockerfile')
     * Template().fromDockerfile('FROM python:3\nRUN pip install numpy')
     * ```
     */
    fromDockerfile(dockerfileContentOrPath: string): TemplateBuilder;
    /**
     * Start from a Docker image in AWS ECR.
     * @param image Full ECR image path
     * @param credentials AWS credentials
     *
     * @example
     * ```ts
     * Template().fromAWSRegistry(
     *   '123456789.dkr.ecr.us-west-2.amazonaws.com/myimage:latest',
     *   {
     *     accessKeyId: 'AKIA...',
     *     secretAccessKey: '...',
     *     region: 'us-west-2'
     *   }
     * )
     * ```
     */
    fromAWSRegistry(image: string, credentials: {
        accessKeyId: string;
        secretAccessKey: string;
        region: string;
    }): TemplateBuilder;
    /**
     * Start from a Docker image in Google Container Registry.
     * @param image Full GCR/GAR image path
     * @param credentials GCP service account credentials
     *
     * @example
     * ```ts
     * Template().fromGCPRegistry(
     *   'gcr.io/myproject/myimage:latest',
     *   { serviceAccountJSON: 'path/to/service-account.json' }
     * )
     * ```
     */
    fromGCPRegistry(image: string, credentials: {
        serviceAccountJSON: object | string;
    }): TemplateBuilder;
    /**
     * Skip cache for all subsequent build instructions from this point.
     *
     * @example
     * ```ts
     * Template().skipCache().fromPythonImage('3')
     * ```
     */
    skipCache(): this;
}
/**
 * Main builder state for constructing templates.
 * Provides methods for customizing the template environment.
 */
interface TemplateBuilder {
    /**
     * Copy files or directories into the template.
     * @param src Source path(s)
     * @param dest Destination path
     * @param options Copy options
     *
     * @example
     * ```ts
     * template.copy('requirements.txt', '/home/user/')
     * template.copy(['app.ts', 'config.ts'], '/app/', { mode: 0o755 })
     * ```
     */
    copy(src: PathLike | PathLike[], dest: PathLike, options?: {
        forceUpload?: true;
        user?: string;
        mode?: number;
        resolveSymlinks?: boolean;
    }): TemplateBuilder;
    /**
     * Copy multiple items with individual options.
     * @param items Array of copy items
     *
     * @example
     * ```ts
     * template.copyItems([
     *   { src: 'app.ts', dest: '/app/' },
     *   { src: 'config.ts', dest: '/app/', mode: 0o644 }
     * ])
     * ```
     */
    copyItems(items: CopyItem[]): TemplateBuilder;
    /**
     * Remove files or directories.
     * @param path Path(s) to remove
     * @param options Remove options
     *
     * @example
     * ```ts
     * template.remove('/tmp/cache', { recursive: true, force: true })
     * template.remove('/tmp/cache', { recursive: true, force: true, user: 'root' })
     * ```
     */
    remove(path: PathLike | PathLike[], options?: {
        force?: boolean;
        recursive?: boolean;
        user?: string;
    }): TemplateBuilder;
    /**
     * Rename or move a file or directory.
     * @param src Source path
     * @param dest Destination path
     * @param options Rename options
     *
     * @example
     * ```ts
     * template.rename('/tmp/old.txt', '/tmp/new.txt')
     * template.rename('/tmp/old.txt', '/tmp/new.txt', { user: 'root' })
     * ```
     */
    rename(src: PathLike, dest: PathLike, options?: {
        force?: boolean;
        user?: string;
    }): TemplateBuilder;
    /**
     * Create directories.
     * @param path Directory path(s)
     * @param options Directory options
     *
     * @example
     * ```ts
     * template.makeDir('/app/data', { mode: 0o755 })
     * template.makeDir(['/app/logs', '/app/cache'])
     * template.makeDir('/app/data', { mode: 0o755, user: 'root' })
     * ```
     */
    makeDir(path: PathLike | PathLike[], options?: {
        mode?: number;
        user?: string;
    }): TemplateBuilder;
    /**
     * Create a symbolic link.
     * @param src Source path (target)
     * @param dest Destination path (symlink location)
     * @param options Symlink options
     *
     * @example
     * ```ts
     * template.makeSymlink('/usr/bin/python3', '/usr/bin/python')
     * template.makeSymlink('/usr/bin/python3', '/usr/bin/python', { user: 'root' })
     * template.makeSymlink('/usr/bin/python3', '/usr/bin/python', { force: true })
     * ```
     */
    makeSymlink(src: PathLike, dest: PathLike, options?: {
        user?: string;
        force?: boolean;
    }): TemplateBuilder;
    /**
     * Run a shell command.
     * @param command Command string
     * @param options Command options
     *
     * @example
     * ```ts
     * template.runCmd('apt-get update')
     * template.runCmd(['pip install numpy', 'pip install pandas'])
     * template.runCmd('apt-get install vim', { user: 'root' })
     * ```
     */
    runCmd(command: string, options?: {
        user?: string;
    }): TemplateBuilder;
    /**
     * Run multiple shell commands.
     * @param commands Array of command strings
     * @param options Command options
     */
    runCmd(commands: string[], options?: {
        user?: string;
    }): TemplateBuilder;
    /**
     * Run command(s).
     * @param commandOrCommands Command or commands
     * @param options Command options
     */
    runCmd(commandOrCommands: string | string[], options?: {
        user?: string;
    }): TemplateBuilder;
    /**
     * Set the working directory.
     * @param workdir Working directory path
     *
     * @example
     * ```ts
     * template.setWorkdir('/app')
     * ```
     */
    setWorkdir(workdir: PathLike): TemplateBuilder;
    /**
     * Set the user for subsequent commands.
     * @param user Username
     *
     * @example
     * ```ts
     * template.setUser('root')
     * ```
     */
    setUser(user: string): TemplateBuilder;
    /**
     * Install Python packages using pip.
     * @param packages Package name(s) or undefined for current directory
     * @param options Install options
     * @param options.g Install globally as root (default: true). Set to false for user-only installation with --user flag
     *
     * @example
     * ```ts
     * template.pipInstall('numpy')  // Installs globally (default)
     * template.pipInstall(['pandas', 'scikit-learn'])
     * template.pipInstall('numpy', { g: false })  // Install for user only
     * template.pipInstall()  // Installs from current directory
     * ```
     */
    pipInstall(packages?: string | string[], options?: {
        g?: boolean;
    }): TemplateBuilder;
    /**
     * Install Node.js packages using npm.
     * @param packages Package name(s) or undefined for package.json
     * @param options Install options
     *
     * @example
     * ```ts
     * template.npmInstall('express')
     * template.npmInstall(['lodash', 'axios'])
     * template.npmInstall('tsx', { g: true })
     * template.npmInstall('typescript', { dev: true })
     * template.npmInstall()  // Installs from package.json
     * ```
     */
    npmInstall(packages?: string | string[], options?: {
        g?: boolean;
        dev?: boolean;
    }): TemplateBuilder;
    /**
     * Install Bun packages using bun.
     * @param packages Package name(s) or undefined for package.json
     * @param options Install options
     *
     * @example
     * ```ts
     * template.bunInstall('express')
     * template.bunInstall(['lodash', 'axios'])
     * template.bunInstall('tsx', { g: true })
     * template.bunInstall('typescript', { dev: true })
     * template.bunInstall()  // Installs from package.json
     * ```
     */
    bunInstall(packages?: string | string[], options?: {
        g?: boolean;
        dev?: boolean;
    }): TemplateBuilder;
    /**
     * Install Debian/Ubuntu packages using apt-get.
     * @param packages Package name(s)
     *
     * @example
     * ```ts
     * template.aptInstall('vim')
     * template.aptInstall(['git', 'curl', 'wget'])
     * template.aptInstall(['vim'], { noInstallRecommends: true })
     * ```
     */
    aptInstall(packages: string | string[], options?: {
        noInstallRecommends?: boolean;
    }): TemplateBuilder;
    /**
     * Install MCP servers using mcp-gateway.
     * Note: Requires a base image with mcp-gateway pre-installed (e.g., mcp-gateway).
     * @param servers MCP server name(s)
     *
     * @throws {Error} If the base template is not mcp-gateway
     * @example
     * ```ts
     * template.addMcpServer('exa')
     * template.addMcpServer(['brave', 'firecrawl', 'duckduckgo'])
     * ```
     */
    addMcpServer(servers: McpServerName | McpServerName[]): TemplateBuilder;
    /**
     * Clone a Git repository.
     * @param url Repository URL
     * @param path Optional destination path
     * @param options Clone options
     *
     * @example
     * ```ts
     * template.gitClone('https://github.com/user/repo.git', '/app/repo')
     * template.gitClone('https://github.com/user/repo.git', undefined, {
     *   branch: 'main',
     *   depth: 1
     * })
     * template.gitClone('https://github.com/user/repo.git', '/app/repo', {
     *   user: 'root'
     * })
     * ```
     */
    gitClone(url: string, path?: PathLike, options?: {
        branch?: string;
        depth?: number;
        user?: string;
    }): TemplateBuilder;
    /**
     * Set environment variables.
     * Note: Environment variables defined here are available only during template build.
     * @param envs Environment variables
     *
     * @example
     * ```ts
     * template.setEnvs({ NODE_ENV: 'production', PORT: '8080' })
     * ```
     */
    setEnvs(envs: Record<string, string>): TemplateBuilder;
    /**
     * Skip cache for all subsequent build instructions from this point.
     *
     * @example
     * ```ts
     * template.skipCache().runCmd('apt-get update')
     * ```
     */
    skipCache(): this;
    /**
     * Set the start command and ready check.
     * @param startCommand Command to run on startup
     * @param readyCommand Command to check readiness
     *
     * @example
     * ```ts
     * // Using a string command
     * template.setStartCmd(
     *   'node app.js',
     *   'curl http://localhost:8000/health'
     * )
     *
     * // Using ReadyCmd helpers
     * import { waitForPort, waitForURL } from 'e2b'
     *
     * template.setStartCmd(
     *   'python -m http.server 8000',
     *   waitForPort(8000)
     * )
     *
     * template.setStartCmd(
     *   'npm start',
     *   waitForURL('http://localhost:3000/health', 200)
     * )
     * ```
     */
    setStartCmd(startCommand: string, readyCommand: string | ReadyCmd): TemplateFinal;
    /**
     * Set or update the ready check command.
     * @param readyCommand Command to check readiness
     *
     * @example
     * ```ts
     * // Using a string command
     * template.setReadyCmd('curl http://localhost:8000/health')
     *
     * // Using ReadyCmd helpers
     * import { waitForPort, waitForFile, waitForProcess } from 'e2b'
     *
     * template.setReadyCmd(waitForPort(3000))
     *
     * template.setReadyCmd(waitForFile('/tmp/ready'))
     *
     * template.setReadyCmd(waitForProcess('nginx'))
     * ```
     */
    setReadyCmd(readyCommand: string | ReadyCmd): TemplateFinal;
    /**
     * Prebuild a devcontainer from the specified directory.
     * @param devcontainerDirectory Path to the devcontainer directory
     *
     * @example
     * ```ts
     * template
     *  .gitClone('https://myrepo.com/project.git', '/my-devcontainer')
     *  .betaDevContainerPrebuild('/my-devcontainer')
     * ```
     */
    betaDevContainerPrebuild(devcontainerDirectory: string): TemplateBuilder;
    /**
     * Start a devcontainer from the specified directory.
     * @param devcontainerDirectory Path to the devcontainer directory
     *
     * @example
     * ```ts
     * template
     *  .gitClone('https://myrepo.com/project.git', '/my-devcontainer')
     *  .startDevcontainer('/my-devcontainer')
     *
     * // Prebuild and start
     * template
     *  .gitClone('https://myrepo.com/project.git', '/my-devcontainer')
     *  .betaDevContainerPrebuild('/my-devcontainer')
     *  // Other instructions...
     *  .betaSetDevContainerStart('/my-devcontainer')
     * ```
     */
    betaSetDevContainerStart(devcontainerDirectory: string): TemplateFinal;
}
/**
 * Final state of a template after start/ready commands are set.
 * The template can only be built in this state.
 */
interface TemplateFinal {
}
/**
 * Type representing a template in any state (builder or final).
 */
type TemplateClass = TemplateBuilder | TemplateFinal;

/**
 * Base class for building E2B sandbox templates.
 */
declare class TemplateBase implements TemplateFromImage, TemplateBuilder, TemplateFinal {
    private defaultBaseImage;
    private baseImage;
    private baseTemplate;
    private registryConfig;
    private startCmd;
    private readyCmd;
    private force;
    private forceNextLayer;
    private instructions;
    private fileContextPath;
    private fileIgnorePatterns;
    private logsRefreshFrequency;
    private stackTraces;
    private stackTracesEnabled;
    private stackTracesOverride;
    constructor(options?: TemplateOptions);
    /**
     * Convert a template to JSON representation.
     *
     * @param template The template to convert
     * @param computeHashes Whether to compute file hashes for cache invalidation
     * @returns JSON string representation of the template
     */
    static toJSON(template: TemplateClass, computeHashes?: boolean): Promise<string>;
    /**
     * Convert a template to Dockerfile format.
     * Note: Templates based on other E2B templates cannot be converted to Dockerfile.
     *
     * @param template The template to convert
     * @returns Dockerfile string representation
     * @throws Error if the template is based on another E2B template
     */
    static toDockerfile(template: TemplateClass): string;
    /**
     * Build and deploy a template to E2B infrastructure.
     *
     * @param template The template to build
     * @param name Template name in 'name' or 'name:tag' format
     * @param options Optional build configuration options
     *
     * @example
     * ```ts
     * const template = Template().fromPythonImage('3')
     *
     * // Build with single tag in name
     * await Template.build(template, 'my-python-env:v1.0')
     *
     * // Build with multiple tags
     * await Template.build(template, 'my-python-env', { tags: ['v1.0', 'stable'] })
     * ```
     */
    static build(template: TemplateClass, name: string, options?: Omit<BuildOptions, 'alias'>): Promise<BuildInfo>;
    /**
     * Build and deploy a template to E2B infrastructure.
     *
     * @param template The template to build
     * @param options Build configuration options with alias (deprecated)
     *
     * @deprecated Use the overload with `name` parameter instead.
     * @example
     * ```ts
     * // Deprecated:
     * await Template.build(template, { alias: 'my-python-env' })
     *
     * // Use instead:
     * await Template.build(template, 'my-python-env:v1.0')
     * ```
     */
    static build(template: TemplateClass, options: BuildOptions): Promise<BuildInfo>;
    /**
     * Build and deploy a template to E2B infrastructure without waiting for completion.
     *
     * @param template The template to build
     * @param name Template name in 'name' or 'name:tag' format
     * @param options Optional build configuration options
     *
     * @example
     * ```ts
     * const template = Template().fromPythonImage('3')
     *
     * // Build with single tag in name
     * const data = await Template.buildInBackground(template, 'my-python-env:v1.0')
     *
     * // Build with multiple tags
     * const data = await Template.buildInBackground(template, 'my-python-env', { tags: ['v1.0', 'stable'] })
     * ```
     */
    static buildInBackground(template: TemplateClass, name: string, options?: Omit<BuildOptions, 'alias'>): Promise<BuildInfo>;
    /**
     * Build and deploy a template to E2B infrastructure without waiting for completion.
     *
     * @param template The template to build
     * @param options Build configuration options with alias (deprecated)
     *
     * @deprecated Use the overload with `name` parameter instead.
     * @example
     * ```ts
     * // Deprecated:
     * await Template.buildInBackground(template, { alias: 'my-python-env' })
     *
     * // Use instead:
     * await Template.buildInBackground(template, 'my-python-env:v1.0')
     * ```
     */
    static buildInBackground(template: TemplateClass, options: BuildOptions): Promise<BuildInfo>;
    /**
     * Get the status of a build.
     *
     * @param data Build identifiers
     * @param options Authentication options
     *
     * @example
     * ```ts
     * const status = await Template.getBuildStatus(data, { logsOffset: 0 })
     * ```
     */
    static getBuildStatus(data: Pick<BuildInfo, 'templateId' | 'buildId'>, options?: GetBuildStatusOptions): Promise<TemplateBuildStatusResponse>;
    /**
     * Check if a template with the given name exists.
     *
     * @param name Template name to check
     * @param options Authentication options
     * @returns True if the name exists, false otherwise
     *
     * @example
     * ```ts
     * const exists = await Template.exists('my-python-env')
     * if (exists) {
     *   console.log('Template exists!')
     * }
     * ```
     */
    static exists(name: string, options?: ConnectionOpts): Promise<boolean>;
    /**
     * Check if a template with the given alias exists.
     *
     * @param alias Template alias to check
     * @param options Authentication options
     * @returns True if the alias exists, false otherwise
     *
     * @deprecated Use `exists` instead.
     * @example
     * ```ts
     * const exists = await Template.aliasExists('my-python-env')
     * if (exists) {
     *   console.log('Template exists!')
     * }
     * ```
     */
    static aliasExists(alias: string, options?: ConnectionOpts): Promise<boolean>;
    /**
     * Assign tag(s) to an existing template build.
     *
     * @param targetName Template name in 'name:tag' format (the source build to tag from)
     * @param tags Tag or tags to assign
     * @param options Authentication options
     * @returns Tag info with buildId and assigned tags
     *
     * @example
     * ```ts
     * // Assign a single tag
     * await Template.assignTags('my-template:v1.0', 'production')
     *
     * // Assign multiple tags
     * await Template.assignTags('my-template:v1.0', ['production', 'stable'])
     * ```
     */
    static assignTags(targetName: string, tags: string | string[], options?: ConnectionOpts): Promise<TemplateTagInfo>;
    /**
     * Remove tag(s) from a template.
     *
     * @param name Template name
     * @param tags Tag or tags to remove
     * @param options Authentication options
     *
     * @example
     * ```ts
     * // Remove a single tag
     * await Template.removeTags('my-template', 'production')
     *
     * // Remove multiple tags from a template
     * await Template.removeTags('my-template', ['production', 'staging'])
     * ```
     */
    static removeTags(name: string, tags: string | string[], options?: ConnectionOpts): Promise<void>;
    fromDebianImage(variant?: string): TemplateBuilder;
    fromUbuntuImage(variant?: string): TemplateBuilder;
    fromPythonImage(version?: string): TemplateBuilder;
    fromNodeImage(variant?: string): TemplateBuilder;
    fromBunImage(variant?: string): TemplateBuilder;
    fromBaseImage(): TemplateBuilder;
    fromImage(baseImage: string, credentials?: {
        username: string;
        password: string;
    }): TemplateBuilder;
    fromTemplate(template: string): TemplateBuilder;
    fromDockerfile(dockerfileContentOrPath: string): TemplateBuilder;
    fromAWSRegistry(image: string, credentials: {
        accessKeyId: string;
        secretAccessKey: string;
        region: string;
    }): TemplateBuilder;
    fromGCPRegistry(image: string, credentials: {
        serviceAccountJSON: string | object;
    }): TemplateBuilder;
    copy(src: PathLike | PathLike[], dest: PathLike, options?: {
        forceUpload?: true;
        user?: string;
        mode?: number;
        resolveSymlinks?: boolean;
    }): TemplateBuilder;
    copyItems(items: CopyItem[]): TemplateBuilder;
    remove(path: PathLike | PathLike[], options?: {
        force?: boolean;
        recursive?: boolean;
        user?: string;
    }): TemplateBuilder;
    rename(src: PathLike, dest: PathLike, options?: {
        force?: boolean;
        user?: string;
    }): TemplateBuilder;
    makeDir(path: PathLike | PathLike[], options?: {
        mode?: number;
        user?: string;
    }): TemplateBuilder;
    makeSymlink(src: PathLike, dest: PathLike, options?: {
        user?: string;
        force?: boolean;
    }): TemplateBuilder;
    runCmd(command: string, options?: {
        user?: string;
    }): TemplateBuilder;
    runCmd(commands: string[], options?: {
        user?: string;
    }): TemplateBuilder;
    setWorkdir(workdir: PathLike): TemplateBuilder;
    setUser(user: string): TemplateBuilder;
    pipInstall(packages?: string | string[], options?: {
        g?: boolean;
    }): TemplateBuilder;
    npmInstall(packages?: string | string[], options?: {
        g?: boolean;
        dev?: boolean;
    }): TemplateBuilder;
    bunInstall(packages?: string | string[], options?: {
        g?: boolean;
        dev?: boolean;
    }): TemplateBuilder;
    aptInstall(packages: string | string[], options?: {
        noInstallRecommends?: boolean;
    }): TemplateBuilder;
    addMcpServer(servers: McpServerName | McpServerName[]): TemplateBuilder;
    gitClone(url: string, path?: PathLike, options?: {
        branch?: string;
        depth?: number;
        user?: string;
    }): TemplateBuilder;
    setStartCmd(startCommand: string, readyCommand: string | ReadyCmd): TemplateFinal;
    setReadyCmd(readyCommand: string | ReadyCmd): TemplateFinal;
    setEnvs(envs: Record<string, string>): TemplateBuilder;
    skipCache(): this;
    betaDevContainerPrebuild(devcontainerDirectory: string): TemplateBuilder;
    betaSetDevContainerStart(devcontainerDirectory: string): TemplateFinal;
    /**
     * Collect the current stack trace for debugging purposes.
     *
     * @param stackTracesDepth Depth to traverse in the call stack
     * @returns this for method chaining
     */
    private collectStackTrace;
    /**
     * Temporarily disable stack trace collection.
     *
     * @returns this for method chaining
     */
    private disableStackTrace;
    /**
     * Re-enable stack trace collection.
     *
     * @returns this for method chaining
     */
    private enableStackTrace;
    /**
     * Execute a function in a clean stack trace context.
     *
     * @param fn Function to execute
     * @returns The result of the function
     */
    private runInNewStackTraceContext;
    private runInStackTraceOverrideContext;
    /**
     * Convert the template to JSON representation.
     *
     * @param computeHashes Whether to compute file hashes for COPY instructions
     * @returns JSON string representation of the template
     */
    private toJSON;
    /**
     * Convert the template to Dockerfile format.
     *
     * Note: Only templates based on Docker images can be converted to Dockerfile.
     * Templates based on other E2B templates cannot be converted because they
     * may use features not available in standard Dockerfiles.
     *
     * @returns Dockerfile string representation
     * @throws Error if template is based on another E2B template or has no base image
     */
    private toDockerfile;
    /**
     * Internal implementation of the template build process.
     *
     * @param client API client for communicating with E2B backend
     * @param name Template name in 'name' or 'name:tag' format
     * @param tags Additional tags to assign to the build
     * @param options Build configuration options
     * @throws BuildError if the build fails
     */
    private build;
    /**
     * Add file hashes to COPY instructions for cache invalidation.
     *
     * @returns Copy of instructions array with filesHash added to COPY instructions
     */
    private instructionsWithHashes;
    /**
     * Serialize the template to the API request format.
     *
     * @param steps Array of build instructions with file hashes
     * @returns Template data formatted for the API
     */
    private serialize;
}
/**
 * Create a new E2B template builder instance.
 *
 * @param options Optional configuration for the template builder
 * @returns A new template builder instance
 *
 * @example
 * ```ts
 * import { Template } from 'e2b'
 *
 * const template = Template()
 *   .fromPythonImage('3')
 *   .copy('requirements.txt', '/app/')
 *   .pipInstall()
 *
 * await Template.build(template, 'my-python-app:v1.0')
 * ```
 */
declare function Template(options?: TemplateOptions): TemplateFromImage;
declare namespace Template {
    var build: typeof TemplateBase.build;
    var buildInBackground: typeof TemplateBase.buildInBackground;
    var getBuildStatus: typeof TemplateBase.getBuildStatus;
    var exists: typeof TemplateBase.exists;
    var aliasExists: typeof TemplateBase.aliasExists;
    var assignTags: typeof TemplateBase.assignTags;
    var removeTags: typeof TemplateBase.removeTags;
    var toJSON: typeof TemplateBase.toJSON;
    var toDockerfile: typeof TemplateBase.toDockerfile;
}

export { ALL_TRAFFIC, ApiClient, AuthenticationError, BuildError, type BuildInfo, type BuildOptions, type BuildStatusReason, type CommandConnectOpts, CommandExitError, CommandHandle, type CommandRequestOpts, type CommandResult, type CommandStartOpts, Commands, ConnectionConfig, type ConnectionOpts, type CopyItem, type EntryInfo, FileType, FileUploadError, Filesystem, type FilesystemEvent, FilesystemEventType, type GetBuildStatusOptions, Git, type GitAddOpts, GitAuthError, type GitBranches, type GitCloneOpts, type GitCommitOpts, type GitConfigOpts, type GitConfigScope, type GitDangerouslyAuthenticateOpts, type GitDeleteBranchOpts, type GitFileStatus, type GitInitOpts, type GitPullOpts, type GitPushOpts, type GitRemoteAddOpts, type GitRequestOpts, type GitStatus, GitUpstreamError, InvalidArgumentError, LogEntry, LogEntryEnd, type LogEntryLevel, LogEntryStart, type Logger, type McpServer$1 as McpServer, type McpServerName, NotEnoughSpaceError, NotFoundError, type ProcessInfo, Pty, type PtyOutput, RateLimitError, ReadyCmd, Sandbox, type SandboxApiOpts, type SandboxBetaCreateOpts, type SandboxConnectOpts, SandboxError, type SandboxInfo, type SandboxListOpts, type SandboxMetrics, type SandboxMetricsOpts, type SandboxNetworkOpts, type SandboxOpts, SandboxPaginator, type SandboxState, type Stderr, type Stdout, Template, TemplateBase, type TemplateBuildStatus, type TemplateBuildStatusResponse, type TemplateBuilder, type TemplateClass, TemplateError, type TemplateTagInfo, TimeoutError, type Username, WatchHandle, type WriteInfo, type components, Sandbox as default, defaultBuildLogger, getSignature, type paths, waitForFile, waitForPort, waitForProcess, waitForTimeout, waitForURL };
