{"version":3,"file":"string.d.cts","names":["BaseTransformOutputParser","ContentBlock","StringOutputParser","Promise","Text","Data","URLContentBlock"],"sources":["../../src/output_parsers/string.d.ts"],"sourcesContent":["import { BaseTransformOutputParser } from \"./transform.js\";\nimport { ContentBlock } from \"../messages/index.js\";\n/**\n * OutputParser that parses LLMResult into the top likely string.\n * @example\n * ```typescript\n * const promptTemplate = PromptTemplate.fromTemplate(\n *   \"Tell me a joke about {topic}\",\n * );\n *\n * const chain = RunnableSequence.from([\n *   promptTemplate,\n *   new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n *   new StringOutputParser(),\n * ]);\n *\n * const result = await chain.invoke({ topic: \"bears\" });\n * console.log(\"What do you call a bear with no teeth? A gummy bear!\");\n * ```\n */\nexport declare class StringOutputParser extends BaseTransformOutputParser<string> {\n    static lc_name(): string;\n    lc_namespace: string[];\n    lc_serializable: boolean;\n    /**\n     * Parses a string output from an LLM call. This method is meant to be\n     * implemented by subclasses to define how a string output from an LLM\n     * should be parsed.\n     * @param text The string output from an LLM call.\n     * @param callbacks Optional callbacks.\n     * @returns A promise of the parsed output.\n     */\n    parse(text: string): Promise<string>;\n    getFormatInstructions(): string;\n    protected _textContentToString(content: ContentBlock.Text): string;\n    protected _imageUrlContentToString(_content: ContentBlock.Data.URLContentBlock): string;\n    protected _messageContentToString(content: ContentBlock): string;\n    protected _baseMessageContentToString(content: ContentBlock[]): string;\n}\n//# sourceMappingURL=string.d.ts.map"],"mappings":";;;;;;;AAoBA;;;;;;;AAAyE;;;;;;;;;cAApDE,kBAAAA,SAA2BF;;;;;;;;;;;;uBAYvBG;;0CAEmBF,YAAAA,CAAaG;+CACRH,YAAAA,CAAaI,IAAAA,CAAKC;6CACpBL;iDACIA"}