{"version":3,"file":"responses.js","names":["convertResponsesUsageToUsageMetadata: Converter<\n  OpenAIClient.Responses.ResponseUsage | undefined,\n  UsageMetadata\n>","convertResponsesMessageToAIMessage: Converter<\n  ResponsesCreateInvoke | ResponsesParseInvoke,\n  AIMessage\n>","messageId: string | undefined","content: MessageContent","tool_calls: ToolCall[]","invalid_tool_calls: InvalidToolCall[]","response_metadata: Record<string, unknown>","additional_kwargs: {\n    [key: string]: unknown;\n    refusal?: string;\n    reasoning?: OpenAIClient.Responses.ResponseReasoningItem;\n    tool_outputs?: unknown[];\n    parsed?: unknown;\n    [_FUNCTION_CALL_IDS_MAP_KEY]?: Record<string, string>;\n  }","e: unknown","errMessage: string | undefined","convertReasoningSummaryToResponsesReasoningItem: Converter<\n  ChatOpenAIReasoningSummary,\n  OpenAIClient.Responses.ResponseReasoningItem\n>","convertResponsesDeltaToChatGenerationChunk: Converter<\n  OpenAIClient.Responses.ResponseStreamEvent,\n  ChatGenerationChunk | null\n>","content: Record<string, unknown>[]","generationInfo: Record<string, unknown>","usage_metadata: UsageMetadata | undefined","tool_call_chunks: ToolCallChunk[]","additional_kwargs: {\n    [key: string]: unknown;\n    reasoning?: Partial<ChatOpenAIReasoningSummary>;\n    tool_outputs?: unknown[];\n  }","id: string | undefined","summary: ChatOpenAIReasoningSummary[\"summary\"] | undefined","convertStandardContentMessageToResponsesInput: Converter<\n  BaseMessage,\n  OpenAIClient.Responses.ResponseInputItem[]\n>","currentMessage: OpenAIClient.Responses.EasyInputMessage | undefined","pushMessageContent: (\n      content: OpenAIClient.Responses.ResponseInputMessageContentList\n    ) => void","value: unknown","block: ContentBlock.Multimodal.Image","block: ContentBlock.Multimodal.File | ContentBlock.Multimodal.Video","block: ContentBlock.Reasoning","reasoningItem: OpenAIClient.Responses.ResponseReasoningItem","block: ContentBlock.Tools.ToolCall | ContentBlock.Tools.ServerToolCall","block: ContentBlock.Tools.ServerToolCallResult","convertMessagesToResponsesInput: Converter<\n  { messages: BaseMessage[]; zdrEnabled: boolean; model: string },\n  ResponsesInputItem[]\n>","input: ResponsesInputItem[]","fallthroughCallTypes: ResponsesInputItem[\"type\"][]","messages: ResponsesInputItem[]","messages"],"sources":["../../src/converters/responses.ts"],"sourcesContent":["import { OpenAI as OpenAIClient } from \"openai\";\nimport {\n  AIMessage,\n  AIMessageChunk,\n  type BaseMessage,\n  type UsageMetadata,\n  type BaseMessageFields,\n  type MessageContent,\n  type InvalidToolCall,\n  MessageContentImageUrl,\n  isDataContentBlock,\n  convertToProviderContentBlock,\n  ContentBlock,\n} from \"@langchain/core/messages\";\nimport { ChatGenerationChunk } from \"@langchain/core/outputs\";\nimport {\n  makeInvalidToolCall,\n  parseToolCall,\n} from \"@langchain/core/output_parsers/openai_tools\";\nimport type {\n  ToolCall,\n  ToolCallChunk,\n  ToolMessage,\n} from \"@langchain/core/messages/tool\";\nimport { ResponseInputMessageContentList } from \"openai/resources/responses/responses.js\";\nimport { ChatOpenAIReasoningSummary } from \"../types.js\";\nimport {\n  isComputerToolCall,\n  isCustomToolCall,\n  parseComputerCall,\n  parseCustomToolCall,\n} from \"../utils/tools.js\";\nimport {\n  getRequiredFilenameFromMetadata,\n  iife,\n  isReasoningModel,\n  messageToOpenAIRole,\n} from \"../utils/misc.js\";\nimport { Converter } from \"@langchain/core/utils/format\";\nimport { completionsApiContentBlockConverter } from \"./completions.js\";\n\nconst _FUNCTION_CALL_IDS_MAP_KEY = \"__openai_function_call_ids__\";\n\ntype ExcludeController<T> = T extends { controller: unknown } ? never : T;\n\nexport type ResponsesCreate = OpenAIClient.Responses[\"create\"];\nexport type ResponsesParse = OpenAIClient.Responses[\"parse\"];\n\nexport type ResponsesCreateInvoke = ExcludeController<\n  Awaited<ReturnType<ResponsesCreate>>\n>;\nexport type ResponsesParseInvoke = ExcludeController<\n  Awaited<ReturnType<ResponsesParse>>\n>;\n\nexport type ResponsesInputItem = OpenAIClient.Responses.ResponseInputItem;\n\n/**\n * Converts OpenAI Responses API usage statistics to LangChain's UsageMetadata format.\n *\n * This converter transforms token usage information from OpenAI's Responses API into\n * the standardized UsageMetadata format used throughout LangChain. It handles both\n * basic token counts and detailed token breakdowns including cached tokens and\n * reasoning tokens.\n *\n * @param usage - The usage statistics object from OpenAI's Responses API containing\n *                token counts and optional detailed breakdowns.\n *\n * @returns A UsageMetadata object containing:\n *   - `input_tokens`: Total number of tokens in the input/prompt (defaults to 0 if not provided)\n *   - `output_tokens`: Total number of tokens in the model's output (defaults to 0 if not provided)\n *   - `total_tokens`: Combined total of input and output tokens (defaults to 0 if not provided)\n *   - `input_token_details`: Object containing detailed input token information:\n *     - `cache_read`: Number of tokens read from cache (only included if available)\n *   - `output_token_details`: Object containing detailed output token information:\n *     - `reasoning`: Number of tokens used for reasoning (only included if available)\n *\n * @example\n * ```typescript\n * const usage = {\n *   input_tokens: 100,\n *   output_tokens: 50,\n *   total_tokens: 150,\n *   input_tokens_details: { cached_tokens: 20 },\n *   output_tokens_details: { reasoning_tokens: 10 }\n * };\n *\n * const metadata = convertResponsesUsageToUsageMetadata(usage);\n * // Returns:\n * // {\n * //   input_tokens: 100,\n * //   output_tokens: 50,\n * //   total_tokens: 150,\n * //   input_token_details: { cache_read: 20 },\n * //   output_token_details: { reasoning: 10 }\n * // }\n * ```\n *\n * @remarks\n * - The function safely handles undefined or null values by using optional chaining\n *   and nullish coalescing operators\n * - Detailed token information (cache_read, reasoning) is only included in the result\n *   if the corresponding values are present in the input\n * - Token counts default to 0 if not provided in the usage object\n * - This converter is specifically designed for OpenAI's Responses API format and\n *   may differ from other OpenAI API endpoints\n */\nexport const convertResponsesUsageToUsageMetadata: Converter<\n  OpenAIClient.Responses.ResponseUsage | undefined,\n  UsageMetadata\n> = (usage) => {\n  const inputTokenDetails = {\n    ...(usage?.input_tokens_details?.cached_tokens != null && {\n      cache_read: usage?.input_tokens_details?.cached_tokens,\n    }),\n  };\n  const outputTokenDetails = {\n    ...(usage?.output_tokens_details?.reasoning_tokens != null && {\n      reasoning: usage?.output_tokens_details?.reasoning_tokens,\n    }),\n  };\n  return {\n    input_tokens: usage?.input_tokens ?? 0,\n    output_tokens: usage?.output_tokens ?? 0,\n    total_tokens: usage?.total_tokens ?? 0,\n    input_token_details: inputTokenDetails,\n    output_token_details: outputTokenDetails,\n  };\n};\n\n/**\n * Converts an OpenAI Responses API response to a LangChain AIMessage.\n *\n * This converter processes the output from OpenAI's Responses API (both `create` and `parse` methods)\n * and transforms it into a LangChain AIMessage object with all relevant metadata, tool calls, and content.\n *\n * @param response - The response object from OpenAI's Responses API. Can be either:\n *   - ResponsesCreateInvoke: Result from `responses.create()`\n *   - ResponsesParseInvoke: Result from `responses.parse()`\n *\n * @returns An AIMessage containing:\n *   - `id`: The message ID from the response output\n *   - `content`: Array of message content blocks (text, images, etc.)\n *   - `tool_calls`: Array of successfully parsed tool calls\n *   - `invalid_tool_calls`: Array of tool calls that failed to parse\n *   - `usage_metadata`: Token usage information converted to LangChain format\n *   - `additional_kwargs`: Extra data including:\n *     - `refusal`: Refusal text if the model refused to respond\n *     - `reasoning`: Reasoning output for reasoning models\n *     - `tool_outputs`: Results from built-in tools (web search, file search, etc.)\n *     - `parsed`: Parsed structured output when using json_schema format\n *     - Function call ID mappings for tracking\n *   - `response_metadata`: Metadata about the response including model, timestamps, status, etc.\n *\n * @throws Error if the response contains an error object. The error message and code are extracted\n *   from the response.error field.\n *\n * @example\n * ```typescript\n * const response = await client.responses.create({\n *   model: \"gpt-4\",\n *   input: [{ type: \"message\", content: \"Hello\" }]\n * });\n * const message = convertResponsesMessageToAIMessage(response);\n * console.log(message.content); // Message content\n * console.log(message.tool_calls); // Any tool calls made\n * ```\n *\n * @remarks\n * The converter handles multiple output item types:\n * - `message`: Text and structured content from the model\n * - `function_call`: Tool/function calls that need to be executed\n * - `reasoning`: Reasoning traces from reasoning models (o1, o3, etc.)\n * - `custom_tool_call`: Custom tool invocations\n * - Built-in tool outputs: web_search, file_search, code_interpreter, etc.\n *\n * Tool calls are parsed and validated. Invalid tool calls (malformed JSON, etc.) are captured\n * in the `invalid_tool_calls` array rather than throwing errors.\n */\nexport const convertResponsesMessageToAIMessage: Converter<\n  ResponsesCreateInvoke | ResponsesParseInvoke,\n  AIMessage\n> = (response) => {\n  if (response.error) {\n    // TODO: add support for `addLangChainErrorFields`\n    const error = new Error(response.error.message);\n    error.name = response.error.code;\n    throw error;\n  }\n\n  let messageId: string | undefined;\n  const content: MessageContent = [];\n  const tool_calls: ToolCall[] = [];\n  const invalid_tool_calls: InvalidToolCall[] = [];\n  const response_metadata: Record<string, unknown> = {\n    model_provider: \"openai\",\n    model: response.model,\n    created_at: response.created_at,\n    id: response.id,\n    incomplete_details: response.incomplete_details,\n    metadata: response.metadata,\n    object: response.object,\n    status: response.status,\n    user: response.user,\n    service_tier: response.service_tier,\n    // for compatibility with chat completion calls.\n    model_name: response.model,\n  };\n\n  const additional_kwargs: {\n    [key: string]: unknown;\n    refusal?: string;\n    reasoning?: OpenAIClient.Responses.ResponseReasoningItem;\n    tool_outputs?: unknown[];\n    parsed?: unknown;\n    [_FUNCTION_CALL_IDS_MAP_KEY]?: Record<string, string>;\n  } = {};\n\n  for (const item of response.output) {\n    if (item.type === \"message\") {\n      messageId = item.id;\n      content.push(\n        ...item.content.flatMap((part) => {\n          if (part.type === \"output_text\") {\n            if (\"parsed\" in part && part.parsed != null) {\n              additional_kwargs.parsed = part.parsed;\n            }\n            return {\n              type: \"text\",\n              text: part.text,\n              annotations: part.annotations,\n            };\n          }\n\n          if (part.type === \"refusal\") {\n            additional_kwargs.refusal = part.refusal;\n            return [];\n          }\n\n          return part;\n        })\n      );\n    } else if (item.type === \"function_call\") {\n      const fnAdapter = {\n        function: { name: item.name, arguments: item.arguments },\n        id: item.call_id,\n      };\n\n      try {\n        tool_calls.push(parseToolCall(fnAdapter, { returnId: true }));\n      } catch (e: unknown) {\n        let errMessage: string | undefined;\n        if (\n          typeof e === \"object\" &&\n          e != null &&\n          \"message\" in e &&\n          typeof e.message === \"string\"\n        ) {\n          errMessage = e.message;\n        }\n        invalid_tool_calls.push(makeInvalidToolCall(fnAdapter, errMessage));\n      }\n\n      additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] ??= {};\n      if (item.id) {\n        additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY][item.call_id] = item.id;\n      }\n    } else if (item.type === \"reasoning\") {\n      additional_kwargs.reasoning = item;\n    } else if (item.type === \"custom_tool_call\") {\n      const parsed = parseCustomToolCall(item);\n      if (parsed) {\n        tool_calls.push(parsed);\n      } else {\n        invalid_tool_calls.push(\n          makeInvalidToolCall(item, \"Malformed custom tool call\")\n        );\n      }\n    } else if (item.type === \"computer_call\") {\n      const parsed = parseComputerCall(item);\n      if (parsed) {\n        tool_calls.push(parsed);\n      } else {\n        invalid_tool_calls.push(\n          makeInvalidToolCall(item, \"Malformed computer call\")\n        );\n      }\n    } else {\n      additional_kwargs.tool_outputs ??= [];\n      additional_kwargs.tool_outputs.push(item);\n    }\n  }\n\n  return new AIMessage({\n    id: messageId,\n    content,\n    tool_calls,\n    invalid_tool_calls,\n    usage_metadata: convertResponsesUsageToUsageMetadata(response.usage),\n    additional_kwargs,\n    response_metadata,\n  });\n};\n\n/**\n * Converts a LangChain ChatOpenAI reasoning summary to an OpenAI Responses API reasoning item.\n *\n * This converter transforms reasoning summaries that have been accumulated during streaming\n * (where summary parts may arrive in multiple chunks with the same index) into the final\n * consolidated format expected by OpenAI's Responses API. It combines summary parts that\n * share the same index and removes the index field from the final output.\n *\n * @param reasoning - A ChatOpenAI reasoning summary object containing:\n *   - `id`: The reasoning item ID\n *   - `type`: The type of reasoning (typically \"reasoning\")\n *   - `summary`: Array of summary parts, each with:\n *     - `text`: The summary text content\n *     - `type`: The summary type (e.g., \"summary_text\")\n *     - `index`: The index used to group related summary parts during streaming\n *\n * @returns An OpenAI Responses API ResponseReasoningItem with:\n *   - All properties from the input reasoning object\n *   - `summary`: Consolidated array of summary objects with:\n *     - `text`: Combined text from all parts with the same index\n *     - `type`: The summary type\n *     - No `index` field (removed after consolidation)\n *\n * @example\n * ```typescript\n * // Input: Reasoning summary with multiple parts at the same index\n * const reasoning = {\n *   id: \"reasoning_123\",\n *   type: \"reasoning\",\n *   summary: [\n *     { text: \"First \", type: \"summary_text\", index: 0 },\n *     { text: \"part\", type: \"summary_text\", index: 0 },\n *     { text: \"Second part\", type: \"summary_text\", index: 1 }\n *   ]\n * };\n *\n * const result = convertReasoningSummaryToResponsesReasoningItem(reasoning);\n * // Returns:\n * // {\n * //   id: \"reasoning_123\",\n * //   type: \"reasoning\",\n * //   summary: [\n * //     { text: \"First part\", type: \"summary_text\" },\n * //     { text: \"Second part\", type: \"summary_text\" }\n * //   ]\n * // }\n * ```\n *\n * @remarks\n * - This converter is primarily used when reconstructing complete reasoning items from\n *   streaming chunks, where summary parts may arrive incrementally with index markers\n * - Summary parts with the same index are concatenated in the order they appear\n * - If the reasoning summary contains only one part, no reduction is performed\n * - The index field is used internally during streaming to track which summary parts\n *   belong together, but is removed from the final output as it's not part of the\n *   OpenAI Responses API schema\n * - This is the inverse operation of the streaming accumulation that happens in\n *   `convertResponsesDeltaToChatGenerationChunk`\n */\nexport const convertReasoningSummaryToResponsesReasoningItem: Converter<\n  ChatOpenAIReasoningSummary,\n  OpenAIClient.Responses.ResponseReasoningItem\n> = (reasoning) => {\n  // combine summary parts that have the the same index and then remove the indexes\n  const summary = (\n    reasoning.summary.length > 1\n      ? reasoning.summary.reduce(\n          (acc, curr) => {\n            const last = acc[acc.length - 1];\n\n            if (last!.index === curr.index) {\n              last!.text += curr.text;\n            } else {\n              acc.push(curr);\n            }\n            return acc;\n          },\n          [{ ...reasoning.summary[0] }]\n        )\n      : reasoning.summary\n  ).map((s) =>\n    Object.fromEntries(Object.entries(s).filter(([k]) => k !== \"index\"))\n  ) as OpenAIClient.Responses.ResponseReasoningItem.Summary[];\n\n  return {\n    ...reasoning,\n    summary,\n  } as OpenAIClient.Responses.ResponseReasoningItem;\n};\n\n/**\n * Converts OpenAI Responses API stream events to LangChain ChatGenerationChunk objects.\n *\n * This converter processes streaming events from OpenAI's Responses API and transforms them\n * into LangChain ChatGenerationChunk objects that can be used in streaming chat applications.\n * It handles various event types including text deltas, tool calls, reasoning, and metadata updates.\n *\n * @param event - A streaming event from OpenAI's Responses API\n *\n * @returns A ChatGenerationChunk containing:\n *   - `text`: Concatenated text content from all text parts in the event\n *   - `message`: An AIMessageChunk with:\n *     - `id`: Message ID (set when a message output item is added)\n *     - `content`: Array of content blocks (text with optional annotations)\n *     - `tool_call_chunks`: Incremental tool call data (name, args, id)\n *     - `usage_metadata`: Token usage information (only in completion events)\n *     - `additional_kwargs`: Extra data including:\n *       - `refusal`: Refusal text if the model refused to respond\n *       - `reasoning`: Reasoning output for reasoning models (id, type, summary)\n *       - `tool_outputs`: Results from built-in tools (web search, file search, etc.)\n *       - `parsed`: Parsed structured output when using json_schema format\n *       - Function call ID mappings for tracking\n *     - `response_metadata`: Metadata about the response (model, id, etc.)\n *   - `generationInfo`: Additional generation information (e.g., tool output status)\n *\n *   Returns `null` for events that don't produce meaningful chunks:\n *   - Partial image generation events (to avoid storing all partial images in history)\n *   - Unrecognized event types\n *\n * @example\n * ```typescript\n * const stream = await client.responses.create({\n *   model: \"gpt-4\",\n *   input: [{ type: \"message\", content: \"Hello\" }],\n *   stream: true\n * });\n *\n * for await (const event of stream) {\n *   const chunk = convertResponsesDeltaToChatGenerationChunk(event);\n *   if (chunk) {\n *     console.log(chunk.text); // Incremental text\n *     console.log(chunk.message.tool_call_chunks); // Tool call updates\n *   }\n * }\n * ```\n *\n * @remarks\n * - Text content is accumulated in an array with index tracking for proper ordering\n * - Tool call chunks include incremental arguments that need to be concatenated by the consumer\n * - Reasoning summaries are built incrementally across multiple events\n * - Function call IDs are tracked in `additional_kwargs` to map call_id to item id\n * - The `text` field is provided for legacy compatibility with `onLLMNewToken` callbacks\n * - Usage metadata is only available in `response.completed` events\n * - Partial images are intentionally ignored to prevent memory bloat in conversation history\n */\nexport const convertResponsesDeltaToChatGenerationChunk: Converter<\n  OpenAIClient.Responses.ResponseStreamEvent,\n  ChatGenerationChunk | null\n> = (event) => {\n  const content: Record<string, unknown>[] = [];\n  let generationInfo: Record<string, unknown> = {};\n  let usage_metadata: UsageMetadata | undefined;\n  const tool_call_chunks: ToolCallChunk[] = [];\n  const response_metadata: Record<string, unknown> = {\n    model_provider: \"openai\",\n  };\n  const additional_kwargs: {\n    [key: string]: unknown;\n    reasoning?: Partial<ChatOpenAIReasoningSummary>;\n    tool_outputs?: unknown[];\n  } = {};\n  let id: string | undefined;\n  if (event.type === \"response.output_text.delta\") {\n    content.push({\n      type: \"text\",\n      text: event.delta,\n      index: event.content_index,\n    });\n  } else if (event.type === \"response.output_text.annotation.added\") {\n    content.push({\n      type: \"text\",\n      text: \"\",\n      annotations: [event.annotation],\n      index: event.content_index,\n    });\n  } else if (\n    event.type === \"response.output_item.added\" &&\n    event.item.type === \"message\"\n  ) {\n    id = event.item.id;\n  } else if (\n    event.type === \"response.output_item.added\" &&\n    event.item.type === \"function_call\"\n  ) {\n    tool_call_chunks.push({\n      type: \"tool_call_chunk\",\n      name: event.item.name,\n      args: event.item.arguments,\n      id: event.item.call_id,\n      index: event.output_index,\n    });\n\n    additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] = {\n      [event.item.call_id]: event.item.id,\n    };\n  } else if (\n    event.type === \"response.output_item.done\" &&\n    event.item.type === \"computer_call\"\n  ) {\n    // Handle computer_call as a tool call so ToolNode can process it\n    tool_call_chunks.push({\n      type: \"tool_call_chunk\",\n      name: \"computer_use\",\n      args: JSON.stringify({ action: event.item.action }),\n      id: event.item.call_id,\n      index: event.output_index,\n    });\n    // Also store the raw item for additional context (pending_safety_checks, etc.)\n    additional_kwargs.tool_outputs = [event.item];\n  } else if (\n    event.type === \"response.output_item.done\" &&\n    [\n      \"web_search_call\",\n      \"file_search_call\",\n      \"code_interpreter_call\",\n      \"mcp_call\",\n      \"mcp_list_tools\",\n      \"mcp_approval_request\",\n      \"image_generation_call\",\n      \"custom_tool_call\",\n    ].includes(event.item.type)\n  ) {\n    additional_kwargs.tool_outputs = [event.item];\n  } else if (event.type === \"response.created\") {\n    response_metadata.id = event.response.id;\n    response_metadata.model_name = event.response.model;\n    response_metadata.model = event.response.model;\n  } else if (event.type === \"response.completed\") {\n    const msg = convertResponsesMessageToAIMessage(event.response);\n\n    usage_metadata = convertResponsesUsageToUsageMetadata(event.response.usage);\n\n    if (event.response.text?.format?.type === \"json_schema\") {\n      additional_kwargs.parsed ??= JSON.parse(msg.text);\n    }\n    for (const [key, value] of Object.entries(event.response)) {\n      if (key !== \"id\") response_metadata[key] = value;\n    }\n  } else if (\n    event.type === \"response.function_call_arguments.delta\" ||\n    event.type === \"response.custom_tool_call_input.delta\"\n  ) {\n    tool_call_chunks.push({\n      type: \"tool_call_chunk\",\n      args: event.delta,\n      index: event.output_index,\n    });\n  } else if (\n    event.type === \"response.web_search_call.completed\" ||\n    event.type === \"response.file_search_call.completed\"\n  ) {\n    generationInfo = {\n      tool_outputs: {\n        id: event.item_id,\n        type: event.type.replace(\"response.\", \"\").replace(\".completed\", \"\"),\n        status: \"completed\",\n      },\n    };\n  } else if (event.type === \"response.refusal.done\") {\n    additional_kwargs.refusal = event.refusal;\n  } else if (\n    event.type === \"response.output_item.added\" &&\n    \"item\" in event &&\n    event.item.type === \"reasoning\"\n  ) {\n    const summary: ChatOpenAIReasoningSummary[\"summary\"] | undefined = event\n      .item.summary\n      ? event.item.summary.map((s, index) => ({\n          ...s,\n          index,\n        }))\n      : undefined;\n\n    additional_kwargs.reasoning = {\n      // We only capture ID in the first event or else the concatenated result of all chunks will\n      // have an ID field that is repeated once per event. There is special handling for the `type`\n      // field that prevents this, however.\n      id: event.item.id,\n      type: event.item.type,\n      ...(summary ? { summary } : {}),\n    };\n  } else if (event.type === \"response.reasoning_summary_part.added\") {\n    additional_kwargs.reasoning = {\n      type: \"reasoning\",\n      summary: [{ ...event.part, index: event.summary_index }],\n    };\n  } else if (event.type === \"response.reasoning_summary_text.delta\") {\n    additional_kwargs.reasoning = {\n      type: \"reasoning\",\n      summary: [\n        {\n          text: event.delta,\n          type: \"summary_text\",\n          index: event.summary_index,\n        },\n      ],\n    };\n  } else if (event.type === \"response.image_generation_call.partial_image\") {\n    // noop/fixme: retaining partial images in a message chunk means that _all_\n    // partial images get kept in history, so we don't do anything here.\n    return null;\n  } else {\n    return null;\n  }\n\n  return new ChatGenerationChunk({\n    // Legacy reasons, `onLLMNewToken` should pulls this out\n    text: content.map((part) => part.text).join(\"\"),\n    message: new AIMessageChunk({\n      id,\n      content: content as MessageContent,\n      tool_call_chunks,\n      usage_metadata,\n      additional_kwargs,\n      response_metadata,\n    }),\n    generationInfo,\n  });\n};\n\n/**\n * Converts a single LangChain BaseMessage to OpenAI Responses API input format.\n *\n * This converter transforms a LangChain message into one or more ResponseInputItem objects\n * that can be used with OpenAI's Responses API. It handles complex message structures including\n * tool calls, reasoning blocks, multimodal content, and various content block types.\n *\n * @param message - The LangChain BaseMessage to convert. Can be any message type including\n *   HumanMessage, AIMessage, SystemMessage, ToolMessage, etc.\n *\n * @returns An array of ResponseInputItem objects.\n *\n * @example\n * Basic text message conversion:\n * ```typescript\n * const message = new HumanMessage(\"Hello, how are you?\");\n * const items = convertStandardContentMessageToResponsesInput(message);\n * // Returns: [{ type: \"message\", role: \"user\", content: [{ type: \"input_text\", text: \"Hello, how are you?\" }] }]\n * ```\n *\n * @example\n * AI message with tool calls:\n * ```typescript\n * const message = new AIMessage({\n *   content: \"I'll check the weather for you.\",\n *   tool_calls: [{\n *     id: \"call_123\",\n *     name: \"get_weather\",\n *     args: { location: \"San Francisco\" }\n *   }]\n * });\n * const items = convertStandardContentMessageToResponsesInput(message);\n * // Returns:\n * // [\n * //   { type: \"message\", role: \"assistant\", content: [{ type: \"input_text\", text: \"I'll check the weather for you.\" }] },\n * //   { type: \"function_call\", call_id: \"call_123\", name: \"get_weather\", arguments: '{\"location\":\"San Francisco\"}' }\n * // ]\n * ```\n */\nexport const convertStandardContentMessageToResponsesInput: Converter<\n  BaseMessage,\n  OpenAIClient.Responses.ResponseInputItem[]\n> = (message) => {\n  const isResponsesMessage =\n    AIMessage.isInstance(message) &&\n    message.response_metadata?.model_provider === \"openai\";\n\n  function* iterateItems(): Generator<OpenAIClient.Responses.ResponseInputItem> {\n    const messageRole = iife(() => {\n      try {\n        const role = messageToOpenAIRole(message);\n        if (\n          role === \"system\" ||\n          role === \"developer\" ||\n          role === \"assistant\" ||\n          role === \"user\"\n        ) {\n          return role;\n        }\n        return \"assistant\";\n      } catch {\n        return \"assistant\";\n      }\n    });\n\n    let currentMessage: OpenAIClient.Responses.EasyInputMessage | undefined =\n      undefined;\n\n    const functionCallIdsWithBlocks = new Set<string>();\n    const serverFunctionCallIdsWithBlocks = new Set<string>();\n\n    const pendingFunctionChunks = new Map<\n      string,\n      { name?: string; args: string[] }\n    >();\n    const pendingServerFunctionChunks = new Map<\n      string,\n      { name?: string; args: string[] }\n    >();\n\n    function* flushMessage() {\n      if (!currentMessage) return;\n      const content = currentMessage.content;\n      if (\n        (typeof content === \"string\" && content.length > 0) ||\n        (Array.isArray(content) && content.length > 0)\n      ) {\n        yield currentMessage;\n      }\n      currentMessage = undefined;\n    }\n\n    const pushMessageContent: (\n      content: OpenAIClient.Responses.ResponseInputMessageContentList\n    ) => void = (content) => {\n      if (!currentMessage) {\n        currentMessage = {\n          type: \"message\",\n          role: messageRole,\n          content: [],\n        };\n      }\n      if (typeof currentMessage.content === \"string\") {\n        currentMessage.content =\n          currentMessage.content.length > 0\n            ? [{ type: \"input_text\", text: currentMessage.content }, ...content]\n            : [...content];\n      } else {\n        currentMessage.content.push(...content);\n      }\n    };\n\n    const toJsonString = (value: unknown) => {\n      if (typeof value === \"string\") {\n        return value;\n      }\n      try {\n        return JSON.stringify(value ?? {});\n      } catch {\n        return \"{}\";\n      }\n    };\n\n    const resolveImageItem = (\n      block: ContentBlock.Multimodal.Image\n    ): OpenAIClient.Responses.ResponseInputImage | undefined => {\n      const detail = iife(() => {\n        const raw = block.metadata?.detail;\n        if (raw === \"low\" || raw === \"high\" || raw === \"auto\") {\n          return raw;\n        }\n        return \"auto\";\n      });\n      if (block.fileId) {\n        return {\n          type: \"input_image\",\n          detail,\n          file_id: block.fileId,\n        };\n      }\n      if (block.url) {\n        return {\n          type: \"input_image\",\n          detail,\n          image_url: block.url,\n        };\n      }\n      if (block.data) {\n        const base64Data =\n          typeof block.data === \"string\"\n            ? block.data\n            : Buffer.from(block.data).toString(\"base64\");\n        const mimeType = block.mimeType ?? \"image/png\";\n        return {\n          type: \"input_image\",\n          detail,\n          image_url: `data:${mimeType};base64,${base64Data}`,\n        };\n      }\n      return undefined;\n    };\n\n    const resolveFileItem = (\n      block: ContentBlock.Multimodal.File | ContentBlock.Multimodal.Video\n    ): OpenAIClient.Responses.ResponseInputFile | undefined => {\n      const filename = getRequiredFilenameFromMetadata(block);\n\n      if (block.fileId && typeof filename === \"string\") {\n        return {\n          type: \"input_file\",\n          file_id: block.fileId,\n          ...(filename ? { filename } : {}),\n        };\n      }\n      if (block.url && typeof filename === \"string\") {\n        return {\n          type: \"input_file\",\n          file_url: block.url,\n          ...(filename ? { filename } : {}),\n        };\n      }\n      if (block.data && typeof filename === \"string\") {\n        const encoded =\n          typeof block.data === \"string\"\n            ? block.data\n            : Buffer.from(block.data).toString(\"base64\");\n        const mimeType = block.mimeType ?? \"application/octet-stream\";\n        return {\n          type: \"input_file\",\n          file_data: `data:${mimeType};base64,${encoded}`,\n          ...(filename ? { filename } : {}),\n        };\n      }\n      return undefined;\n    };\n\n    const convertReasoningBlock = (\n      block: ContentBlock.Reasoning\n    ): OpenAIClient.Responses.ResponseReasoningItem => {\n      const summaryEntries = iife(() => {\n        if (Array.isArray(block.summary)) {\n          const candidate = block.summary;\n          const mapped =\n            candidate\n              ?.map((item) => item?.text)\n              .filter((text): text is string => typeof text === \"string\") ?? [];\n          if (mapped.length > 0) {\n            return mapped;\n          }\n        }\n        return block.reasoning ? [block.reasoning] : [];\n      });\n\n      const summary =\n        summaryEntries.length > 0\n          ? summaryEntries.map((text) => ({\n              type: \"summary_text\" as const,\n              text,\n            }))\n          : [{ type: \"summary_text\" as const, text: \"\" }];\n\n      const reasoningItem: OpenAIClient.Responses.ResponseReasoningItem = {\n        type: \"reasoning\",\n        id: block.id ?? \"\",\n        summary,\n      };\n\n      if (block.reasoning) {\n        reasoningItem.content = [\n          {\n            type: \"reasoning_text\" as const,\n            text: block.reasoning,\n          },\n        ];\n      }\n      return reasoningItem;\n    };\n\n    const convertFunctionCall = (\n      block: ContentBlock.Tools.ToolCall | ContentBlock.Tools.ServerToolCall\n    ): OpenAIClient.Responses.ResponseFunctionToolCall => ({\n      type: \"function_call\",\n      name: block.name ?? \"\",\n      call_id: block.id ?? \"\",\n      arguments: toJsonString(block.args),\n    });\n\n    const convertFunctionCallOutput = (\n      block: ContentBlock.Tools.ServerToolCallResult\n    ): OpenAIClient.Responses.ResponseInputItem.FunctionCallOutput => {\n      const output = toJsonString(block.output);\n      const status =\n        block.status === \"success\"\n          ? \"completed\"\n          : block.status === \"error\"\n          ? \"incomplete\"\n          : undefined;\n      return {\n        type: \"function_call_output\",\n        call_id: block.toolCallId ?? \"\",\n        output,\n        ...(status ? { status } : {}),\n      };\n    };\n\n    for (const block of message.contentBlocks) {\n      if (block.type === \"text\") {\n        pushMessageContent([{ type: \"input_text\", text: block.text }]);\n      } else if (block.type === \"invalid_tool_call\") {\n        // no-op\n      } else if (block.type === \"reasoning\") {\n        yield* flushMessage();\n        yield convertReasoningBlock(\n          block as ContentBlock.Standard & { type: \"reasoning\" }\n        );\n      } else if (block.type === \"tool_call\") {\n        yield* flushMessage();\n        const id = block.id ?? \"\";\n        if (id) {\n          functionCallIdsWithBlocks.add(id);\n          pendingFunctionChunks.delete(id);\n        }\n        yield convertFunctionCall(\n          block as ContentBlock.Standard & { type: \"tool_call\" }\n        );\n      } else if (block.type === \"tool_call_chunk\") {\n        if (block.id) {\n          const existing = pendingFunctionChunks.get(block.id) ?? {\n            name: block.name,\n            args: [],\n          };\n          if (block.name) existing.name = block.name;\n          if (block.args) existing.args.push(block.args);\n          pendingFunctionChunks.set(block.id, existing);\n        }\n      } else if (block.type === \"server_tool_call\") {\n        yield* flushMessage();\n        const id = block.id ?? \"\";\n        if (id) {\n          serverFunctionCallIdsWithBlocks.add(id);\n          pendingServerFunctionChunks.delete(id);\n        }\n        yield convertFunctionCall(block);\n      } else if (block.type === \"server_tool_call_chunk\") {\n        if (block.id) {\n          const existing = pendingServerFunctionChunks.get(block.id) ?? {\n            name: block.name,\n            args: [],\n          };\n          if (block.name) existing.name = block.name;\n          if (block.args) existing.args.push(block.args);\n          pendingServerFunctionChunks.set(block.id, existing);\n        }\n      } else if (block.type === \"server_tool_call_result\") {\n        yield* flushMessage();\n        yield convertFunctionCallOutput(block);\n      } else if (block.type === \"audio\") {\n        // no-op\n      } else if (block.type === \"file\") {\n        const fileItem = resolveFileItem(block);\n        if (fileItem) {\n          pushMessageContent([fileItem]);\n        }\n      } else if (block.type === \"image\") {\n        const imageItem = resolveImageItem(block);\n        if (imageItem) {\n          pushMessageContent([imageItem]);\n        }\n      } else if (block.type === \"video\") {\n        const videoItem = resolveFileItem(block);\n        if (videoItem) {\n          pushMessageContent([videoItem]);\n        }\n      } else if (block.type === \"text-plain\") {\n        if (block.text) {\n          pushMessageContent([\n            {\n              type: \"input_text\",\n              text: block.text,\n            },\n          ]);\n        }\n      } else if (block.type === \"non_standard\" && isResponsesMessage) {\n        yield* flushMessage();\n        yield block.value as ResponsesInputItem;\n      }\n    }\n    yield* flushMessage();\n\n    for (const [id, chunk] of pendingFunctionChunks) {\n      if (!id || functionCallIdsWithBlocks.has(id)) continue;\n      const args = chunk.args.join(\"\");\n      if (!chunk.name && !args) continue;\n      yield {\n        type: \"function_call\",\n        call_id: id,\n        name: chunk.name ?? \"\",\n        arguments: args,\n      };\n    }\n\n    for (const [id, chunk] of pendingServerFunctionChunks) {\n      if (!id || serverFunctionCallIdsWithBlocks.has(id)) continue;\n      const args = chunk.args.join(\"\");\n      if (!chunk.name && !args) continue;\n      yield {\n        type: \"function_call\",\n        call_id: id,\n        name: chunk.name ?? \"\",\n        arguments: args,\n      };\n    }\n  }\n  return Array.from(iterateItems());\n};\n\n/**\n * - MCP (Model Context Protocol) approval responses\n * - Zero Data Retention (ZDR) mode handling\n *\n * @param params - Conversion parameters\n * @param params.messages - Array of LangChain BaseMessages to convert\n * @param params.zdrEnabled - Whether Zero Data Retention mode is enabled. When true, certain\n *   metadata like message IDs and function call IDs are omitted from the output\n * @param params.model - The model name being used. Used to determine if special role mapping\n *   is needed (e.g., \"system\" -> \"developer\" for reasoning models)\n *\n * @returns Array of ResponsesInputItem objects formatted for the OpenAI Responses API\n *\n * @throws {Error} When a function message is encountered (not supported)\n * @throws {Error} When computer call output format is invalid\n *\n * @example\n * ```typescript\n * const messages = [\n *   new HumanMessage(\"Hello\"),\n *   new AIMessage({ content: \"Hi there!\", tool_calls: [...] })\n * ];\n *\n * const input = convertMessagesToResponsesInput({\n *   messages,\n *   zdrEnabled: false,\n *   model: \"gpt-4\"\n * });\n * ```\n */\nexport const convertMessagesToResponsesInput: Converter<\n  { messages: BaseMessage[]; zdrEnabled: boolean; model: string },\n  ResponsesInputItem[]\n> = ({ messages, zdrEnabled, model }) => {\n  return messages.flatMap(\n    (lcMsg): ResponsesInputItem | ResponsesInputItem[] => {\n      const responseMetadata = lcMsg.response_metadata as\n        | Record<string, unknown>\n        | undefined;\n      if (responseMetadata?.output_version === \"v1\") {\n        return convertStandardContentMessageToResponsesInput(lcMsg);\n      }\n\n      const additional_kwargs = lcMsg.additional_kwargs as\n        | BaseMessageFields[\"additional_kwargs\"] & {\n            [_FUNCTION_CALL_IDS_MAP_KEY]?: Record<string, string>;\n            reasoning?: OpenAIClient.Responses.ResponseReasoningItem;\n            type?: string;\n            refusal?: string;\n          };\n\n      let role = messageToOpenAIRole(lcMsg);\n      if (role === \"system\" && isReasoningModel(model)) role = \"developer\";\n\n      if (role === \"function\") {\n        throw new Error(\"Function messages are not supported in Responses API\");\n      }\n\n      if (role === \"tool\") {\n        const toolMessage = lcMsg as ToolMessage;\n\n        // Handle computer call output\n        if (additional_kwargs?.type === \"computer_call_output\") {\n          const output = (() => {\n            if (typeof toolMessage.content === \"string\") {\n              return {\n                type: \"input_image\" as const,\n                image_url: toolMessage.content,\n              };\n            }\n\n            if (Array.isArray(toolMessage.content)) {\n              /**\n               * Check for input_image type first (computer-use-preview format)\n               */\n              const inputImage = toolMessage.content.find(\n                (i) => i.type === \"input_image\"\n              ) as { type: \"input_image\"; image_url: string } | undefined;\n\n              if (inputImage) return inputImage;\n\n              /**\n               * Check for computer_screenshot type (legacy format)\n               */\n              const oaiScreenshot = toolMessage.content.find(\n                (i) => i.type === \"computer_screenshot\"\n              ) as\n                | { type: \"computer_screenshot\"; image_url: string }\n                | undefined;\n\n              if (oaiScreenshot) return oaiScreenshot;\n\n              /**\n               * Convert image_url content block to input_image format\n               */\n              const lcImage = toolMessage.content.find(\n                (i) => i.type === \"image_url\"\n              ) as MessageContentImageUrl;\n\n              if (lcImage) {\n                return {\n                  type: \"input_image\" as const,\n                  image_url:\n                    typeof lcImage.image_url === \"string\"\n                      ? lcImage.image_url\n                      : lcImage.image_url.url,\n                };\n              }\n            }\n\n            throw new Error(\"Invalid computer call output\");\n          })();\n\n          /**\n           * Cast needed because OpenAI SDK types don't yet include input_image\n           * for computer-use-preview model output format\n           */\n          return {\n            type: \"computer_call_output\",\n            output,\n            call_id: toolMessage.tool_call_id,\n          } as ResponsesInputItem;\n        }\n\n        // Handle custom tool output\n        if (toolMessage.additional_kwargs?.customTool) {\n          return {\n            type: \"custom_tool_call_output\",\n            call_id: toolMessage.tool_call_id,\n            output: toolMessage.content as string,\n          };\n        }\n\n        return {\n          type: \"function_call_output\",\n          call_id: toolMessage.tool_call_id,\n          id: toolMessage.id?.startsWith(\"fc_\") ? toolMessage.id : undefined,\n          output:\n            typeof toolMessage.content !== \"string\"\n              ? JSON.stringify(toolMessage.content)\n              : toolMessage.content,\n        };\n      }\n\n      if (role === \"assistant\") {\n        // if we have the original response items, just reuse them\n        if (\n          !zdrEnabled &&\n          responseMetadata?.output != null &&\n          Array.isArray(responseMetadata?.output) &&\n          responseMetadata?.output.length > 0 &&\n          responseMetadata?.output.every((item) => \"type\" in item)\n        ) {\n          return responseMetadata?.output;\n        }\n\n        // otherwise, try to reconstruct the response from what we have\n\n        const input: ResponsesInputItem[] = [];\n\n        // reasoning items\n        if (additional_kwargs?.reasoning && !zdrEnabled) {\n          const reasoningItem = convertReasoningSummaryToResponsesReasoningItem(\n            additional_kwargs.reasoning\n          );\n          input.push(reasoningItem);\n        }\n\n        // ai content\n        let { content } = lcMsg as { content: ContentBlock[] };\n        if (additional_kwargs?.refusal) {\n          if (typeof content === \"string\") {\n            content = [{ type: \"output_text\", text: content, annotations: [] }];\n          }\n          content = [\n            ...(content as ContentBlock[]),\n            { type: \"refusal\", refusal: additional_kwargs.refusal },\n          ];\n        }\n\n        if (typeof content === \"string\" || content.length > 0) {\n          input.push({\n            type: \"message\",\n            role: \"assistant\",\n            ...(lcMsg.id && !zdrEnabled && lcMsg.id.startsWith(\"msg_\")\n              ? { id: lcMsg.id }\n              : {}),\n            content: iife(() => {\n              if (typeof content === \"string\") {\n                return content;\n              }\n              return content.flatMap((item) => {\n                if (item.type === \"text\") {\n                  return {\n                    type: \"output_text\",\n                    text: item.text,\n                    annotations: item.annotations ?? [],\n                  };\n                }\n\n                if (item.type === \"output_text\" || item.type === \"refusal\") {\n                  return item;\n                }\n\n                return [];\n              });\n            }) as ResponseInputMessageContentList,\n          });\n        }\n\n        const functionCallIds = additional_kwargs?.[_FUNCTION_CALL_IDS_MAP_KEY];\n\n        if (AIMessage.isInstance(lcMsg) && !!lcMsg.tool_calls?.length) {\n          input.push(\n            ...lcMsg.tool_calls.map((toolCall): ResponsesInputItem => {\n              if (isCustomToolCall(toolCall)) {\n                return {\n                  type: \"custom_tool_call\",\n                  id: toolCall.call_id,\n                  call_id: toolCall.id ?? \"\",\n                  input: toolCall.args.input,\n                  name: toolCall.name,\n                };\n              }\n              if (isComputerToolCall(toolCall)) {\n                return {\n                  type: \"computer_call\",\n                  id: toolCall.call_id,\n                  call_id: toolCall.id ?? \"\",\n                  action: toolCall.args.action,\n                } as ResponsesInputItem;\n              }\n              return {\n                type: \"function_call\",\n                name: toolCall.name,\n                arguments: JSON.stringify(toolCall.args),\n                call_id: toolCall.id!,\n                ...(!zdrEnabled ? { id: functionCallIds?.[toolCall.id!] } : {}),\n              };\n            })\n          );\n        } else if (additional_kwargs?.tool_calls) {\n          input.push(\n            ...additional_kwargs.tool_calls.map(\n              (toolCall): ResponsesInputItem => ({\n                type: \"function_call\",\n                name: toolCall.function.name,\n                call_id: toolCall.id,\n                arguments: toolCall.function.arguments,\n                ...(!zdrEnabled ? { id: functionCallIds?.[toolCall.id] } : {}),\n              })\n            )\n          );\n        }\n\n        const toolOutputs = (\n          responseMetadata?.output as Array<ResponsesInputItem>\n        )?.length\n          ? responseMetadata?.output\n          : additional_kwargs.tool_outputs;\n\n        const fallthroughCallTypes: ResponsesInputItem[\"type\"][] = [\n          \"computer_call\",\n          \"mcp_call\",\n          \"code_interpreter_call\",\n          \"image_generation_call\",\n        ];\n\n        if (toolOutputs != null) {\n          const castToolOutputs = toolOutputs as Array<ResponsesInputItem>;\n          const fallthroughCalls = castToolOutputs?.filter((item) =>\n            fallthroughCallTypes.includes(item.type)\n          );\n          if (fallthroughCalls.length > 0) input.push(...fallthroughCalls);\n        }\n\n        return input;\n      }\n\n      if (role === \"user\" || role === \"system\" || role === \"developer\") {\n        if (typeof lcMsg.content === \"string\") {\n          return { type: \"message\", role, content: lcMsg.content };\n        }\n\n        const messages: ResponsesInputItem[] = [];\n        const content = (lcMsg.content as ContentBlock[]).flatMap((item) => {\n          if (item.type === \"mcp_approval_response\") {\n            messages.push({\n              type: \"mcp_approval_response\",\n              approval_request_id: item.approval_request_id as string,\n              approve: item.approve as boolean,\n            });\n          }\n          if (isDataContentBlock(item)) {\n            return convertToProviderContentBlock(\n              item,\n              completionsApiContentBlockConverter\n            );\n          }\n          if (item.type === \"text\") {\n            return {\n              type: \"input_text\",\n              text: item.text,\n            };\n          }\n          if (item.type === \"image_url\") {\n            const imageUrl = iife(() => {\n              if (typeof item.image_url === \"string\") {\n                return item.image_url;\n              } else if (\n                typeof item.image_url === \"object\" &&\n                item.image_url !== null &&\n                \"url\" in item.image_url\n              ) {\n                return item.image_url.url;\n              }\n              return undefined;\n            });\n            const detail = iife(() => {\n              if (typeof item.image_url === \"string\") {\n                return \"auto\";\n              } else if (\n                typeof item.image_url === \"object\" &&\n                item.image_url !== null &&\n                \"detail\" in item.image_url\n              ) {\n                return item.image_url.detail;\n              }\n              return undefined;\n            });\n            return {\n              type: \"input_image\",\n              image_url: imageUrl,\n              detail,\n            };\n          }\n          if (\n            item.type === \"input_text\" ||\n            item.type === \"input_image\" ||\n            item.type === \"input_file\"\n          ) {\n            return item;\n          }\n          return [];\n        });\n\n        if (content.length > 0) {\n          messages.push({\n            type: \"message\",\n            role,\n            content: content as ResponseInputMessageContentList,\n          });\n        }\n        return messages;\n      }\n\n      console.warn(\n        `Unsupported role found when converting to OpenAI Responses API: ${role}`\n      );\n      return [];\n    }\n  );\n};\n"],"mappings":";;;;;;;;AAyCA,MAAM,6BAA6B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkEnC,MAAaA,uCAGT,CAAC,UAAU;CACb,MAAM,oBAAoB,EACxB,GAAI,OAAO,sBAAsB,iBAAiB,QAAQ,EACxD,YAAY,OAAO,sBAAsB,cAC1C,EACF;CACD,MAAM,qBAAqB,EACzB,GAAI,OAAO,uBAAuB,oBAAoB,QAAQ,EAC5D,WAAW,OAAO,uBAAuB,iBAC1C,EACF;AACD,QAAO;EACL,cAAc,OAAO,gBAAgB;EACrC,eAAe,OAAO,iBAAiB;EACvC,cAAc,OAAO,gBAAgB;EACrC,qBAAqB;EACrB,sBAAsB;CACvB;AACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmDD,MAAaC,qCAGT,CAAC,aAAa;AAChB,KAAI,SAAS,OAAO;EAElB,MAAM,QAAQ,IAAI,MAAM,SAAS,MAAM;EACvC,MAAM,OAAO,SAAS,MAAM;AAC5B,QAAM;CACP;CAED,IAAIC;CACJ,MAAMC,UAA0B,CAAE;CAClC,MAAMC,aAAyB,CAAE;CACjC,MAAMC,qBAAwC,CAAE;CAChD,MAAMC,oBAA6C;EACjD,gBAAgB;EAChB,OAAO,SAAS;EAChB,YAAY,SAAS;EACrB,IAAI,SAAS;EACb,oBAAoB,SAAS;EAC7B,UAAU,SAAS;EACnB,QAAQ,SAAS;EACjB,QAAQ,SAAS;EACjB,MAAM,SAAS;EACf,cAAc,SAAS;EAEvB,YAAY,SAAS;CACtB;CAED,MAAMC,oBAOF,CAAE;AAEN,MAAK,MAAM,QAAQ,SAAS,OAC1B,KAAI,KAAK,SAAS,WAAW;EAC3B,YAAY,KAAK;EACjB,QAAQ,KACN,GAAG,KAAK,QAAQ,QAAQ,CAAC,SAAS;AAChC,OAAI,KAAK,SAAS,eAAe;AAC/B,QAAI,YAAY,QAAQ,KAAK,UAAU,MACrC,kBAAkB,SAAS,KAAK;AAElC,WAAO;KACL,MAAM;KACN,MAAM,KAAK;KACX,aAAa,KAAK;IACnB;GACF;AAED,OAAI,KAAK,SAAS,WAAW;IAC3B,kBAAkB,UAAU,KAAK;AACjC,WAAO,CAAE;GACV;AAED,UAAO;EACR,EAAC,CACH;CACF,WAAU,KAAK,SAAS,iBAAiB;EACxC,MAAM,YAAY;GAChB,UAAU;IAAE,MAAM,KAAK;IAAM,WAAW,KAAK;GAAW;GACxD,IAAI,KAAK;EACV;AAED,MAAI;GACF,WAAW,KAAK,cAAc,WAAW,EAAE,UAAU,KAAM,EAAC,CAAC;EAC9D,SAAQC,GAAY;GACnB,IAAIC;AACJ,OACE,OAAO,MAAM,YACb,KAAK,QACL,aAAa,KACb,OAAO,EAAE,YAAY,UAErB,aAAa,EAAE;GAEjB,mBAAmB,KAAK,oBAAoB,WAAW,WAAW,CAAC;EACpE;EAED,kBAAkB,gCAAgC,CAAE;AACpD,MAAI,KAAK,IACP,kBAAkB,4BAA4B,KAAK,WAAW,KAAK;CAEtE,WAAU,KAAK,SAAS,aACvB,kBAAkB,YAAY;UACrB,KAAK,SAAS,oBAAoB;EAC3C,MAAM,SAAS,oBAAoB,KAAK;AACxC,MAAI,QACF,WAAW,KAAK,OAAO;OAEvB,mBAAmB,KACjB,oBAAoB,MAAM,6BAA6B,CACxD;CAEJ,WAAU,KAAK,SAAS,iBAAiB;EACxC,MAAM,SAAS,kBAAkB,KAAK;AACtC,MAAI,QACF,WAAW,KAAK,OAAO;OAEvB,mBAAmB,KACjB,oBAAoB,MAAM,0BAA0B,CACrD;CAEJ,OAAM;EACL,kBAAkB,iBAAiB,CAAE;EACrC,kBAAkB,aAAa,KAAK,KAAK;CAC1C;AAGH,QAAO,IAAI,UAAU;EACnB,IAAI;EACJ;EACA;EACA;EACA,gBAAgB,qCAAqC,SAAS,MAAM;EACpE;EACA;CACD;AACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6DD,MAAaC,kDAGT,CAAC,cAAc;CAEjB,MAAM,WACJ,UAAU,QAAQ,SAAS,IACvB,UAAU,QAAQ,OAChB,CAAC,KAAK,SAAS;EACb,MAAM,OAAO,IAAI,IAAI,SAAS;AAE9B,MAAI,KAAM,UAAU,KAAK,OACvB,KAAM,QAAQ,KAAK;OAEnB,IAAI,KAAK,KAAK;AAEhB,SAAO;CACR,GACD,CAAC,EAAE,GAAG,UAAU,QAAQ,GAAI,CAAC,EAC9B,GACD,UAAU,SACd,IAAI,CAAC,MACL,OAAO,YAAY,OAAO,QAAQ,EAAE,CAAC,OAAO,CAAC,CAAC,EAAE,KAAK,MAAM,QAAQ,CAAC,CACrE;AAED,QAAO;EACL,GAAG;EACH;CACD;AACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyDD,MAAaC,6CAGT,CAAC,UAAU;CACb,MAAMC,UAAqC,CAAE;CAC7C,IAAIC,iBAA0C,CAAE;CAChD,IAAIC;CACJ,MAAMC,mBAAoC,CAAE;CAC5C,MAAMT,oBAA6C,EACjD,gBAAgB,SACjB;CACD,MAAMU,oBAIF,CAAE;CACN,IAAIC;AACJ,KAAI,MAAM,SAAS,8BACjB,QAAQ,KAAK;EACX,MAAM;EACN,MAAM,MAAM;EACZ,OAAO,MAAM;CACd,EAAC;UACO,MAAM,SAAS,yCACxB,QAAQ,KAAK;EACX,MAAM;EACN,MAAM;EACN,aAAa,CAAC,MAAM,UAAW;EAC/B,OAAO,MAAM;CACd,EAAC;UAEF,MAAM,SAAS,gCACf,MAAM,KAAK,SAAS,WAEpB,KAAK,MAAM,KAAK;UAEhB,MAAM,SAAS,gCACf,MAAM,KAAK,SAAS,iBACpB;EACA,iBAAiB,KAAK;GACpB,MAAM;GACN,MAAM,MAAM,KAAK;GACjB,MAAM,MAAM,KAAK;GACjB,IAAI,MAAM,KAAK;GACf,OAAO,MAAM;EACd,EAAC;EAEF,kBAAkB,8BAA8B,GAC7C,MAAM,KAAK,UAAU,MAAM,KAAK,GAClC;CACF,WACC,MAAM,SAAS,+BACf,MAAM,KAAK,SAAS,iBACpB;EAEA,iBAAiB,KAAK;GACpB,MAAM;GACN,MAAM;GACN,MAAM,KAAK,UAAU,EAAE,QAAQ,MAAM,KAAK,OAAQ,EAAC;GACnD,IAAI,MAAM,KAAK;GACf,OAAO,MAAM;EACd,EAAC;EAEF,kBAAkB,eAAe,CAAC,MAAM,IAAK;CAC9C,WACC,MAAM,SAAS,+BACf;EACE;EACA;EACA;EACA;EACA;EACA;EACA;EACA;CACD,EAAC,SAAS,MAAM,KAAK,KAAK,EAE3B,kBAAkB,eAAe,CAAC,MAAM,IAAK;UACpC,MAAM,SAAS,oBAAoB;EAC5C,kBAAkB,KAAK,MAAM,SAAS;EACtC,kBAAkB,aAAa,MAAM,SAAS;EAC9C,kBAAkB,QAAQ,MAAM,SAAS;CAC1C,WAAU,MAAM,SAAS,sBAAsB;EAC9C,MAAM,MAAM,mCAAmC,MAAM,SAAS;EAE9D,iBAAiB,qCAAqC,MAAM,SAAS,MAAM;AAE3E,MAAI,MAAM,SAAS,MAAM,QAAQ,SAAS,eACxC,kBAAkB,WAAW,KAAK,MAAM,IAAI,KAAK;AAEnD,OAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAO,QAAQ,MAAM,SAAS,CACvD,KAAI,QAAQ,MAAM,kBAAkB,OAAO;CAE9C,WACC,MAAM,SAAS,4CACf,MAAM,SAAS,yCAEf,iBAAiB,KAAK;EACpB,MAAM;EACN,MAAM,MAAM;EACZ,OAAO,MAAM;CACd,EAAC;UAEF,MAAM,SAAS,wCACf,MAAM,SAAS,uCAEf,iBAAiB,EACf,cAAc;EACZ,IAAI,MAAM;EACV,MAAM,MAAM,KAAK,QAAQ,aAAa,GAAG,CAAC,QAAQ,cAAc,GAAG;EACnE,QAAQ;CACT,EACF;UACQ,MAAM,SAAS,yBACxB,kBAAkB,UAAU,MAAM;UAElC,MAAM,SAAS,gCACf,UAAU,SACV,MAAM,KAAK,SAAS,aACpB;EACA,MAAMC,UAA6D,MAChE,KAAK,UACJ,MAAM,KAAK,QAAQ,IAAI,CAAC,GAAG,WAAW;GACpC,GAAG;GACH;EACD,GAAE,GACH;EAEJ,kBAAkB,YAAY;GAI5B,IAAI,MAAM,KAAK;GACf,MAAM,MAAM,KAAK;GACjB,GAAI,UAAU,EAAE,QAAS,IAAG,CAAE;EAC/B;CACF,WAAU,MAAM,SAAS,yCACxB,kBAAkB,YAAY;EAC5B,MAAM;EACN,SAAS,CAAC;GAAE,GAAG,MAAM;GAAM,OAAO,MAAM;EAAe,CAAC;CACzD;UACQ,MAAM,SAAS,yCACxB,kBAAkB,YAAY;EAC5B,MAAM;EACN,SAAS,CACP;GACE,MAAM,MAAM;GACZ,MAAM;GACN,OAAO,MAAM;EACd,CACF;CACF;UACQ,MAAM,SAAS,+CAGxB,QAAO;KAEP,QAAO;AAGT,QAAO,IAAI,oBAAoB;EAE7B,MAAM,QAAQ,IAAI,CAAC,SAAS,KAAK,KAAK,CAAC,KAAK,GAAG;EAC/C,SAAS,IAAI,eAAe;GAC1B;GACS;GACT;GACA;GACA;GACA;EACD;EACD;CACD;AACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyCD,MAAaC,gDAGT,CAAC,YAAY;CACf,MAAM,qBACJ,UAAU,WAAW,QAAQ,IAC7B,QAAQ,mBAAmB,mBAAmB;CAEhD,UAAU,eAAoE;EAC5E,MAAM,cAAc,KAAK,MAAM;AAC7B,OAAI;IACF,MAAM,OAAO,oBAAoB,QAAQ;AACzC,QACE,SAAS,YACT,SAAS,eACT,SAAS,eACT,SAAS,OAET,QAAO;AAET,WAAO;GACR,QAAO;AACN,WAAO;GACR;EACF,EAAC;EAEF,IAAIC,iBACF;EAEF,MAAM,4CAA4B,IAAI;EACtC,MAAM,kDAAkC,IAAI;EAE5C,MAAM,wCAAwB,IAAI;EAIlC,MAAM,8CAA8B,IAAI;EAKxC,UAAU,eAAe;AACvB,OAAI,CAAC,eAAgB;GACrB,MAAM,UAAU,eAAe;AAC/B,OACG,OAAO,YAAY,YAAY,QAAQ,SAAS,KAChD,MAAM,QAAQ,QAAQ,IAAI,QAAQ,SAAS,GAE5C,MAAM;GAER,iBAAiB;EAClB;EAED,MAAMC,qBAEM,CAAC,YAAY;AACvB,OAAI,CAAC,gBACH,iBAAiB;IACf,MAAM;IACN,MAAM;IACN,SAAS,CAAE;GACZ;AAEH,OAAI,OAAO,eAAe,YAAY,UACpC,eAAe,UACb,eAAe,QAAQ,SAAS,IAC5B,CAAC;IAAE,MAAM;IAAc,MAAM,eAAe;GAAS,GAAE,GAAG,OAAQ,IAClE,CAAC,GAAG,OAAQ;QAElB,eAAe,QAAQ,KAAK,GAAG,QAAQ;EAE1C;EAED,MAAM,eAAe,CAACC,UAAmB;AACvC,OAAI,OAAO,UAAU,SACnB,QAAO;AAET,OAAI;AACF,WAAO,KAAK,UAAU,SAAS,CAAE,EAAC;GACnC,QAAO;AACN,WAAO;GACR;EACF;EAED,MAAM,mBAAmB,CACvBC,UAC0D;GAC1D,MAAM,SAAS,KAAK,MAAM;IACxB,MAAM,MAAM,MAAM,UAAU;AAC5B,QAAI,QAAQ,SAAS,QAAQ,UAAU,QAAQ,OAC7C,QAAO;AAET,WAAO;GACR,EAAC;AACF,OAAI,MAAM,OACR,QAAO;IACL,MAAM;IACN;IACA,SAAS,MAAM;GAChB;AAEH,OAAI,MAAM,IACR,QAAO;IACL,MAAM;IACN;IACA,WAAW,MAAM;GAClB;AAEH,OAAI,MAAM,MAAM;IACd,MAAM,aACJ,OAAO,MAAM,SAAS,WAClB,MAAM,OACN,OAAO,KAAK,MAAM,KAAK,CAAC,SAAS,SAAS;IAChD,MAAM,WAAW,MAAM,YAAY;AACnC,WAAO;KACL,MAAM;KACN;KACA,WAAW,CAAC,KAAK,EAAE,SAAS,QAAQ,EAAE,YAAY;IACnD;GACF;AACD,UAAO;EACR;EAED,MAAM,kBAAkB,CACtBC,UACyD;GACzD,MAAM,WAAW,gCAAgC,MAAM;AAEvD,OAAI,MAAM,UAAU,OAAO,aAAa,SACtC,QAAO;IACL,MAAM;IACN,SAAS,MAAM;IACf,GAAI,WAAW,EAAE,SAAU,IAAG,CAAE;GACjC;AAEH,OAAI,MAAM,OAAO,OAAO,aAAa,SACnC,QAAO;IACL,MAAM;IACN,UAAU,MAAM;IAChB,GAAI,WAAW,EAAE,SAAU,IAAG,CAAE;GACjC;AAEH,OAAI,MAAM,QAAQ,OAAO,aAAa,UAAU;IAC9C,MAAM,UACJ,OAAO,MAAM,SAAS,WAClB,MAAM,OACN,OAAO,KAAK,MAAM,KAAK,CAAC,SAAS,SAAS;IAChD,MAAM,WAAW,MAAM,YAAY;AACnC,WAAO;KACL,MAAM;KACN,WAAW,CAAC,KAAK,EAAE,SAAS,QAAQ,EAAE,SAAS;KAC/C,GAAI,WAAW,EAAE,SAAU,IAAG,CAAE;IACjC;GACF;AACD,UAAO;EACR;EAED,MAAM,wBAAwB,CAC5BC,UACiD;GACjD,MAAM,iBAAiB,KAAK,MAAM;AAChC,QAAI,MAAM,QAAQ,MAAM,QAAQ,EAAE;KAChC,MAAM,YAAY,MAAM;KACxB,MAAM,SACJ,WACI,IAAI,CAAC,SAAS,MAAM,KAAK,CAC1B,OAAO,CAAC,SAAyB,OAAO,SAAS,SAAS,IAAI,CAAE;AACrE,SAAI,OAAO,SAAS,EAClB,QAAO;IAEV;AACD,WAAO,MAAM,YAAY,CAAC,MAAM,SAAU,IAAG,CAAE;GAChD,EAAC;GAEF,MAAM,UACJ,eAAe,SAAS,IACpB,eAAe,IAAI,CAAC,UAAU;IAC5B,MAAM;IACN;GACD,GAAE,GACH,CAAC;IAAE,MAAM;IAAyB,MAAM;GAAI,CAAC;GAEnD,MAAMC,gBAA8D;IAClE,MAAM;IACN,IAAI,MAAM,MAAM;IAChB;GACD;AAED,OAAI,MAAM,WACR,cAAc,UAAU,CACtB;IACE,MAAM;IACN,MAAM,MAAM;GACb,CACF;AAEH,UAAO;EACR;EAED,MAAM,sBAAsB,CAC1BC,WACqD;GACrD,MAAM;GACN,MAAM,MAAM,QAAQ;GACpB,SAAS,MAAM,MAAM;GACrB,WAAW,aAAa,MAAM,KAAK;EACpC;EAED,MAAM,4BAA4B,CAChCC,UACgE;GAChE,MAAM,SAAS,aAAa,MAAM,OAAO;GACzC,MAAM,SACJ,MAAM,WAAW,YACb,cACA,MAAM,WAAW,UACjB,eACA;AACN,UAAO;IACL,MAAM;IACN,SAAS,MAAM,cAAc;IAC7B;IACA,GAAI,SAAS,EAAE,OAAQ,IAAG,CAAE;GAC7B;EACF;AAED,OAAK,MAAM,SAAS,QAAQ,cAC1B,KAAI,MAAM,SAAS,QACjB,mBAAmB,CAAC;GAAE,MAAM;GAAc,MAAM,MAAM;EAAM,CAAC,EAAC;WACrD,MAAM,SAAS,qBAAqB,CAE9C,WAAU,MAAM,SAAS,aAAa;GACrC,OAAO,cAAc;GACrB,MAAM,sBACJ,MACD;EACF,WAAU,MAAM,SAAS,aAAa;GACrC,OAAO,cAAc;GACrB,MAAM,KAAK,MAAM,MAAM;AACvB,OAAI,IAAI;IACN,0BAA0B,IAAI,GAAG;IACjC,sBAAsB,OAAO,GAAG;GACjC;GACD,MAAM,oBACJ,MACD;EACF,WAAU,MAAM,SAAS,mBACxB;OAAI,MAAM,IAAI;IACZ,MAAM,WAAW,sBAAsB,IAAI,MAAM,GAAG,IAAI;KACtD,MAAM,MAAM;KACZ,MAAM,CAAE;IACT;AACD,QAAI,MAAM,MAAM,SAAS,OAAO,MAAM;AACtC,QAAI,MAAM,MAAM,SAAS,KAAK,KAAK,MAAM,KAAK;IAC9C,sBAAsB,IAAI,MAAM,IAAI,SAAS;GAC9C;aACQ,MAAM,SAAS,oBAAoB;GAC5C,OAAO,cAAc;GACrB,MAAM,KAAK,MAAM,MAAM;AACvB,OAAI,IAAI;IACN,gCAAgC,IAAI,GAAG;IACvC,4BAA4B,OAAO,GAAG;GACvC;GACD,MAAM,oBAAoB,MAAM;EACjC,WAAU,MAAM,SAAS,0BACxB;OAAI,MAAM,IAAI;IACZ,MAAM,WAAW,4BAA4B,IAAI,MAAM,GAAG,IAAI;KAC5D,MAAM,MAAM;KACZ,MAAM,CAAE;IACT;AACD,QAAI,MAAM,MAAM,SAAS,OAAO,MAAM;AACtC,QAAI,MAAM,MAAM,SAAS,KAAK,KAAK,MAAM,KAAK;IAC9C,4BAA4B,IAAI,MAAM,IAAI,SAAS;GACpD;aACQ,MAAM,SAAS,2BAA2B;GACnD,OAAO,cAAc;GACrB,MAAM,0BAA0B,MAAM;EACvC,WAAU,MAAM,SAAS,SAAS,CAElC,WAAU,MAAM,SAAS,QAAQ;GAChC,MAAM,WAAW,gBAAgB,MAAM;AACvC,OAAI,UACF,mBAAmB,CAAC,QAAS,EAAC;EAEjC,WAAU,MAAM,SAAS,SAAS;GACjC,MAAM,YAAY,iBAAiB,MAAM;AACzC,OAAI,WACF,mBAAmB,CAAC,SAAU,EAAC;EAElC,WAAU,MAAM,SAAS,SAAS;GACjC,MAAM,YAAY,gBAAgB,MAAM;AACxC,OAAI,WACF,mBAAmB,CAAC,SAAU,EAAC;EAElC,WAAU,MAAM,SAAS,cACxB;OAAI,MAAM,MACR,mBAAmB,CACjB;IACE,MAAM;IACN,MAAM,MAAM;GACb,CACF,EAAC;EACH,WACQ,MAAM,SAAS,kBAAkB,oBAAoB;GAC9D,OAAO,cAAc;GACrB,MAAM,MAAM;EACb;EAEH,OAAO,cAAc;AAErB,OAAK,MAAM,CAAC,IAAI,MAAM,IAAI,uBAAuB;AAC/C,OAAI,CAAC,MAAM,0BAA0B,IAAI,GAAG,CAAE;GAC9C,MAAM,OAAO,MAAM,KAAK,KAAK,GAAG;AAChC,OAAI,CAAC,MAAM,QAAQ,CAAC,KAAM;GAC1B,MAAM;IACJ,MAAM;IACN,SAAS;IACT,MAAM,MAAM,QAAQ;IACpB,WAAW;GACZ;EACF;AAED,OAAK,MAAM,CAAC,IAAI,MAAM,IAAI,6BAA6B;AACrD,OAAI,CAAC,MAAM,gCAAgC,IAAI,GAAG,CAAE;GACpD,MAAM,OAAO,MAAM,KAAK,KAAK,GAAG;AAChC,OAAI,CAAC,MAAM,QAAQ,CAAC,KAAM;GAC1B,MAAM;IACJ,MAAM;IACN,SAAS;IACT,MAAM,MAAM,QAAQ;IACpB,WAAW;GACZ;EACF;CACF;AACD,QAAO,MAAM,KAAK,cAAc,CAAC;AAClC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCD,MAAaC,kCAGT,CAAC,EAAE,UAAU,YAAY,OAAO,KAAK;AACvC,QAAO,SAAS,QACd,CAAC,UAAqD;EACpD,MAAM,mBAAmB,MAAM;AAG/B,MAAI,kBAAkB,mBAAmB,KACvC,QAAO,8CAA8C,MAAM;EAG7D,MAAM,oBAAoB,MAAM;EAQhC,IAAI,OAAO,oBAAoB,MAAM;AACrC,MAAI,SAAS,YAAY,iBAAiB,MAAM,EAAE,OAAO;AAEzD,MAAI,SAAS,WACX,OAAM,IAAI,MAAM;AAGlB,MAAI,SAAS,QAAQ;GACnB,MAAM,cAAc;AAGpB,OAAI,mBAAmB,SAAS,wBAAwB;IACtD,MAAM,UAAU,MAAM;AACpB,SAAI,OAAO,YAAY,YAAY,SACjC,QAAO;MACL,MAAM;MACN,WAAW,YAAY;KACxB;AAGH,SAAI,MAAM,QAAQ,YAAY,QAAQ,EAAE;;;;MAItC,MAAM,aAAa,YAAY,QAAQ,KACrC,CAAC,MAAM,EAAE,SAAS,cACnB;AAED,UAAI,WAAY,QAAO;;;;MAKvB,MAAM,gBAAgB,YAAY,QAAQ,KACxC,CAAC,MAAM,EAAE,SAAS,sBACnB;AAID,UAAI,cAAe,QAAO;;;;MAK1B,MAAM,UAAU,YAAY,QAAQ,KAClC,CAAC,MAAM,EAAE,SAAS,YACnB;AAED,UAAI,QACF,QAAO;OACL,MAAM;OACN,WACE,OAAO,QAAQ,cAAc,WACzB,QAAQ,YACR,QAAQ,UAAU;MACzB;KAEJ;AAED,WAAM,IAAI,MAAM;IACjB,IAAG;;;;;AAMJ,WAAO;KACL,MAAM;KACN;KACA,SAAS,YAAY;IACtB;GACF;AAGD,OAAI,YAAY,mBAAmB,WACjC,QAAO;IACL,MAAM;IACN,SAAS,YAAY;IACrB,QAAQ,YAAY;GACrB;AAGH,UAAO;IACL,MAAM;IACN,SAAS,YAAY;IACrB,IAAI,YAAY,IAAI,WAAW,MAAM,GAAG,YAAY,KAAK;IACzD,QACE,OAAO,YAAY,YAAY,WAC3B,KAAK,UAAU,YAAY,QAAQ,GACnC,YAAY;GACnB;EACF;AAED,MAAI,SAAS,aAAa;AAExB,OACE,CAAC,cACD,kBAAkB,UAAU,QAC5B,MAAM,QAAQ,kBAAkB,OAAO,IACvC,kBAAkB,OAAO,SAAS,KAClC,kBAAkB,OAAO,MAAM,CAAC,SAAS,UAAU,KAAK,CAExD,QAAO,kBAAkB;GAK3B,MAAMC,QAA8B,CAAE;AAGtC,OAAI,mBAAmB,aAAa,CAAC,YAAY;IAC/C,MAAM,gBAAgB,gDACpB,kBAAkB,UACnB;IACD,MAAM,KAAK,cAAc;GAC1B;GAGD,IAAI,EAAE,SAAS,GAAG;AAClB,OAAI,mBAAmB,SAAS;AAC9B,QAAI,OAAO,YAAY,UACrB,UAAU,CAAC;KAAE,MAAM;KAAe,MAAM;KAAS,aAAa,CAAE;IAAE,CAAC;IAErE,UAAU,CACR,GAAI,SACJ;KAAE,MAAM;KAAW,SAAS,kBAAkB;IAAS,CACxD;GACF;AAED,OAAI,OAAO,YAAY,YAAY,QAAQ,SAAS,GAClD,MAAM,KAAK;IACT,MAAM;IACN,MAAM;IACN,GAAI,MAAM,MAAM,CAAC,cAAc,MAAM,GAAG,WAAW,OAAO,GACtD,EAAE,IAAI,MAAM,GAAI,IAChB,CAAE;IACN,SAAS,KAAK,MAAM;AAClB,SAAI,OAAO,YAAY,SACrB,QAAO;AAET,YAAO,QAAQ,QAAQ,CAAC,SAAS;AAC/B,UAAI,KAAK,SAAS,OAChB,QAAO;OACL,MAAM;OACN,MAAM,KAAK;OACX,aAAa,KAAK,eAAe,CAAE;MACpC;AAGH,UAAI,KAAK,SAAS,iBAAiB,KAAK,SAAS,UAC/C,QAAO;AAGT,aAAO,CAAE;KACV,EAAC;IACH,EAAC;GACH,EAAC;GAGJ,MAAM,kBAAkB,oBAAoB;AAE5C,OAAI,UAAU,WAAW,MAAM,IAAI,CAAC,CAAC,MAAM,YAAY,QACrD,MAAM,KACJ,GAAG,MAAM,WAAW,IAAI,CAAC,aAAiC;AACxD,QAAI,iBAAiB,SAAS,CAC5B,QAAO;KACL,MAAM;KACN,IAAI,SAAS;KACb,SAAS,SAAS,MAAM;KACxB,OAAO,SAAS,KAAK;KACrB,MAAM,SAAS;IAChB;AAEH,QAAI,mBAAmB,SAAS,CAC9B,QAAO;KACL,MAAM;KACN,IAAI,SAAS;KACb,SAAS,SAAS,MAAM;KACxB,QAAQ,SAAS,KAAK;IACvB;AAEH,WAAO;KACL,MAAM;KACN,MAAM,SAAS;KACf,WAAW,KAAK,UAAU,SAAS,KAAK;KACxC,SAAS,SAAS;KAClB,GAAI,CAAC,aAAa,EAAE,IAAI,kBAAkB,SAAS,IAAM,IAAG,CAAE;IAC/D;GACF,EAAC,CACH;YACQ,mBAAmB,YAC5B,MAAM,KACJ,GAAG,kBAAkB,WAAW,IAC9B,CAAC,cAAkC;IACjC,MAAM;IACN,MAAM,SAAS,SAAS;IACxB,SAAS,SAAS;IAClB,WAAW,SAAS,SAAS;IAC7B,GAAI,CAAC,aAAa,EAAE,IAAI,kBAAkB,SAAS,IAAK,IAAG,CAAE;GAC9D,GACF,CACF;GAGH,MAAM,eACJ,kBAAkB,SACjB,SACC,kBAAkB,SAClB,kBAAkB;GAEtB,MAAMC,uBAAqD;IACzD;IACA;IACA;IACA;GACD;AAED,OAAI,eAAe,MAAM;IACvB,MAAM,kBAAkB;IACxB,MAAM,mBAAmB,iBAAiB,OAAO,CAAC,SAChD,qBAAqB,SAAS,KAAK,KAAK,CACzC;AACD,QAAI,iBAAiB,SAAS,GAAG,MAAM,KAAK,GAAG,iBAAiB;GACjE;AAED,UAAO;EACR;AAED,MAAI,SAAS,UAAU,SAAS,YAAY,SAAS,aAAa;AAChE,OAAI,OAAO,MAAM,YAAY,SAC3B,QAAO;IAAE,MAAM;IAAW;IAAM,SAAS,MAAM;GAAS;GAG1D,MAAMC,aAAiC,CAAE;GACzC,MAAM,UAAW,MAAM,QAA2B,QAAQ,CAAC,SAAS;AAClE,QAAI,KAAK,SAAS,yBAChBC,WAAS,KAAK;KACZ,MAAM;KACN,qBAAqB,KAAK;KAC1B,SAAS,KAAK;IACf,EAAC;AAEJ,QAAI,mBAAmB,KAAK,CAC1B,QAAO,8BACL,MACA,oCACD;AAEH,QAAI,KAAK,SAAS,OAChB,QAAO;KACL,MAAM;KACN,MAAM,KAAK;IACZ;AAEH,QAAI,KAAK,SAAS,aAAa;KAC7B,MAAM,WAAW,KAAK,MAAM;AAC1B,UAAI,OAAO,KAAK,cAAc,SAC5B,QAAO,KAAK;eAEZ,OAAO,KAAK,cAAc,YAC1B,KAAK,cAAc,QACnB,SAAS,KAAK,UAEd,QAAO,KAAK,UAAU;AAExB,aAAO;KACR,EAAC;KACF,MAAM,SAAS,KAAK,MAAM;AACxB,UAAI,OAAO,KAAK,cAAc,SAC5B,QAAO;eAEP,OAAO,KAAK,cAAc,YAC1B,KAAK,cAAc,QACnB,YAAY,KAAK,UAEjB,QAAO,KAAK,UAAU;AAExB,aAAO;KACR,EAAC;AACF,YAAO;MACL,MAAM;MACN,WAAW;MACX;KACD;IACF;AACD,QACE,KAAK,SAAS,gBACd,KAAK,SAAS,iBACd,KAAK,SAAS,aAEd,QAAO;AAET,WAAO,CAAE;GACV,EAAC;AAEF,OAAI,QAAQ,SAAS,GACnBA,WAAS,KAAK;IACZ,MAAM;IACN;IACS;GACV,EAAC;AAEJ,UAAOA;EACR;EAED,QAAQ,KACN,CAAC,gEAAgE,EAAE,MAAM,CAC1E;AACD,SAAO,CAAE;CACV,EACF;AACF"}