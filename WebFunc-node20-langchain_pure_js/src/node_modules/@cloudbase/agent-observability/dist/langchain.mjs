import {
  init_src,
  startObservation
} from "./chunk-ZGEMAYS4.mjs";
import "./chunk-NFEGQTCC.mjs";

// src/langchain/CallbackHandler.ts
init_src();
import { BaseCallbackHandler } from "@langchain/core/callbacks/base";
import {
  AIMessage,
  AIMessageChunk,
  BaseMessage
} from "@langchain/core/messages";
import { noopLogger } from "@cloudbase/agent-shared";
var CallbackHandler = class extends BaseCallbackHandler {
  name = "ObservabilityCallbackHandler";
  userId;
  version;
  sessionId;
  tags;
  traceMetadata;
  completionStartTimes = {};
  promptToParentRunMap;
  runMap = /* @__PURE__ */ new Map();
  last_trace_id = null;
  // External parent context from AG-UI.Server span
  externalParentSpanContext;
  // Adapter name for ROOT span prefix
  adapterName;
  // Logger for debug output (defaults to noopLogger for silent operation)
  logger;
  constructor(params) {
    super();
    this.sessionId = params?.sessionId;
    this.userId = params?.userId;
    this.tags = params?.tags ?? [];
    this.traceMetadata = params?.traceMetadata;
    this.version = params?.version;
    this.adapterName = params?.adapterName;
    this.logger = params?.logger ?? noopLogger;
    this.promptToParentRunMap = /* @__PURE__ */ new Map();
  }
  /**
   * Set external parent SpanContext from AG-UI.Server span.
   * This allows the CallbackHandler to link LangChain/LangGraph spans
   * to the server-level span, creating a unified trace hierarchy.
   *
   * @param spanContext - SpanContext from the AG-UI.Server span
   * @public
   */
  setExternalParentContext(spanContext) {
    this.externalParentSpanContext = spanContext;
  }
  async handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, _fields) {
    if (runId && !(runId in this.completionStartTimes)) {
      this.logger.debug?.(`LLM first streaming token: ${runId}`);
      this.completionStartTimes[runId] = /* @__PURE__ */ new Date();
    }
  }
  async handleChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, name) {
    try {
      this.logger.debug?.(`Chain start with Id: ${runId}`);
      const runName = name ?? chain.id.at(-1)?.toString() ?? "Langchain Run";
      this.registerPromptInfo(parentRunId, metadata);
      let finalInput = inputs;
      if (typeof inputs === "object" && "input" in inputs && Array.isArray(inputs["input"]) && inputs["input"].every((m) => m instanceof BaseMessage)) {
        finalInput = inputs["input"].map(
          (m) => this.extractChatMessageContent(m)
        );
      } else if (typeof inputs === "object" && "messages" in inputs && Array.isArray(inputs["messages"]) && inputs["messages"].every((m) => m instanceof BaseMessage)) {
        finalInput = inputs["messages"].map(
          (m) => this.extractChatMessageContent(m)
        );
      } else if (typeof inputs === "object" && "content" in inputs && typeof inputs["content"] === "string") {
        finalInput = inputs["content"];
      }
      const observation = this.startAndRegisterObservation({
        runName,
        parentRunId,
        runId,
        tags,
        metadata,
        attributes: {
          input: finalInput
        },
        asType: "span"
      });
      const traceTags = [.../* @__PURE__ */ new Set([...tags ?? [], ...this.tags])];
      if (!parentRunId) {
        observation.updateTrace({
          tags: traceTags,
          userId: metadata && "userId" in metadata && typeof metadata["userId"] === "string" ? metadata["userId"] : this.userId,
          sessionId: metadata && "sessionId" in metadata && typeof metadata["sessionId"] === "string" ? metadata["sessionId"] : this.sessionId,
          metadata: this.traceMetadata,
          version: this.version
        });
      }
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleAgentAction(action, runId, parentRunId) {
    try {
      this.logger.debug?.(`Agent action ${action.tool} with ID: ${runId}`);
      this.startAndRegisterObservation({
        runId,
        parentRunId,
        runName: action.tool,
        attributes: {
          input: action
        },
        asType: "tool"
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleAgentEnd(action, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Agent finish with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: { output: action }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleChainError(err, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Chain error: ${err} with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: {
          level: "ERROR",
          statusMessage: err.toString()
        }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleGenerationStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {
    this.logger.debug?.(
      `Generation start with ID: ${runId} and parentRunId ${parentRunId}`
    );
    const runName = name ?? llm.id.at(-1)?.toString() ?? "Langchain Generation";
    const modelParameters = {};
    const invocationParams = extraParams?.["invocation_params"];
    for (const [key, value] of Object.entries({
      temperature: invocationParams?.temperature,
      max_tokens: invocationParams?.max_tokens,
      top_p: invocationParams?.top_p,
      frequency_penalty: invocationParams?.frequency_penalty,
      presence_penalty: invocationParams?.presence_penalty,
      request_timeout: invocationParams?.request_timeout
    })) {
      if (value !== void 0 && value !== null) {
        modelParameters[key] = value;
      }
    }
    let extractedModelName;
    if (extraParams) {
      const invocationParamsModelName = extraParams.invocation_params.model;
      const metadataModelName = metadata && "ls_model_name" in metadata ? metadata["ls_model_name"] : void 0;
      extractedModelName = invocationParamsModelName ?? metadataModelName;
    }
    const registeredPrompt = this.promptToParentRunMap.get(
      parentRunId ?? "root"
    );
    if (registeredPrompt && parentRunId) {
      this.deregisterPromptInfo(parentRunId);
    }
    this.startAndRegisterObservation({
      runId,
      parentRunId,
      metadata,
      tags,
      runName,
      attributes: {
        input: messages,
        model: extractedModelName,
        modelParameters
      },
      asType: "llm"
    });
  }
  async handleChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, name) {
    try {
      this.logger.debug?.(`Chat model start with ID: ${runId}`);
      const prompts = messages.flatMap(
        (message) => message.map((m) => this.extractChatMessageContent(m))
      );
      this.handleGenerationStart(
        llm,
        prompts,
        runId,
        parentRunId,
        extraParams,
        tags,
        metadata,
        name
      );
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleChainEnd(outputs, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Chain end with ID: ${runId}`);
      let finalOutput = outputs;
      if (typeof outputs === "object" && "output" in outputs && typeof outputs["output"] === "string") {
        finalOutput = outputs["output"];
      } else if (typeof outputs === "object" && "messages" in outputs && Array.isArray(outputs["messages"]) && outputs["messages"].every((m) => m instanceof BaseMessage)) {
        finalOutput = {
          messages: outputs.messages.map(
            (message) => this.extractChatMessageContent(message)
          )
        };
      }
      this.handleObservationEnd({
        runId,
        attributes: {
          output: finalOutput
        }
      });
      this.deregisterPromptInfo(runId);
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, name) {
    try {
      this.logger.debug?.(`LLM start with ID: ${runId}`);
      this.handleGenerationStart(
        llm,
        prompts,
        runId,
        parentRunId,
        extraParams,
        tags,
        metadata,
        name
      );
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleToolStart(tool, input, runId, parentRunId, tags, metadata, name) {
    try {
      this.logger.debug?.(`Tool start with ID: ${runId}`);
      this.startAndRegisterObservation({
        runId,
        parentRunId,
        runName: name ?? tool.id.at(-1)?.toString() ?? "Tool execution",
        attributes: {
          input
        },
        metadata,
        tags,
        asType: "tool"
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name) {
    try {
      this.logger.debug?.(`Retriever start with ID: ${runId}`);
      this.startAndRegisterObservation({
        runId,
        parentRunId,
        runName: name ?? retriever.id.at(-1)?.toString() ?? "Retriever",
        attributes: {
          input: query
        },
        tags,
        metadata,
        asType: "span"
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleRetrieverEnd(documents, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Retriever end with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: {
          output: documents
        }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleRetrieverError(err, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Retriever error: ${err} with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: {
          level: "ERROR",
          statusMessage: err.toString()
        }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleToolEnd(output, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Tool end with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: { output }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleToolError(err, runId, _parentRunId) {
    try {
      this.logger.debug?.(`Tool error ${err} with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: {
          level: "ERROR",
          statusMessage: err.toString()
        }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleLLMEnd(output, runId, _parentRunId) {
    try {
      this.logger.debug?.(`LLM end with ID: ${runId}`);
      const lastResponse = output.generations[output.generations.length - 1][output.generations[output.generations.length - 1].length - 1];
      const llmUsage = this.extractUsageMetadata(lastResponse) ?? output.llmOutput?.["tokenUsage"];
      const modelName = this.extractModelNameFromMetadata(lastResponse);
      const usageDetails = {
        input: llmUsage?.input_tokens ?? ("promptTokens" in llmUsage ? llmUsage?.promptTokens : void 0),
        output: llmUsage?.output_tokens ?? ("completionTokens" in llmUsage ? llmUsage?.completionTokens : void 0),
        total: llmUsage?.total_tokens ?? ("totalTokens" in llmUsage ? llmUsage?.totalTokens : void 0)
      };
      if (llmUsage && "input_token_details" in llmUsage) {
        for (const [key, val] of Object.entries(
          llmUsage["input_token_details"] ?? {}
        )) {
          usageDetails[`input_${key}`] = val;
          if ("input" in usageDetails && typeof val === "number") {
            usageDetails["input"] = Math.max(0, usageDetails["input"] - val);
          }
        }
      }
      if (llmUsage && "output_token_details" in llmUsage) {
        for (const [key, val] of Object.entries(
          llmUsage["output_token_details"] ?? {}
        )) {
          usageDetails[`output_${key}`] = val;
          if ("output" in usageDetails && typeof val === "number") {
            usageDetails["output"] = Math.max(0, usageDetails["output"] - val);
          }
        }
      }
      const extractedOutput = "message" in lastResponse ? this.extractChatMessageContent(
        lastResponse["message"]
      ) : lastResponse.text;
      this.handleObservationEnd({
        runId,
        attributes: {
          model: modelName,
          output: extractedOutput,
          completionStartTime: runId in this.completionStartTimes ? this.completionStartTimes[runId] : void 0,
          usageDetails
        }
      });
      if (runId in this.completionStartTimes) {
        delete this.completionStartTimes[runId];
      }
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  async handleLLMError(err, runId, _parentRunId) {
    try {
      this.logger.debug?.(`LLM error ${err} with ID: ${runId}`);
      this.handleObservationEnd({
        runId,
        attributes: {
          level: "ERROR",
          statusMessage: err.toString()
        }
      });
    } catch (e) {
      this.logger.debug?.(e instanceof Error ? e.message : String(e));
    }
  }
  registerPromptInfo(parentRunId, metadata) {
    if (metadata && "promptInfo" in metadata && parentRunId) {
      this.promptToParentRunMap.set(
        parentRunId,
        metadata.promptInfo
      );
    }
  }
  deregisterPromptInfo(runId) {
    this.promptToParentRunMap.delete(runId);
  }
  startAndRegisterObservation(params) {
    const { runName, runId, parentRunId, attributes, metadata, tags, asType } = params;
    let parentSpanContext;
    if (parentRunId) {
      parentSpanContext = this.runMap.get(parentRunId)?.otelSpan.spanContext();
    } else if (this.externalParentSpanContext) {
      parentSpanContext = this.externalParentSpanContext;
    }
    let finalRunName = runName;
    if (!parentRunId && this.adapterName) {
      finalRunName = `Adapter.${this.adapterName}`;
    }
    const observation = startObservation(
      finalRunName,
      {
        version: this.version,
        metadata: this.joinTagsAndMetaData(tags, metadata),
        ...attributes
      },
      {
        asType: asType ?? "span",
        parentSpanContext
      }
    );
    this.runMap.set(runId, observation);
    return observation;
  }
  handleObservationEnd(params) {
    const { runId, attributes = {} } = params;
    const observation = this.runMap.get(runId);
    if (!observation) {
      this.logger.warn?.("Observation not found in runMap. Skipping operation.");
      return;
    }
    observation.update(attributes).end();
    this.last_trace_id = observation.traceId;
    this.runMap.delete(runId);
  }
  joinTagsAndMetaData(tags, metadata1, metadata2) {
    const finalDict = {};
    if (tags && tags.length > 0) {
      finalDict.tags = tags;
    }
    if (metadata1) {
      Object.assign(finalDict, metadata1);
    }
    if (metadata2) {
      Object.assign(finalDict, metadata2);
    }
    return this.stripObservabilityKeysFromMetadata(finalDict);
  }
  stripObservabilityKeysFromMetadata(metadata) {
    if (!metadata) {
      return;
    }
    const reservedKeys = ["promptInfo", "userId", "sessionId"];
    return Object.fromEntries(
      Object.entries(metadata).filter(([key, _]) => !reservedKeys.includes(key))
    );
  }
  extractUsageMetadata(generation) {
    try {
      const usageMetadata = "message" in generation && (AIMessage.isInstance(generation["message"]) || AIMessageChunk.isInstance(generation["message"])) ? generation["message"].usage_metadata : void 0;
      return usageMetadata;
    } catch (err) {
      this.logger.debug?.(`Error extracting usage metadata: ${err}`);
      return;
    }
  }
  extractModelNameFromMetadata(generation) {
    try {
      return "message" in generation && (AIMessage.isInstance(generation["message"]) || AIMessageChunk.isInstance(generation["message"])) ? generation["message"].response_metadata.model_name : void 0;
    } catch {
    }
  }
  extractChatMessageContent(message) {
    let response = void 0;
    if (message.getType() === "human") {
      response = { content: message.content, role: "user" };
    } else if (message.getType() === "generic") {
      response = {
        content: message.content,
        role: "human"
      };
    } else if (message.getType() === "ai") {
      response = { content: message.content, role: "assistant" };
      if ("tool_calls" in message && Array.isArray(message.tool_calls) && (message.tool_calls?.length ?? 0) > 0) {
        response["tool_calls"] = message["tool_calls"];
      }
      if ("additional_kwargs" in message && "tool_calls" in message["additional_kwargs"]) {
        response["tool_calls"] = message["additional_kwargs"]["tool_calls"];
      }
    } else if (message.getType() === "system") {
      response = { content: message.content, role: "system" };
    } else if (message.getType() === "function") {
      response = {
        content: message.content,
        additional_kwargs: message.additional_kwargs,
        role: message.name
      };
    } else if (message.getType() === "tool") {
      response = {
        content: message.content,
        additional_kwargs: message.additional_kwargs,
        role: message.name
      };
    } else if (!message.name) {
      response = { content: message.content };
    } else {
      response = {
        role: message.name,
        content: message.content
      };
    }
    if ((message.additional_kwargs.function_call || message.additional_kwargs.tool_calls) && response["tool_calls"] === void 0) {
      return { ...response, additional_kwargs: message.additional_kwargs };
    }
    return response;
  }
};
export {
  CallbackHandler
};
//# sourceMappingURL=langchain.mjs.map