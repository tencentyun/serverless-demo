import { AgentAction, AgentFinish } from '@langchain/core/agents';
import { BaseCallbackHandler } from '@langchain/core/callbacks/base';
import { Document } from '@langchain/core/documents';
import { Serialized } from '@langchain/core/load/serializable';
import { BaseMessageFields, MessageContent, BaseMessage } from '@langchain/core/messages';
import { LLMResult } from '@langchain/core/outputs';
import { ChainValues } from '@langchain/core/utils/types';
import { SpanContext } from '@opentelemetry/api';
import { Logger } from '@cloudbase/agent-shared';

/**
 * LangChain Callback Handler for AG-Kit Observability
 *
 * Converts LangChain callback events into AG-Kit observations with OpenInference semantics.
 */

/**
 * Constructor parameters for CallbackHandler.
 *
 * @public
 */
type ConstructorParams = {
    userId?: string;
    sessionId?: string;
    tags?: string[];
    version?: string;
    traceMetadata?: Record<string, unknown>;
    adapterName?: string;
    /** Logger for debug output. Defaults to noopLogger (silent). */
    logger?: Logger;
};
/**
 * Message format for LLM input/output.
 *
 * @public
 */
type LlmMessage = {
    role: string;
    content: BaseMessageFields["content"];
    additional_kwargs?: BaseMessageFields["additional_kwargs"];
};
/**
 * Anonymous message format (without role).
 *
 * @public
 */
type AnonymousLlmMessage = {
    content: BaseMessageFields["content"];
    additional_kwargs?: BaseMessageFields["additional_kwargs"];
};
/**
 * LangChain Callback Handler for AG-Kit Observability.
 *
 * This handler intercepts LangChain callbacks and converts them into
 * AG-Kit observations following OpenInference semantic conventions.
 *
 * @public
 */
declare class CallbackHandler extends BaseCallbackHandler {
    name: string;
    private userId?;
    private version?;
    private sessionId?;
    private tags;
    private traceMetadata?;
    private completionStartTimes;
    private promptToParentRunMap;
    private runMap;
    last_trace_id: string | null;
    private externalParentSpanContext?;
    private adapterName?;
    private logger;
    constructor(params?: ConstructorParams);
    /**
     * Set external parent SpanContext from AG-UI.Server span.
     * This allows the CallbackHandler to link LangChain/LangGraph spans
     * to the server-level span, creating a unified trace hierarchy.
     *
     * @param spanContext - SpanContext from the AG-UI.Server span
     * @public
     */
    setExternalParentContext(spanContext: SpanContext): void;
    handleLLMNewToken(token: string, _idx: any, runId: string, _parentRunId?: string, _tags?: string[], _fields?: any): Promise<void>;
    handleChainStart(chain: Serialized, inputs: ChainValues, runId: string, parentRunId?: string | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, runType?: string, name?: string): Promise<void>;
    handleAgentAction(action: AgentAction, runId: string, parentRunId?: string): Promise<void>;
    handleAgentEnd?(action: AgentFinish, runId: string, _parentRunId?: string): Promise<void>;
    handleChainError(err: any, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleGenerationStart(llm: Serialized, messages: (LlmMessage | MessageContent | AnonymousLlmMessage)[], runId: string, parentRunId?: string | undefined, extraParams?: Record<string, unknown> | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, name?: string): Promise<void>;
    handleChatModelStart(llm: Serialized, messages: BaseMessage[][], runId: string, parentRunId?: string | undefined, extraParams?: Record<string, unknown> | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, name?: string): Promise<void>;
    handleChainEnd(outputs: ChainValues, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleLLMStart(llm: Serialized, prompts: string[], runId: string, parentRunId?: string | undefined, extraParams?: Record<string, unknown> | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, name?: string): Promise<void>;
    handleToolStart(tool: Serialized, input: string, runId: string, parentRunId?: string | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, name?: string): Promise<void>;
    handleRetrieverStart(retriever: Serialized, query: string, runId: string, parentRunId?: string | undefined, tags?: string[] | undefined, metadata?: Record<string, unknown> | undefined, name?: string): Promise<void>;
    handleRetrieverEnd(documents: Document<Record<string, any>>[], runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleRetrieverError(err: any, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleToolEnd(output: string, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleToolError(err: any, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleLLMEnd(output: LLMResult, runId: string, _parentRunId?: string | undefined): Promise<void>;
    handleLLMError(err: any, runId: string, _parentRunId?: string | undefined): Promise<void>;
    private registerPromptInfo;
    private deregisterPromptInfo;
    private startAndRegisterObservation;
    private handleObservationEnd;
    private joinTagsAndMetaData;
    private stripObservabilityKeysFromMetadata;
    private extractUsageMetadata;
    private extractModelNameFromMetadata;
    private extractChatMessageContent;
}

export { type AnonymousLlmMessage, CallbackHandler, type LlmMessage };
