{"version":3,"file":"index.d.cts","names":["Runnable","BaseLanguageModel","basePush","push","pull","T","Promise"],"sources":["../../src/hub/index.d.ts"],"sourcesContent":["import { Runnable } from \"@langchain/core/runnables\";\nimport type { BaseLanguageModel } from \"@langchain/core/language_models/base\";\nimport { basePush } from \"./base.js\";\nexport { basePush as push };\n/**\n * Pull a prompt from the hub.\n *\n * @param ownerRepoCommit The name of the repo containing the prompt, as well as an optional commit hash separated by a slash.\n * @param options.apiKey LangSmith API key to use when pulling the prompt\n * @param options.apiUrl LangSmith API URL to use when pulling the prompt\n * @param options.includeModel Whether to also instantiate and attach a model instance to the prompt,\n *   if the prompt has associated model metadata. If set to true, invoking the resulting pulled prompt will\n *   also invoke the instantiated model. For non-OpenAI models, you must also set \"modelClass\" to the\n *   correct class of the model.\n * @param options.modelClass If includeModel is true, the class of the model to instantiate. Required\n *   for non-OpenAI models. If you are running in Node or another environment that supports dynamic imports,\n *   you may instead import this function from \"langchain/hub/node\" and pass \"includeModel: true\" instead\n *   of specifying this parameter.\n * @returns\n */\nexport declare function pull<T extends Runnable>(ownerRepoCommit: string, options?: {\n    apiKey?: string;\n    apiUrl?: string;\n    includeModel?: boolean;\n    modelClass?: new (...args: any[]) => BaseLanguageModel;\n}): Promise<T>;\n//# sourceMappingURL=index.d.ts.map"],"mappings":";;;;;;;AAoBA;;;;;AAKW;;;;;;;;;;iBALaI,eAAeJ;;;;uCAIEC;IACrCK,QAAQD"}