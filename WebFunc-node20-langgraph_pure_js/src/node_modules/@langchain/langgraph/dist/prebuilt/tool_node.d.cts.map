{"version":3,"file":"tool_node.d.cts","names":["BaseMessage","ToolMessage","RunnableConfig","RunnableToolLike","DynamicTool","StructuredToolInterface","ToolCall","RunnableCallable","MessagesAnnotation","END","Command","ToolNodeOptions","ToolNode","T","Promise","toolsCondition","State"],"sources":["../../src/prebuilt/tool_node.d.ts"],"sourcesContent":["import { BaseMessage, ToolMessage } from \"@langchain/core/messages\";\nimport { RunnableConfig, RunnableToolLike } from \"@langchain/core/runnables\";\nimport { DynamicTool, StructuredToolInterface } from \"@langchain/core/tools\";\nimport type { ToolCall } from \"@langchain/core/messages/tool\";\nimport { RunnableCallable } from \"../utils.js\";\nimport { MessagesAnnotation } from \"../graph/messages_annotation.js\";\nimport { END, Command } from \"../constants.js\";\nexport type ToolNodeOptions = {\n    name?: string;\n    tags?: string[];\n    handleToolErrors?: boolean;\n};\n/**\n * A node that runs the tools requested in the last AIMessage. It can be used\n * either in StateGraph with a \"messages\" key or in MessageGraph. If multiple\n * tool calls are requested, they will be run in parallel. The output will be\n * a list of ToolMessages, one for each tool call.\n *\n * @example\n * ```ts\n * import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n * import { tool } from \"@langchain/core/tools\";\n * import { z } from \"zod\";\n * import { AIMessage } from \"@langchain/core/messages\";\n *\n * const getWeather = tool((input) => {\n *   if ([\"sf\", \"san francisco\"].includes(input.location.toLowerCase())) {\n *     return \"It's 60 degrees and foggy.\";\n *   } else {\n *     return \"It's 90 degrees and sunny.\";\n *   }\n * }, {\n *   name: \"get_weather\",\n *   description: \"Call to get the current weather.\",\n *   schema: z.object({\n *     location: z.string().describe(\"Location to get the weather for.\"),\n *   }),\n * });\n *\n * const tools = [getWeather];\n * const toolNode = new ToolNode(tools);\n *\n * const messageWithSingleToolCall = new AIMessage({\n *   content: \"\",\n *   tool_calls: [\n *     {\n *       name: \"get_weather\",\n *       args: { location: \"sf\" },\n *       id: \"tool_call_id\",\n *       type: \"tool_call\",\n *     }\n *   ]\n * })\n *\n * await toolNode.invoke({ messages: [messageWithSingleToolCall] });\n * // Returns tool invocation responses as:\n * // { messages: ToolMessage[] }\n * ```\n *\n * @example\n * ```ts\n * import {\n *   StateGraph,\n *   MessagesAnnotation,\n * } from \"@langchain/langgraph\";\n * import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n * import { tool } from \"@langchain/core/tools\";\n * import { z } from \"zod\";\n * import { ChatAnthropic } from \"@langchain/anthropic\";\n *\n * const getWeather = tool((input) => {\n *   if ([\"sf\", \"san francisco\"].includes(input.location.toLowerCase())) {\n *     return \"It's 60 degrees and foggy.\";\n *   } else {\n *     return \"It's 90 degrees and sunny.\";\n *   }\n * }, {\n *   name: \"get_weather\",\n *   description: \"Call to get the current weather.\",\n *   schema: z.object({\n *     location: z.string().describe(\"Location to get the weather for.\"),\n *   }),\n * });\n *\n * const tools = [getWeather];\n * const modelWithTools = new ChatAnthropic({\n *   model: \"claude-3-haiku-20240307\",\n *   temperature: 0\n * }).bindTools(tools);\n *\n * const toolNodeForGraph = new ToolNode(tools)\n *\n * const shouldContinue = (state: typeof MessagesAnnotation.State) => {\n *   const { messages } = state;\n *   const lastMessage = messages[messages.length - 1];\n *   if (\"tool_calls\" in lastMessage && Array.isArray(lastMessage.tool_calls) && lastMessage.tool_calls?.length) {\n *     return \"tools\";\n *   }\n *   return \"__end__\";\n * }\n *\n * const callModel = async (state: typeof MessagesAnnotation.State) => {\n *   const { messages } = state;\n *   const response = await modelWithTools.invoke(messages);\n *   return { messages: response };\n * }\n *\n * const graph = new StateGraph(MessagesAnnotation)\n *   .addNode(\"agent\", callModel)\n *   .addNode(\"tools\", toolNodeForGraph)\n *   .addEdge(\"__start__\", \"agent\")\n *   .addConditionalEdges(\"agent\", shouldContinue)\n *   .addEdge(\"tools\", \"agent\")\n *   .compile();\n *\n * const inputs = {\n *   messages: [{ role: \"user\", content: \"what is the weather in SF?\" }],\n * };\n *\n * const stream = await graph.stream(inputs, {\n *   streamMode: \"values\",\n * });\n *\n * for await (const { messages } of stream) {\n *   console.log(messages);\n * }\n * // Returns the messages in the state at each step of execution\n * ```\n */\nexport declare class ToolNode<T = any> extends RunnableCallable<T, T> {\n    tools: (StructuredToolInterface | DynamicTool | RunnableToolLike)[];\n    handleToolErrors: boolean;\n    trace: boolean;\n    constructor(tools: (StructuredToolInterface | DynamicTool | RunnableToolLike)[], options?: ToolNodeOptions);\n    protected runTool(call: ToolCall, config: RunnableConfig): Promise<ToolMessage | Command>;\n    protected run(input: unknown, config: RunnableConfig): Promise<T>;\n}\n/**\n * A conditional edge function that determines whether to route to a tools node or end the graph.\n *\n * This function is designed to be used as a conditional edge in a LangGraph state graph to implement\n * the common pattern of checking if an AI message contains tool calls that need to be executed.\n *\n * @param state - The current state of the graph, which can be either:\n *   - An array of `BaseMessage` objects, where the last message is checked for tool calls\n *   - A state object conforming to `MessagesAnnotation.State`, which contains a `messages` array\n *\n * @returns A string indicating the next node to route to:\n *   - `\"tools\"` - If the last message contains tool calls that need to be executed\n *   - `END` - If there are no tool calls, indicating the graph should terminate\n *\n * @example\n * ```typescript\n * import { StateGraph, MessagesAnnotation, END, START } from \"@langchain/langgraph\";\n * import { ToolNode, toolsCondition } from \"@langchain/langgraph/prebuilt\";\n *\n * const graph = new StateGraph(MessagesAnnotation)\n *   .addNode(\"agent\", agentNode)\n *   .addNode(\"tools\", new ToolNode([searchTool, calculatorTool]))\n *   .addEdge(START, \"agent\")\n *   .addConditionalEdges(\"agent\", toolsCondition, [\"tools\", END])\n *   .addEdge(\"tools\", \"agent\")\n *   .compile();\n * ```\n *\n * @remarks\n * The function checks the last message in the state for the presence of `tool_calls`.\n * If the message is an `AIMessage` with one or more tool calls, it returns `\"tools\"`,\n * indicating that the graph should route to a tools node (typically a `ToolNode`) to\n * execute those tool calls. Otherwise, it returns `END` to terminate the graph execution.\n *\n * This is a common pattern in agentic workflows where an AI model decides whether to\n * use tools or provide a final response.\n */\nexport declare function toolsCondition(state: BaseMessage[] | typeof MessagesAnnotation.State): \"tools\" | typeof END;\n"],"mappings":";;;;;;;;;KAOYW,eAAAA;;EAAAA,IAAAA,CAAAA,EAAAA,MAAAA,EAAAA;EA0HSC,gBAAQ,CAAA,EAAA,OAAA;CAAA;;;;;;;;;;;;;;;;;;;;AA6C7B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cA7CqBA,0BAA0BL,iBAAiBM,GAAGA;UACvDR,0BAA0BD,cAAcD;;;sBAG5BE,0BAA0BD,cAAcD,+BAA+BQ;0BACnEL,kBAAkBJ,iBAAiBY,QAAQb,cAAcS;wCAC3CR,iBAAiBY,QAAQD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iBAuC3CE,cAAAA,QAAsBf,uBAAuBQ,kBAAAA,CAAmBQ,yBAAyBP"}